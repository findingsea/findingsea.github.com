{"meta":{"title":"findingsea's blog","subtitle":null,"description":null,"author":"findingsea","url":"http://findingsea.github.io","root":"/"},"pages":[{"title":"about","date":"2015-08-30T01:58:22.000Z","updated":"2020-02-22T09:30:45.925Z","comments":true,"path":"about/index.html","permalink":"http://findingsea.github.io/about/index.html","excerpt":"","text":"林胤电子邮件：findingsea@163.com 个人网站：findingsea.github.io 籍贯：浙江台州 联系电话：18616359554 学校：同济大学（研究生） 专业：计算机技术 工作经验2016.07-至今 腾讯科技(上海)有限公司 OMG广告平台部/CDG平台产品技术部 岗位：C++后台开发工程师 工作内容：负责合约广告投放引擎的开发工作。在线实时决策当前最优的广告播放方案，负责模块包括检索、过滤、粗排、概率精选，最终实现广告的精准投放。 2015.06-2015.09 阿里巴巴集团 淘点点事业部（实习） 岗位：后台开发工程师 工作内容：所在团队为支付宝–商家Tab提供后端服务聚合，主要参与mobilecsa系统日常业务开发和LDC改造。 项目经验2018.05 合约广告ABTest系统 职责：独立负责ABTest系统设计，及流量匹配模块开发。 效果：通过对流量的多维度标签化处理，实现高灵活度的流量筛选及匹配；支持在线多套产品、算法策略进行ABTest效果对比，为开发决策提供数据依据，提升开发效率。 2017.08 合约广告平滑播控 职责：独立设计并开发基于时间片的平滑播控模块。设计服务器本地播控数据缓存，在过滤阶段对广告播放进行控制，同时利用Redis对全局播控数据进行同步。 效果：降低了整体广告播控时延，尤其针对小预定量广告实现了更精准的播放控制。 2017.03 广告人群包表达式在线匹配 职责：利用k-index算法，实现了人群包逻辑表达式的在线匹配。 效果：使得投放引擎有能力在线使用原子人群包进行复杂人群定向，将人群定向投放的生效周期从天级降低为小时级，同时提升了投放灵活度。 DouBanReader 2015.06 – 2015.07豆瓣读书报告生成器，包括豆瓣授权、获取用户读书信息和生成MarkDown文件等功能，独立开发。关键技术：Python，GitHub开源。 在线词典 2014.03 – 2014.04Web词典应用，包括单词查询、整句翻译、背单词等功能，独立开发。关键技术：PHP，Bootstrap。 快递通 2012.07 – 2013.06物流ERP系统，功能覆盖物流各主要环节，在杭州酷仓宝科技有限公司实习期间参与该系统开发，主要负责异常单模块、理赔单模块、短信模块的设计与开发。关键技术：Java，DHTML。 青丝网 2012.02 – 2012.12在线发型推荐网站，包含基于脸型识别的发型推荐、发型试戴等功能，负责全部技术环节。作品参加2012年全国大学生电子商务大赛，获得浙江省一等奖，全国一等奖。关键技术：PHP，跨语言模块调用。 专业技能 全国大学生英语六级（467），全国大学生英语四级（550）。 熟悉C++语言。 熟悉Git、SVN、VIM、Sublime Text2等工具。 实践情况及其他 2012年10月获硕士推免生资格，保送同济大学就读计算机硕士学位。 本科期间，获二等奖学金一次，获三等奖学金一次。 浙江省物理竞赛一等奖、浙江省高数竞赛三等奖、校电子商务大赛三等奖。"},{"title":"分类","date":"2015-08-06T07:35:06.000Z","updated":"2020-02-22T09:30:45.925Z","comments":false,"path":"categories/index.html","permalink":"http://findingsea.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2015-08-06T07:37:02.000Z","updated":"2020-02-22T09:30:45.925Z","comments":false,"path":"tags/index.html","permalink":"http://findingsea.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"《一个叫欧维的男人决定去死》","slug":"En-man-som-heter-Ove","date":"2020-03-15T06:43:11.000Z","updated":"2020-03-15T06:43:45.196Z","comments":true,"path":"2020/03/15/En-man-som-heter-Ove/","link":"","permalink":"http://findingsea.github.io/2020/03/15/En-man-som-heter-Ove/","excerpt":"很有名的一本书，瑞典有史以来最畅销的书。我拿起来刚看了几章的时候，就感觉到作者很懂现在读者的阅读习惯，每个小章节都是一截比较完整的故事，开头都会有个转折，结尾回个悬念，阅读趣味性很高。很像是网络连载文学，后来一查， 巴克曼的确就是一位出众网络博主，整本书也非常符合网络时代的阅读习惯，估计这么畅销也跟这点有关。","text":"很有名的一本书，瑞典有史以来最畅销的书。我拿起来刚看了几章的时候，就感觉到作者很懂现在读者的阅读习惯，每个小章节都是一截比较完整的故事，开头都会有个转折，结尾回个悬念，阅读趣味性很高。很像是网络连载文学，后来一查， 巴克曼的确就是一位出众网络博主，整本书也非常符合网络时代的阅读习惯，估计这么畅销也跟这点有关。 故事开头，欧维是一个59岁的老头，脾气古怪，非常顽固，有着很多看起来莫名其妙的原则。看起来没什么朋友，他也一副看谁都看不惯的样子。 然后，他想自杀。 也没说明他为什么想自杀，就是一副活够的感觉。他本来已经计划好了关于自杀的一切，包括所有身后事，甚至是安葬的费用。知道对话痨夫妇和他们的两个话痨女儿搬到隔壁，还不小心撞坏了他的邮筒。欧维的生活开始跟别人有了交集。 各种机缘巧合下，他每次想自杀，都会被突如其来的事情破坏，然后总也忍不住去帮助别人，解决别人的麻烦。结果其中进入他生活的人越来越多，并且因他受益。欧维也越来越多开始展现吸引人的一面，看似顽固，其实是恪守自己的原则，看似不近人情，其实内心却非常温柔，嘴上虽然不饶人，但身体力行地帮助别人。 这其中大量地插叙了欧维的成长经历，以及他跟妻子的爱情。 书里有两个点是作者着重要表达的：他对原则几乎顽固的恪守，他对妻子的爱。前者字里行间都能体会到，但是因为有些故事讲的过于圆滑，所以让我有点出戏；后者的确打动到了我，尤其是作者在这部分的处理方式很高明。 书前三分之一部分，每当欧维跟外部有冲突的时候，都会出现他跟妻子倾诉的情节，她仿佛是他还能跟这个世界沟通的唯一桥梁，只有跟索雅（欧维的妻子）在一起时，欧维才是温柔的。同时，他也会偶尔抱怨妻子的衣服太多了、总是开暖气浪费钱，直到某一小节，突然： 他是个非黑即白的男人。她是色彩，他的全部色彩。他为她搭了个书架，然后她用一页一页写满感情的书把它填满。”我想你。”他低声说。六个月前，她去世了。但欧维还是每天两次走遍所有房间，摸摸暖气片，看她有没有悄悄把它们打开。 我才恍然大悟，他的妻子已经过世了，之前的一切情节，都发生在他妻子的墓前，跟空荡荡的家里。 一下子之前两个人之间的甜蜜，全都变为了欧维对索雅无比深沉的思念。非常打动到我。 这是一本足够温暖跟感动人的书，虽然欧维的故事有点生硬，但是越读下去还是越能感受到他顽固的魅力，以及他爱情的深沉。","categories":[],"tags":[]},{"title":"远程办公的一些感受","slug":"My-remote-experience","date":"2020-03-01T10:16:56.000Z","updated":"2020-03-01T10:20:09.985Z","comments":true,"path":"2020/03/01/My-remote-experience/","link":"","permalink":"http://findingsea.github.io/2020/03/01/My-remote-experience/","excerpt":"由于疫情的原因，经历了一段时间的远程办公，写一篇文章来记录下这段时间的感受。","text":"由于疫情的原因，经历了一段时间的远程办公，写一篇文章来记录下这段时间的感受。 总体感受在互联网领域，远程办公不是什么新鲜的事情，毕竟写代码不是一个需要密切交流的工作。业内也有不少非常成功的公司，采用的是全体员工办公的方式，比如大名鼎鼎的37signals，产出了BaseCamp跟《Rework》（中译名《重来》）。不过以整个从业群体来说，远程办公还是少数。 我一开始的预期是远程办公应该差异不大，毕竟之前周末也常常在家加班，真的连续办公之后才发现不像是想象的那样。 总体上我对于远程办公经历了新奇-&gt;不适-&gt;适应三个阶段。 新奇的第一周第一周复工开始远程办公，可以说是感受最新奇的时候，不管是工作上同事之间需要经历再磨合，还是生活上长时间呆在家里适应这种半封闭的状态。 所以第一周我每天都会进行回顾记录。 第一天 第二天 第三天 第四天 第五天 可以看到第一周开始远程办公，几乎每天都会经历新鲜事。然后一周结束后，我得出的结论是：我不适合远程办公。其中最不适应的点在于： 沟通效率变差。之前只需要转头就能讨论的问题，现在必须要进行线上沟通，而且也不确定对方这段时间是否有空。 工作环境更加局限。虽然是远程，但还是规定了工作时间的，在公司上班的时候还能更同时交流，或者去茶水间、会议室，切换下工作环境，而在家里的就真的从早到晚对电脑，并且所有信息都要从线上获取，甚至会更频繁地查看未读消息。 在家拖延后续一两周的远程办公，不适感更加重了。其中很重要的原因是办公的氛围没有了，会在工作中频繁的走神。 要做饭、洗碗、拿外卖/快递、倒垃圾，这些在公司上班时不用关心的事情，现在会频繁地打断工作节奏，而且一旦打断再切换回去又会觉得困恼。 一个人工作，会频繁出神，在工作不那么忙，或是工作/会议的间隙，更容易走神，刷手机/网页。 这些因素都让我觉得工作效率很低，而且很不愿意开始工作。毕竟工作哪有手机来的好玩，而且确实也没人管你/监督。导致我手头的几个项目，拖到了ddl才交付。虽然没有引发实质上的delay，但我明显能感觉到自己在拖延，会有一种「反正在家，晚点再做好了」的感觉。 在家办公好像还不错的样子随着在家办公时间变成，这种拖延感开始减轻，这其中当然有工作增多的因素，拖不起了，也有我自己主动做出的调整。 划定工作与生活的时间。这是我在家办公体会最深的，因为没有场景的切换，在家更容易生活工作混成一团，应该要开始工作的时候还在拖沓，应该要下班的时候还在继续工作。所以我给自己规定了工作的时间表，遵守到点开始到点结束。 早点开始工作。这其实是在家办公的一大优势，因为省去了通勤的时间，早上相比平时是要多出一块时间的。之前我都把这部分时间拿来继续睡觉或者洗漱或者吃早饭，其实就是拖到平时上班的时间点才开始上班。后来意识到这样越是拖，越是不愿意开工。反倒不如保持更平时上班的作息一致，把通勤空出来的时间直接拿来早点开始工作，由于这段时间基本无打扰，所以工作效率很高，早上就能完成一天工作的大半，这样下班时间也得到了保证。 感受生活。解决了工作问题之后，我才感觉到在家办公是能真正感觉到生活的。平时去公司上班，不管白天黑夜都开着灯，三餐不用自己操心，工作思考的都是抽象问题，其实是没有一种我在生活的感觉。在家里要想中午吃什么，要做家务，拿外卖/快递的时候，看看空着很多车位的小区，晒太阳的猫狗，窗外从天亮到天黑，有时候还能看见夕阳。这种时候很能感受到我在生活，日子是真的一天天在过。这种生活的气息，好像在开始工作之后，就没怎么感受过了。 疫情期间，希望大家工作生活都能照顾好自己。 以上。","categories":[],"tags":[]},{"title":"一些想法 Review","slug":"2019-review","date":"2020-01-12T01:59:57.000Z","updated":"2020-02-22T09:30:45.925Z","comments":true,"path":"2020/01/12/2019-review/","link":"","permalink":"http://findingsea.github.io/2020/01/12/2019-review/","excerpt":"本来这篇文章是2019年review的，但是因为在草稿箱躺了太久，就把标题改了改。","text":"本来这篇文章是2019年review的，但是因为在草稿箱躺了太久，就把标题改了改。 2019年相对来说，对我是比较困难的一年，第一次觉得生活工作到了一个瓶颈期。这一年过的不顺，也迫使自己反思了很多东西。所以2019 review就不去记录今年又看了几本书、几部电影、去了哪些地方，而是记录下这一年思想上的一些转变跟感悟。 如何避免「一年工作经验用了三年」2019年对我触动比较大的一句话是「很多人工作了9年，并不真的有9年的工作经验，而是把3年的工作经验用了9年」，原句记不太清了，大意如此。 当时正值我自己回顾反思工作三年的收获，这句话让我感受颇深。我的工作属于业务型开发程序员，的确在工作中对业务流程的数据和理解是最重要的，技术本身反倒是其次的。而业务只要你前期花时间去了解熟悉，上手之后就不会发生频繁的变更。 回顾我的工作经历，第一年的确在业务跟技术上都成长很快，已经足够覆盖日常工作所需，而往后工作本身没有在业务或者技术上产生过很大的挑战。所以如果要我说自己比两年前成长了多少，除了对工作更熟练，对一些细节修修补补之外，乏善可称。 人的惰性是天性，无可避免，一旦适应了环境之后，跳出舒适圈的动力就很小了。关于这一点，除了主动push自己提升、学习外，我也没找到很好的解决办法。我现在做的是反思、提醒自己，等我找到好的解决办法了再来分享。 把工作做好是能力，把生活过好更是能力这一点我之前的感知很少，可能也是之前的工作相对顺利，不管是工作还是生活，遇到的困难都少。就像天平的两边，一旦一方失衡，就不可避免地影响到另一边，尤其是工作生活分不开的时候，这种感觉尤其明显。在我工作不顺利的时候，大量的无用加班，无法推进的项目，定位不到原因的各种问题，都造成难以摆脱的压力跟疲惫感。在压迫工作的同时，也挤压生活。 以前我觉得专业是能力，而生活是自然的事情。现在我发现，「为了生活而工作」，而不是本末倒置，是需要额外的能力的。理清楚工作跟生活的分界，不要工作的负能量带到生活里，甚至影响到家人、朋友，这些都是得不偿失的。 把生活过好，这种能力也是需要锻炼的，需要自己不停地去调整边界，调整心态，最重要的可能是要调整并认识到什么才是更重要的东西。 改变的勇气恐惧是对未知本身。我们的确无法知道每次选择、改变是否能带来好的结果，但也要相信，一般人的工作生活，真的很少有什么选择是无法回头或者万劫不复。说到底，人生很长，做出一些改变跟尝试是值得的，哪怕它们在短期内没有带来什么收益。 安于现状是一种无可指摘的生活态度，只是一直如此，那另一种可能永远也都只存在于想象中的比较中，倒不如做一些改变，去亲身实地地感受一下。其实这也不需要多大的勇气，很多时候放不下已经积累的沉默成本，放到整个职业生涯的尺度上思考，这些东西真的没那么重要。 以上。","categories":[],"tags":[{"name":"review","slug":"review","permalink":"http://findingsea.github.io/tags/review/"}]},{"title":"C++ 结构体操作符重载","slug":"c-struct-operator","date":"2019-07-05T03:38:07.000Z","updated":"2020-02-22T09:30:45.925Z","comments":true,"path":"2019/07/05/c-struct-operator/","link":"","permalink":"http://findingsea.github.io/2019/07/05/c-struct-operator/","excerpt":"同事在工作中与到的一个问题，组装资源的时候，往std::set里插入自定义结构体失败，导致使用时查找失败。几个人一起排查了一下，最后发现是对自定义结构operator&lt;操作符进行重载时有歧义，导致了线上问题。","text":"同事在工作中与到的一个问题，组装资源的时候，往std::set里插入自定义结构体失败，导致使用时查找失败。几个人一起排查了一下，最后发现是对自定义结构operator&lt;操作符进行重载时有歧义，导致了线上问题。 错误示例123456789101112131415161718class Range &#123;public: int min; int max; // 错误示例：a.min=b.min，那么a&lt;(b)的判断为false，b&lt;(a)的判断为false，就会判断a=b，无法插入 bool operator&lt;(Range const&amp; b) const &#123; if (min == b.min &amp;&amp; max == b.max) &#123; return false; &#125; else &#123; return min &lt; b.min; &#125; &#125; Range(int min, int max) &#123; this-&gt;min = min; this-&gt;max = max; &#125;&#125;; std::set是去重的，那么如何判断两个元素是否相同？这就依赖operator&lt;，对于a、b两个元素，分别调用a&lt;b以及b&lt;a，如果两个都返回false，那么就判断a=b。这种判断机制，也是造成如上定义会出现问题的关键。 执行代码： 123456789101112int main() &#123; set&lt;Range&gt; range_set; Range r1(1, 2); Range r2(1, 2); Range r3(1, 1); range_set.insert(r1); range_set.insert(r2); range_set.insert(r3); for (auto &amp;r : range_set) &#123; cout &lt;&lt; \"[\" &lt;&lt; r.min &lt;&lt; \", \" &lt;&lt; r.max &lt;&lt; \"]\" &lt;&lt; endl; &#125;&#125; 输出： 1[1, 2] 可以看到r1和r2的确是相同的，只能插入其中一个，这个符合预期；r1和r3是两个不同的区间，但是r3的插入失败了。这里就是由于在Range中定义的operator&lt;仅仅对区间的左边界进行来判断。return min &lt; b.min;这个判断，对于a&lt;b和b&lt;a都是返回false，此时程序就会认为a和b是相等的，导致其中一个插入失败。 单独比较一下r1跟r3： 12cout &lt;&lt; \"r1 &lt; r3: \" &lt;&lt; (r1 &lt; r3) &lt;&lt; endl; // 0cout &lt;&lt; \"r3 &lt; r1: \" &lt;&lt; (r3 &lt; r1) &lt;&lt; endl; // 0 可以发现两次判断都是false，这样就会被set判断为是相等的两个元素。 正确示例123456789101112131415161718192021class Range &#123;public: int min; int max; bool operator&lt;(Range const&amp; b) const &#123; if (min == b.min &amp;&amp; max == b.max) &#123; return false; &#125; else if (min &lt; b.min) &#123; return true; &#125; else if (min == b.min) &#123; return max &lt; b.max; &#125; else &#123; return false; &#125; &#125; Range(int min, int max) &#123; this-&gt;min = min; this-&gt;max = max; &#125;&#125;; 执行代码： 123456789101112int main() &#123; set&lt;Range&gt; range_set; Range r1(1, 2); Range r2(1, 2); Range r3(1, 1); range_set.insert(r1); range_set.insert(r2); range_set.insert(r3); for (auto &amp;r : range_set) &#123; cout &lt;&lt; \"[\" &lt;&lt; r.min &lt;&lt; \", \" &lt;&lt; r.max &lt;&lt; \"]\" &lt;&lt; endl; &#125;&#125; 输出： 12[1, 2][1, 1] 输出符合预期。 这个问题其实在UT阶段就应该被发现，这里还是因为项目上线比较紧，而导致很多质量把控环节都疏忽了。","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"http://findingsea.github.io/tags/c/"}]},{"title":"关于 C++ vector 的两个小 tips","slug":"two-tips-on-cpp-vector","date":"2019-05-02T08:34:28.000Z","updated":"2020-02-22T09:30:45.924Z","comments":true,"path":"2019/05/02/two-tips-on-cpp-vector/","link":"","permalink":"http://findingsea.github.io/2019/05/02/two-tips-on-cpp-vector/","excerpt":"本来这篇文章标题我想起成《关于 vector 的两个小坑》，后来想想，其实也不算是坑，还是自己对原理性的东西理解的没做那么透彻。工作中遇到的很多问题，后来归根到底都是基础不牢靠。","text":"本来这篇文章标题我想起成《关于 vector 的两个小坑》，后来想想，其实也不算是坑，还是自己对原理性的东西理解的没做那么透彻。工作中遇到的很多问题，后来归根到底都是基础不牢靠。 vector 扩容这个问题很经典了，但还是不小心踩到。有一个需求是要对目标元素进行复制，而目标元素集合是保存在 vector 里面，于是简单思考下就有如下代码（大致含义）： 1234567891011void Duplidate(vector&lt;Element&gt;* element_list, Element* element) &#123; element_list.push_back(*element);&#125;void Process() &#123; for (auto&amp; package : package_list) &#123; if (IsNeedDuplicate()) &#123; Duplicate(element_list, package-&gt;element); &#125; &#125;&#125; 看起来好像没什么问题，就是当前的 package 对象是否满足复制的要求，需要的话，就对 package 的成员 origin_element 进行复制。跑 UT 也正常，然后在测试的时候就 coredump 了。看 core 文件就是挂在了复制的时候。这里我一开始就没明白，一个简单的复制为什么会有 coredump。 检查了很久 element 复制的场景，甚至想要专门写一个拷贝构造函数。最后才恍然大悟，origin_element 指针指向的就是 element_list 里面的元素，element_list 是整体流程的数据源，packge 对象是封装的中间处理对象。之前的开发人员为了方便，直接在 package 对象上保存了原始的 element 指针，而这个指针指向的是一个 vector 里的元素。而我新加的逻辑会往原始的 vector 里面再添加元素，那么就有可能导致 vector 扩容，而 vector 扩容会导致整体的复制，从而导致原来指向这些元素的指针都失效了，靠后的 package 对象再去访问 origin_element 就产生了 coredump。 当然，从设计上来说，就不应该保存指向 vector 元素的指针，但是这里有太多旧代码牵涉，这里就不做讨论。 vector::erase()起因是我在代码里面新增了如下代码（大致）： 123456void EraseElement(const vector&lt;Element&gt;::iterator&amp; element_iter, vector&lt;Element&gt;&amp; element_list) &#123; while (element_iter != element_list.end()) &#123; element_list.erase(element_iter); &#125;&#125; 然后 cr 的同学提出了一个疑问是 element_iter 是 const 不可变的，但是在函数里有擦除了对应的元素，这里会不会有问题？虽然 UT 都已经跑过了，但是这种写法的确比较奇怪，于是就借机学习了一下 vector::erase() 的实现原理跟用法。 erase(iterator) 的实现原理其实不会改变 iterator，而是把后面的元素一个个往前移动，相当于是 iterator 指向的元素本身发生了变化，所以可以用 const 来修饰这个 iterator。但是这里用 cosnt &amp; 其实是没有错但是无用的修饰，除了容易让人误判之外，其实没有什么实际用途。我之前是为了修正 cpplint 才把reference 改成 const reference。 另外 erase 本身的确比较危险，主要还是 erase 的时候 iterator 本身没发生变化，但是指向的元素变了，，在很多时候 iterator 会自然地指向下一个元素，但是由于这是未定义的行为，这里面可能会有不可预期的地方，所以最终改成显示的获取返回重新赋值（erase() 会返回下一个迭代器，但这一点常常被忽略），这样就能保证安全性了。更安全更推荐的做法应该是使用 remove_if() 这里就不展开讲了。 123456void EraseElement(vector&lt;Element&gt;&amp; element_list, vector&lt;Element&gt;::iterator element_iter ) &#123; while (element_iter != element_list.end()) &#123; element_iter = element_list.erase(element_iter); &#125;&#125;","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"http://findingsea.github.io/tags/c/"}]},{"title":"即刻第三方开发者","slug":"jiek-third-party-developer","date":"2019-03-16T05:09:53.000Z","updated":"2020-02-22T09:30:45.924Z","comments":true,"path":"2019/03/16/jiek-third-party-developer/","link":"","permalink":"http://findingsea.github.io/2019/03/16/jiek-third-party-developer/","excerpt":"即刻，是一个「我也不知道怎么定义，总之挺好玩的」app。上面不仅有很多有趣的人，还有很多程序员👨‍💻‍开发了不少基于即刻的小项目，非常好玩、有趣，本文就罗列一下我已知的几个项目。","text":"即刻，是一个「我也不知道怎么定义，总之挺好玩的」app。上面不仅有很多有趣的人，还有很多程序员👨‍💻‍开发了不少基于即刻的小项目，非常好玩、有趣，本文就罗列一下我已知的几个项目。 Ⓙ jikeme 🐟 让你在命令行摸🐟刷圈子，GitHub 🔗：findingsea/jikeme，by Ⓙfindingsea ⒿChungZH Ⓙ jikefm 🎵 让你在命令行收听晚安电台，GitHub 🔗：0neSe7en/jikefm，by Ⓙ0neSe7en Ⓙ Jike-Metro 🚇 即刻 API Python SDK，即刻搭车指南，GitHub 🔗：Sorosliu1029/Jike-Metro， by Ⓙ搞即建的 Ⓙ 即刻喵即刻通知 Chrome 插件，Chrome Market 🔗：即刻喵，by Ⓙ盐酥鸡 Ⓙ 即刻喵 2.0jike-meow 2.0，重写了一遍并添加了更多功能，GitHub 🔗：即刻喵 2，by Ⓙ盐酥鸡 Ⓙ 即刻黄历 📆 JSBox 脚本，让你在 iOS 通知中心看黄历，🔗：即刻黄历，by Ryan Ⓙ 果果名片生成器 帮你生成你的即刻名片，GitHub 🔗：spencerwooo/jike-guoguo-badge，by ⒿSpencerWoo Ⓙ Love Jike Extension 优化即刻网页版体验的 Chrome 插件，GitHub 🔗：Doila/love-jike-chrome-extension，by Ⓙ呜啦啦朵小小 等待后续补充……","categories":[],"tags":[{"name":"essay","slug":"essay","permalink":"http://findingsea.github.io/tags/essay/"}]},{"title":"我的校招回顾","slug":"my-Campus-Recruitment","date":"2019-03-13T06:45:13.000Z","updated":"2020-02-22T09:30:45.924Z","comments":true,"path":"2019/03/13/my-Campus-Recruitment/","link":"","permalink":"http://findingsea.github.io/2019/03/13/my-Campus-Recruitment/","excerpt":"我是 2015 年参加校招，这个过程可谓是一波三折。先是比较顺利地拿到了阿里的实习 offer，然后在快要转正的时候被通知「拥抱变化」，接着在腾讯和小公司的 offer 之间抉择，然而选择了小公司之后又被毁约三方协议，最后重新申请腾讯 offer 成功。","text":"我是 2015 年参加校招，这个过程可谓是一波三折。先是比较顺利地拿到了阿里的实习 offer，然后在快要转正的时候被通知「拥抱变化」，接着在腾讯和小公司的 offer 之间抉择，然而选择了小公司之后又被毁约三方协议，最后重新申请腾讯 offer 成功。 阿里实习我高中和本科都在杭州念的，所以很有感情，也想回杭州工作。在杭州的互联网公司中，阿里是最好的选择了（当时 BAT 都是风光无限）。正好实验室有师兄在阿里工作，就让他帮我内推了实习，面试很顺利就通过了。 实习期过的是挺爽的，小论文已经投掉了📚，阿里实习工资又高💰，我在杭州的同学朋友又多👬，我跟团队以及导师也都互相都挺满意的，可谓两情相悦，return offer 看起来没什么问题。跟我导师闲聊的内容都是年轻人的第一辆车🚗应该买什么，杭州哪里的房子🏡比较好。包括之后的转正面试，导师也表明结果很好（八月底），我也就没抱其他想法，安心舒适地等结果就行。 拥抱变化结果后来就发生了「拥抱变化」，考古请看👉 《阿里巴巴毁约，说好的3000个校招名额突然缩减为400个》。当时可以说是非常懵逼的，因为我一点面试其他公司的准备都没做，简历都停留在实习招聘时的样子。而且刚传出这个消息的时候，我跟我导师都不太相信，导师说按照以往的经验，即便要缩减校招 hc 也是优先缩减非技术岗的，不太会影响到技术类的招聘。结果之后的风声越传越真，我导师也有点慌了，劝我先出去面试拿一个 offer 保底再说（最后的结果是我们组有三个实习生但是一个校招 hc 都没有）。我就赶紧改简历，投简历。 最坑的是当时已经过了秋招第一批内推招聘的时间点了，甚至已经错过了很多公司校招前半截的时间。甚至还出现了很搞笑的情况是，因为拥抱变化发生在校招内推之后，所以有些实习同学内推的朋友已经拿到 offer 了，而他自己的 offer 却冻结了。 腾讯 VS 创业公司懵逼归懵逼，工作还是要找的。有些公司提供了针对阿里实习生的面试绿色通道，所以快速又密集地参加了几家公司的面试。 很快就拿到了腾讯的 offer，过程回忆起来还挺简单的，基本的笔试，基础知识，项目经验，实习经验，这些都少不了，额外的就是考了一下手写快排。最后跟 hr 聊了聊就发了 offer，但是是 base 上海，所以又开始纠结，我还是想留在杭州。 这个时候阿里的导师推荐了一个创业公司，由他的前同事在之前的集团架构调整时跳出来创立的，里面基本都是前阿里员工，跟我导师关系都不错。这家公司是做智能硬件解决方案的，当时比较代表性的硬件产品是智能 SD 卡，可以自动帮你备份 SD 卡里的数据到云端（主要是图片），软件产品是云端相册（包括三端的客户端，跟现在的时光相册很像），服务端用的是阿里云，之后的业务蓝图里还涉及智能家居、图像处理、大数据存储等等。 看起来还是挺不错的，初创，待遇也还行，又有导师背书，又能在杭州工作。当时思考了一个国庆，就答应了（多少还是受到「大公司拧螺丝，创业公司锻炼人」观念的影响，当时真是 naive 啊🤦‍）。然后跟腾讯联系毁约，这里不得不说，腾讯的 HR 非常专业，流程处理的非常快，了解了一下基本情况，然后就登记完成了（估计每年跟腾讯毁约的毕业生也不少吧🤦‍）。 被毁三方之后就是几个月的浪🏄的时间，去福建、北京、西班牙🇪🇸玩了一圈。我在天津玩的时候，收到了那家创业公司 HR 的电话，我记得特别清楚，那天是 2015 年的最后一天——12 月 31 日，我跟高中同学正在吃饭。HR 通知我原本的岗位 hc 取消了，不能录用我了，公司要对我的三方进行毁约。当时完全没有处理过类似的事情，非常无奈，但是又没办法，这件事情的主动权完全掌握在公司那边，我也就只能接受。 之后就是跟家里人想对策，我妈建议我再联系腾讯试试看，看能不能把之前的 offer 再要回来。虽然觉得不可能，但是死马当活马医了，给腾讯的 HR 重新发了邮件，说明了情况，希望能重新申请当初的 offer。结果没想到 HR 很快就回复了，并且跟用人组联系之后，发现之前的 hc 还在，同意重新发 offer 给我。当时真的是高兴，同时对腾讯的好感也增加了很多。这里又不得不夸一下腾讯 HR 的专业态度跟工作效率。 之后的故事没有太多波澜，我毕业之后顺利入职了腾讯，工作至今。 结语其实 2015 年跟今年（2019）有点像，各种寒冬的论调甚嚣尘上，不仅阿里缩减了校招 hc，那年很多创业公司都濒临倒闭。 我的校招之路相当波折，但是又不能怪阿里和那家创业公司，毕竟细说起来，实习本身也就没保证能转正，三方协议本身也就是只是个协议而已。只能说自己要随时做好准备，生活的变化太快了，你只有自己随时都有准备，才能应对各种变化😁。 以上。","categories":[],"tags":[{"name":"essay","slug":"essay","permalink":"http://findingsea.github.io/tags/essay/"}]},{"title":"C++ Tips","slug":"c-tips","date":"2019-03-07T02:46:47.000Z","updated":"2020-02-22T09:30:45.924Z","comments":true,"path":"2019/03/07/c-tips/","link":"","permalink":"http://findingsea.github.io/2019/03/07/c-tips/","excerpt":"读了《C++ 的门门道道 | 技术头条》这篇文章之后有很多共鸣，可以说是近期看过的最好的技术 tips 文章了。按照这篇文章里面讲到的几点，结合工作上实际遇到的问题，我也来说一下我的感受。","text":"读了《C++ 的门门道道 | 技术头条》这篇文章之后有很多共鸣，可以说是近期看过的最好的技术 tips 文章了。按照这篇文章里面讲到的几点，结合工作上实际遇到的问题，我也来说一下我的感受。 成员变量初始化成员变量忘了初始化是一个相当经典的错误，甚至《Effective C++》中还专门列了一条来讲这个事情。在工作中，我就看到过这种错误，同事对一个新增的功能加上了开关控制的逻辑，但是忘了对这个开关的标识进行初始化，导致了一条分支逻辑失效。而且因为 C++ 没有默认初始值，那它的初始值是随机的，所以导致线上的表现是概率性复现，增加了 debug 的难度。当然增加 Coverity 扫描提早发现这个问题，当时项目上线比较急就直接跳过了这一步。 从 C++11 开始支持在声明成员变量的时候直接初始化，有了这个特性之后，我已经养成了所有成员变量都直接在声明的时候初始化。 1234class Ad &#123;private: unsinged int lifetime = 10000;&#125;; sort() 里的坑这个坑即便是有点经验的程序员也会踩到，有一次线上事故就是一个稳定跑了很久的逻辑，突然出现了 core，而且是持续地 core 在 sort 上。花了很长时间排查，最后才意识到实现新增的 sort 比较函数没有保证严格弱序（strict weak order），比较两个对象的属性时用了 &lt;=。这里就涉及到 C++ 中 sort 的实现。细节之后会写一篇文章来讲，简单说来就是 STL sort 核心排序算法是快排，在依据 pivot 调整元素位置时采用的实现方式如下： 12345678910111213while (true)&#123; while (__comp(*__first, __pivot)) ++__first; --__last; while (__comp(__pivot, *__last)) --__last; if (!(__first &lt; __last)) return __first; std::iter_swap(__first, __last); ++__first;&#125; 重点就在于 while (__comp(*__first, __pivot)) ++__first;，当整个容器里的元素都相等时，就会导致 __first 这个迭代器越界，程序就 core 了。 操作符短路原文关于如何避免操作符短路讲得很好了，其实我们还可以利用操作符短路来简化代码。对我更常用的场景：if (!stack.empty() &amp;&amp; stack.top() == 0)，这恰恰是利用短路来合并判断。 别让循环停不下来这个有个经典场景，在 vector 里面，我要找到首个递增序列的最后一个元素，很容易写成这样的代码： 1while (i &lt; ve.size() - 1 &amp;&amp; ve[i] &lt;= ve[i + 1]) i++; 这里如果传入的 ve 是个空 vector，那么就会成为超大循环，因为 vector::size() 返回的是 unsigned int，根据数值类型传递，ve.size() - 1 的类型也是 unsigned int，那么就会返回一个很大的数，导致 while 陷入超大循环。 理解 vector 的实现vector 可以说是在日常开发中使用频率最高的容器了，支持下标访问，动态扩容，二分查找的效率，C++11 之后支持移动构造，这些优点都让它非常好用。vector 的坑都集中在它的动态扩容上，理解它动态扩容的机制可以在开发中避开这些坑。 vector 动态扩容的两个特点： vector 扩容是按照 2 的指数倍往上翻的，也就是 2, 4, 8, 64, 128, ……。 动态扩容时是会全量复制一遍现有的所有元素到新分配的内存中。 根据这两个特点，结合 vector 的其他特性得到的： 尽量预先分配好 vector 的空间，使用 reserve() 预分配空间，避免多次扩容。 不要在 vector 里存储大对象，扩容的时候会全量复制，额外的性能开销很大。 不要保存指向 vector 内部对象的指针，扩容时对象地址会发生变化。 reserve() 是提前分配空间，此时不能直接用下标索引访问（如果用基本类型倒是能访问，但是这种行为仍然是未定义的）。 有时候真的不必用 std::unorder_map组里有一个项目升级到 C++11 之后，一窝蜂地使用 unordered_map，但是其实对于小数据量，比如本次请求命中的一些配置，其实数据量基本都在 10 项以内，那其实用 map 就完全够用了，unorder_map 查找的效率当然是高的，但是也要认识到它维护一个哈希表额外付出的性能代价。 慎用short，char因为一开始设计的数值类型过于严格而导致的重写，我遇到过不止一次了。 有些人写代码的时候有一种倾向，就是能省则省，能用 int 的绝不用 long，能用 short 的绝不用 int。但是其实有些情况下 short 并不能节省空间（字节对齐），还导致过度「优化」，导致逻辑变化之后要重写，或者实际的取值不符合设计导致溢出。 避免箭头型代码什么是「箭头型代码」？见下图： 这种代码其实在业务复杂的场景下并不少见，酷壳上有一篇文件专门讲过如何重构这种代码：《如何重构“箭头型”代码》。 我在实际项目中应用比较多是利用 while (0) 来规避这种代码。 在项目经常遇到的场景是对一连串条件进行判断，不符合条件的分支需要打印日志，示例代码如下： 123456789101112131415161718if (conditionA()) &#123; if (conditionB()) &#123; if (conditionC()) &#123; if (conditionD()) &#123; // do something &#125; else &#123; // log &#125; &#125; else &#123; // log &#125; &#125; else &#123; // log &#125;&#125; else &#123; // log&#125; 这种情况下用 do-while(0) 可以进行非常好的重构，重构之后的代码如下： 12345678910111213141516171819do &#123; if (!conditionA()) &#123; // log break; &#125; if (!conditionB()) &#123; // log break; &#125; if (!conditionC()) &#123; // log break; &#125; if (!conditionD()) &#123; // log break; &#125;&#125; while (0); 参考文章： 《C++ 的门门道道 | 技术头条》 《STL源码剖析》","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"http://findingsea.github.io/tags/c/"}]},{"title":"Go Protobuf 资源的可读化","slug":"Go-jsonpb","date":"2018-09-14T07:30:43.000Z","updated":"2020-02-22T09:30:45.924Z","comments":true,"path":"2018/09/14/Go-jsonpb/","link":"","permalink":"http://findingsea.github.io/2018/09/14/Go-jsonpb/","excerpt":"工作上有大量协议采用 Google Protocol Buffer，关于 Protobuf 的简单介绍可以看 IBM 的《Google Protocol Buffer 的使用和原理》这篇介绍。简单来说，Protobuf 的优点是（相比 XML）更小、更快、更简单，同时可以向后兼容。缺点的话，对我日常工作影响比较大的就是可读性较差，因为 Protobuf 压缩的时候会做序列化，生成 pb 文件，这个文件是二进制的，无法做到 human readable。但在日常工作中，尤其是排查问题是，经常需要看资源文件内容是否正确、上下游服务收发包内容是否正确、伪造 pb 资源等等，这些内容都是 pb 的，需要经过转换才能读懂，由此就用 Go 写了利用 JSON 伪造 pb 资源和反序列化 pb 打印成人类可读的文本的两段程序。","text":"工作上有大量协议采用 Google Protocol Buffer，关于 Protobuf 的简单介绍可以看 IBM 的《Google Protocol Buffer 的使用和原理》这篇介绍。简单来说，Protobuf 的优点是（相比 XML）更小、更快、更简单，同时可以向后兼容。缺点的话，对我日常工作影响比较大的就是可读性较差，因为 Protobuf 压缩的时候会做序列化，生成 pb 文件，这个文件是二进制的，无法做到 human readable。但在日常工作中，尤其是排查问题是，经常需要看资源文件内容是否正确、上下游服务收发包内容是否正确、伪造 pb 资源等等，这些内容都是 pb 的，需要经过转换才能读懂，由此就用 Go 写了利用 JSON 伪造 pb 资源和反序列化 pb 打印成人类可读的文本的两段程序。 JSON 转 pb这个感觉起来是件很麻烦的事情，但是有了 jsonpb 这个库之后，事情就变得很简单了。 首先定义 user.proto 。 12345678910111213syntax = \"proto3\";package user_info;message UserInfo &#123; message User &#123; string username = 1; uint32 age = 2; string graduate = 3; &#125; repeated User user_list = 1;&#125; 然后再转换生成 user.pb.go 文件。 1protoc --go_out=. user.proto 编写 JSON 文件，注意 key 的名字需要遵循 user.pb.go 中的名字，例如： 123456789type UserInfo struct &#123; UserList []*UserInfo_User `protobuf:\"bytes,1,rep,name=user_list,json=userList\" json:\"user_list,omitempty\"`&#125;type UserInfo_User struct &#123; Username string `protobuf:\"bytes,1,opt,name=username\" json:\"username,omitempty\"` Age uint32 `protobuf:\"varint,2,opt,name=age\" json:\"age,omitempty\"` Graduate string `protobuf:\"bytes,3,opt,name=graduate\" json:\"graduate,omitempty\"`&#125; user.pb.go 已经指定了一个 field 在 JSON 中的命名，直接按照这个编写 JSON 文件即可。 1234567891011121314&#123; \"userList\": [ &#123; \"username\": \"lawrencelin\", \"age\": 28, \"graduate\": \"Tongji University\" &#125;, &#123; \"username\": \"findingsea\", \"age\": 28, \"graduate\": \"Fudan University\" &#125; ]&#125; 编写主代码： 12345678910111213141516171819202122232425262728293031323334353637383940package mainimport ( \"github.com/golang/protobuf/proto\" \"io/ioutil\" \"os\" \"fmt\" \"github.com/golang/protobuf/jsonpb\" \"user_proto\")func main() &#123; jsonFilePath := \"/home/lawrence/GoglandProjects/JsonToPbIntro/json/user_info.json\" pbFilePath := \"/home/lawrence/GoglandProjects/JsonToPbIntro/pb/user_info.pb\" buf, err := ioutil.ReadFile(jsonFilePath) if err != nil &#123; fmt.Println(\"Read file err: \", err) os.Exit(0) &#125; userInfo := &amp;user_info.UserInfo&#123;&#125; if err = jsonpb.UnmarshalString(string(buf), userInfo); err != nil &#123; fmt.Println(\"jsonpb UnmarshalString fail: \", err) os.Exit(0) &#125; fmt.Println(\"user info pb: \", userInfo.String()) data, err := proto.Marshal(userInfo) if err != nil &#123; fmt.Println(\"proto Marshal fail: \", err) os.Exit(0) &#125; if err = ioutil.WriteFile(pbFilePath, data, os.ModePerm); err != nil &#123; fmt.Println(\"Write file err: \", err) &#125;&#125; 核心函数就是 UnmarshalString ，输入是 JSON 字符串，输出 Protobuf 对象。 1func UnmarshalString(str string, pb proto.Message) error 运行一下 main.go，就生成好了 user_info.pb 文件，打印如下： 1user info pb: user_list:&lt;username:\"lawrencelin\" age:28 graduate:\"Tongji University\" &gt; user_list:&lt;username:\"findingsea\" age:28 graduate:\"Fudan University\" &gt; 打印 Protobuf 对象这一边本来应该很简单的，因为 Protobuf 库就提供了字符串转换函数，像 C++ 版 Protobuf 直接提供了 DebugString() 方法，可以直接输出可读的打印字符串。但是 Go 里面，我直觉反应调用了一下 String() 方法，fmt.Println(&quot;user info pb: &quot;, userInfo.String())，发现只能打印成一行。 1user_list:&lt;username:\"lawrencelin\" age:28 graduate:\"Tongji University\" &gt; user_list:&lt;username:\"findingsea\" age:28 graduate:\"Fudan University\" &gt; 看了一下 String() 方法的实现，直接调用了 CompactTextString 方法： 1234567func (m *UserInfo) String() string &#123; return proto.CompactTextString(m) &#125;// CompactText writes a given protocol buffer in compact text format (one line).func CompactText(w io.Writer, pb Message) error &#123; return compactTextMarshaler.Marshal(w, pb) &#125;// CompactTextString is the same as CompactText, but returns the string directly.func CompactTextString(pb Message) string &#123; return compactTextMarshaler.Text(pb) &#125; 注释里说明了这个接口只能返回压缩过的文本，这个可读性就很差了，那如何输出可读的 Protobuf 对象呢？ 看了文档之后，发现应该使用 MarshalTextString 接口，就可以直接返回可读的文本格式 Protobuf 对象。其接口源码和注释如下： 123456// MarshalText writes a given protocol buffer in text format.// The only errors returned are from w.func MarshalText(w io.Writer, pb Message) error &#123; return defaultTextMarshaler.Marshal(w, pb) &#125;// MarshalTextString is the same as MarshalText, but returns the string directly.func MarshalTextString(pb Message) string &#123; return defaultTextMarshaler.Text(pb) &#125; 调用的方法很简单，fmt.Println(proto.MarshalTextString(userInfo))，输出： 12345678910user_list: &lt; username: \"lawrencelin\" age: 28 graduate: \"Tongji University\"&gt;user_list: &lt; username: \"findingsea\" age: 28 graduate: \"Fudan University\"&gt;","categories":[],"tags":[{"name":"Go","slug":"Go","permalink":"http://findingsea.github.io/tags/Go/"}]},{"title":"Go slice 扩容问题","slug":"go-slice","date":"2018-08-17T08:49:02.000Z","updated":"2020-02-22T09:30:45.924Z","comments":true,"path":"2018/08/17/go-slice/","link":"","permalink":"http://findingsea.github.io/2018/08/17/go-slice/","excerpt":"本文主要讨论 slice 扩容时对原数组的影响。","text":"本文主要讨论 slice 扩容时对原数组的影响。 slice 是 Go 语言中的动态数组，具体的使用方法可以参考：Go by Example: Slices。 slice 有两种创建方式，一种是直接创建，如： 1s := make([]int, 4) 另一种是从数组中创建，如： 12arr := [4]int&#123;1, 2, 3, 4&#125;s := arr[:2] 第一种是比较简单的场景，如果是从数组中分片创建的，那有一个场景是需要特殊注意的：扩容。 还是上面这段代码，先看一下它在内存里的结构是怎么样的。 slice 有三个属性字段：长度、容量和指向数组的指针。如果是直接创建的，数组则在创建时新建；如果是从数组中创建的，slice 中的数组指针就指向原数组。那么这就关系到一个问题：修改 slice 时，也会修改原数组吗？ 答案好像很显然：会！因为 slice 其实没有额外分配空间，修改 slice 的元素就是修改其数组指针指向的空间嘛，就是原数组嘛。这个答案当然是对的，但是这里有特殊情况，那么就是 slice 扩容。 这里要分两种情况： slice 扩容后，还没有触及到原数组的容量，那么 slice 中的数组指针依然指向原数组。 slice 扩容后，超过了原数组的容量，那么 Go 会开辟一块新的内存，把原数组拷贝进去，slice 中的数组指针指向新数组。 写代码验证。 1234567891011121314151617arr := [4]int&#123;0, 2, 0, 0&#125;s1 := arr[:2]s1[0] = 1fmt.Println(arr) // [1 2 0 0]s2 := append(s1, 3)fmt.Println(arr) // [1 2 3 0]s3 := append(s2, 4)fmt.Println(arr) // [1 2 3 4]s4 := append(s3, 5)fmt.Println(arr) // [1 2 3 4]s4[0] = 0fmt.Println(arr) // [1 2 3 4]fmt.Println(s4) // [0 2 3 4 5] 从代码和结果输出里就能很清晰地看到，在 slice 扩容没有超过原数组容量（也就是 4）时，所有对 slice 的操作，其实都是在原数组上原地修改的。一旦 slice 扩容超过了原数组的容量，那么 slice 指向的就是一个新数组了，对它的修改也就不会在原数组上生效了。","categories":[],"tags":[{"name":"Go","slug":"Go","permalink":"http://findingsea.github.io/tags/Go/"}]},{"title":"《纳什均衡与博弈论》","slug":"A-Beautiful-Math","date":"2017-07-02T07:57:24.000Z","updated":"2020-02-22T09:30:45.924Z","comments":true,"path":"2017/07/02/A-Beautiful-Math/","link":"","permalink":"http://findingsea.github.io/2017/07/02/A-Beautiful-Math/","excerpt":"前言本书的实际内容，和你看到书名之后的期待相去甚远。我本来想象中，书里应该会起码讲一下纳什均衡和博弈论的基本知识以及在各个领域内的应用。然而，全书一半是对博弈论历史的概述，一半是对未来应用的展望。实质性的内容偏少，连纳什均衡也是简单介绍了一下概念，然后举了两个非常基础的例子。 总体来说，是推荐度比较低的一本书。","text":"前言本书的实际内容，和你看到书名之后的期待相去甚远。我本来想象中，书里应该会起码讲一下纳什均衡和博弈论的基本知识以及在各个领域内的应用。然而，全书一半是对博弈论历史的概述，一半是对未来应用的展望。实质性的内容偏少，连纳什均衡也是简单介绍了一下概念，然后举了两个非常基础的例子。 总体来说，是推荐度比较低的一本书。 博弈论的历史博弈论最早的思想基础可以追溯到亚当·斯密和达尔文。在亚当·斯密伟大的两部著作——《国富论》与《道德情操论》——中，他提出让市场自然博弈而达到平衡和最大收益的观点。而在市场经济的自我调节中。达尔文的进化论中，物种（或者说基因）互相博弈，在进化过程中占据优势的，从而使自身得以延续。因此，在市场经济理论和进化论中，就已经包含了博弈论的雏形。 其后，冯·诺依曼正式提出并创立了博弈论。他说明了，在二人零和博弈中，总有一种办法找到最佳可能策略，这个策略能够使一个人的收益达到最大（或者说损失最小），而不用管这个得失的具体内容是什么，战略只与博弈规则和对手的选择有关。这就是冯·诺依曼最初于1926年12月提交《哥根廷数学学会》，之后于1928年在其本人的论文中充分阐述的最小最大化原理，此篇文章名为《Zur Therorie der Gesellshaftsspiele》（客厅游戏理论），也是他后续研究的基础。 冯·诺依曼的研究吸引了德国经济学家奥斯卡·摩根斯特恩，他们的共同研究最终改变了经济学的基础。 在冯·诺依曼和摩根斯特恩研究这些问题的过程中，当时的经济学权威教科书将他们的一种简单的被称为「鲁宾逊经济」的模型奉为经典，在这个模型中，鲁宾逊孤身一人流落到孤岛上，处境艰难。这种情况下，他自己就是一个经济整体：自己决定怎样使用岛上的资源，使自己的收益最大化，而一切条件完全来自于自然环境。当时，经济学被视为许多个体鲁宾逊的活动。在大型的经济生活中，消费者与价格之间相互作用，就像鲁宾逊与自然之间一样。这就是新古典主义的经济学观点。 但是，博弈论采用的是一种截然不同的理论框架，在这种框架下，一个人的利益由其他人的行为决定，你的利益由我的行为决定，这样一来，我们就不得不策略性地思考问题了。 这也正是冯·诺依曼和摩根斯特恩在1944年的著作中强调的。鲁宾逊·克鲁索经济从根本上与盖里甘岛经济不同。它不仅仅是影响你关于商品价格和服务的选择的来自他人的社会影响的综合。你的选择结果，以及获得你想得到的利益的能力，这些不可避免地都与他人的选择联系在一起。两位认为，「如果两个或更多的人相互之间交换货物，那么通常每个人的结果不仅依赖于他自己的行为，也受到其他人行为的影响」。 从数学上而言，这意味着鲁宾逊的最大利益再也不是简单的只与他自己有关，因而计算中要包括具有竞争关系的目标的混合，涉及盖里甘、船长、百万富翁和他妻子、电影明星、教授和玛丽·安（Mary Ann）的最大利益。 在社会经济中，问题不仅仅是你个人的效用，你必须考虑其他人的选择。在小规模的“盖里甘岛”经济中，纯粹的战略选择可能会被诸如部分游戏参与者之间的联合这样的因素破坏。如何解决呢？热力学理论再一次为我们提供了帮助。 温度是对分子运动快慢的衡量，总体而言，描述单个分子的速度就像计算鲁宾逊·克鲁索的效用一样简单。但是对于“盖里甘岛”，就变得很困难了，这就像热力学中，要想计算较少数目的相互作用的分子的速度实际上是不可能的。但是如果计算的是亿万以上的分子，情况又不一样了，此时分子间的相互作用趋于平均，利用热力学理论就可以对温度做出精确的预测。「参与者的数目变得尤为庞大时，」冯·诺依曼和摩根斯特恩写道，「每个参与者个体的影响就有可能可以忽略不计。」 冯·诺伊曼和摩根斯特恩以《博弈论与经济行为》一书开拓了新的数学领域，这是经济学界的路易斯安那购买条约，而纳什则扮演了路易斯和克拉克的角色。 纳什均衡可以说，冯·诺依曼和摩根斯特恩将博弈论成功应用于二人零和游戏，而纳什则使博弈论在科学世界中的广泛应用成为可能。 纳什均衡简单来说是一种策略组合，使得同一时间内每个参与人的策略是对其他参与人策略的最优反应。纳什证明了在任何博弈中，都存在着这样一个均衡点。「均衡点，」他在博士论文中写道，「意味着…在其他玩家的策略不变时，每个玩家采取的混合策略都最大化其自身收益。」换句话说，在博弈中至少存在着这样一种策略组合，如果你改变你的策略（其他任何人的策略都不改变）你会获得比之前差的结果。 纳什均衡的真正关键之处在于它将博弈论数学和物理定律进行了类比——博弈论描绘社会系统，物理定律描绘自然系统。在自然界中，每个事物都寻求稳态，也就是寻求一种能量最小的状态。岩石从山峰上滚落因为在山峰上的岩石具有巨大的势能，它滚下山释放了这种能量，这是万有引力的作用。在化学反应中，所有的原子都在寻求一种稳定的、拥有最小能量的排列，这是缘于热力学定律。 正如在化学反应中所有的原子同时在寻求一个能量最小化的状态一样，在一个经济系统中，所有人都在寻求利益最大化。一个化学反应会达到热力学定律作用所规范的均衡；一个经济系统也将达到博弈论所描述的纳什均衡。 当然，现实生活并非如此简单。经常存在着复杂的影响因素。一辆推土机可以将岩石推回山上；你可以对一些分子添加化学药品来催化新的反应。当人的因素被包含进来时，各种新的不可预见性使博弈论发挥的领域变得更加复杂（想象一下如果分子能够思考，化学反应将变得多么难以捉摸）。 然而，纳什的均衡观念却抓住了社会的一个关键特征。运用纳什的数学方法，你可以和适当情形下的博弈作比较，从而得出人们如何在一个社会情境中达到稳态。因此如果你想将博弈论应用于现实生活，你需要设定一种能体现你所关注的现实生活情境本质特征的博弈。而且，即使你不曾注意到，生活中也包含了各种各样的情境需要我们来应对。 「纳什带领社会科学走向了一个新的世界，使对各种情况下的冲突和合作的研究有了统一的分析方法。」芝加哥大学的经济学教授罗杰·迈尔森（Roger Myerson）这样写道，「纳什确立的非合作博弈理论已经发展成了一种有效衡量动机的算法，它能够帮助我们更好地了解无论在任何社会、政治或是经济背景下的冲突和合作问题的实质。」 博弈论的未来博弈论的发展不止在于其理论本身，更在于它和其他学科的结合。例如生物学和社会学。 博弈论有助于解释在动物（包括人类）世界中社交行为的进化，解开了达尔文进化论中初始的谜团：为什么动物会合作？你可能会认为，斗争的生存法则将会助长自私。然而，合作在生物世界却相当普遍，从寄生虫与寄生主体的共生关系到人们经常向陌生者展示的利他主义。如果没有如此广泛的合作，人类的文明绝不会形成；如果不理解合作是如何演变的，那么描述人类社会行为的自然法则也将不可能存在。这一理解的关键线索来自于博弈论。 类似的例子还有很多，这里不再赘述。 博弈论是在物理学的土壤中孕育出来的，因为冯·诺依曼和摩根斯特恩使用的推理都基于统计物理学。冯·诺依曼提到当描述经济系统中大量群体交互时统计是有用的。纳什推导纳什均衡时提到了反应分子的统计交互。将物理学中的平衡概念借用到化学中的分子系统，纳什衍生出一个类比的概念，即由人组成的社会系统的均衡。纳什的数学是关于人的，但它基于分子，而且这种数学将博弈论和社会科学与物理学统一了起来。 从经济学、心理学和社会学到进化生物学、人类学和神经科学。博弈论提供了一种通用的数学语言来联合这些科学，它们代表了拼图的各个块，拼在一起得到了生命、思维和文化——人类集体行为的总和。博弈论的数学也可以被转换成物理学的数学的事实表明了它是揭开万物真正原理的密钥，统一物理学和生活的科学。 毕竟物理和生命的系统都寻求稳态，或者说均衡。如果你想要预测一种化学反应的进程或人类的行为，未来会如何演化，你必须知道如何计算均衡。博弈论展示了为什么达到一个均衡点需要混合策略——以及对混合策略的需要如何驱动复杂性的创造。换言之，进化。博弈论描述了进化的过程，这种过程产生出不同物种的组合、不同类型的人的组合、不同策略的混合、不同环境下出现的不同文化的组合。 博弈论描述了产生复杂网络的进化过程。选择混合策略的大脑是神经细胞的网络；展示出多元文化的社会是大脑的网络。把它们放在一起，你得到一个用来量化自然（真正包含了万物）的框架，一个将生活和社会科学的博弈论和描述物质世界的物理学融于一体的框架。","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"《异类》","slug":"Outliers-The-Story-of-Success","date":"2017-06-12T16:23:13.000Z","updated":"2020-02-22T09:30:45.923Z","comments":true,"path":"2017/06/13/Outliers-The-Story-of-Success/","link":"","permalink":"http://findingsea.github.io/2017/06/13/Outliers-The-Story-of-Success/","excerpt":"目录 前言 机遇 马太效应 10000小时法则 天才论 比尔·乔伊、甲壳虫乐队和比尔盖茨 天才之忧 门槛效应 实践智力 文化传承 小镇哈伦 稻田与数学 玛丽塔之幸 故事来自牙买加","text":"目录 前言 机遇 马太效应 10000小时法则 天才论 比尔·乔伊、甲壳虫乐队和比尔盖茨 天才之忧 门槛效应 实践智力 文化传承 小镇哈伦 稻田与数学 玛丽塔之幸 故事来自牙买加 前言 在《异类》这本书中我想证明，个性作用并非个人成功的决定因素。成功人士并非白手起家，他们以某种形式获得家族的荫蔽和支持。那些最终变得卓尔不群的人看似完全依靠个人奋斗，其实不然。事实上，他们一直得益于某些隐蔽的先天优势，或是非凡的机缘，抑或某一文化的特殊优势；这使得他们学得快，干得多，以普通人难以企及的方式认知世界。出生的时代与地域对个体的影响巨大。而我们所处的文化背景，以及我们的祖先留传下来的东西，在我们无意识的情况下，就已限定了我们获得成功的方式。因此，只关心成功人士是什么样的人这远远不够。我们还必须探究他们从哪里来，只有这样才能明白为何某些人成功，其他人则流于平庸。 本书主要从两个方面来阐述「某些隐蔽的先天优」：机遇和文化传承。 第一部分讨论了成功所依赖的优势积累模式：何时何地出生，父母如何营生，成长环境如何决定了你在社会中是否能取得成功。 第二部分将讨论了我们从祖先那里继承而来的传统和行为模式，是否也在个人发展道路中发挥决定性作用。 生物学家讨论生物体时常涉及「生态学」：森林里最高的橡树之所以长得最高，不仅因为有一颗最优质的种子，还因为它在成长过程没有被其他大树挡住阳光，它生长的土壤深厚肥沃，它在还是幼苗的时候没碰上兔子啃树皮，它长成以后也没被砍伐。人们通常只想到杰出人士是最优质的种子，但很少想到成材还必须有充足的日照，有深厚肥沃的土壤，有足够的运气躲过兔子和伐木工人。这本书的主旨不是讨论个体的树，而是讨论整个森林。 机遇马太效应 凡是有的，还要加给他，叫他有余；没有的，连他所有的，也要夺过来。 社会学家罗伯特·默顿援引《新约·马太福音》，把一种优势不断累加的现象叫作「马太效应」。 富有者因取得了更多的减税优惠从而变得更富有；成绩优异的学生因获得了更优秀的老师的指导，更多的关注，从而取得更好的成绩。 那些获得这些特殊机遇的人（这些优势可能来自随机的运气），在最初的竞争中获得了微小的优势，但随着「马太效应」的不断累积，最终形成了人生巨大的差异。 加拿大职业冰球队，有大量球员的生日集中在年初（1~3月）。这是由于加拿大冰球训练体系的年龄划分以年初（1月1日）为分界线，教练们会从孩子（9岁到10岁）中选拨表现优异者进行重点培养。而在这个年纪（9岁到10岁）中，几个月的年龄差别就会让稍年长的孩子具有一定的竞争优势（靠近年初出生的孩子比年末出生的孩子在生理和心理上都具有一定优势），而正是这一点优势，导致年初出生的孩子具有更大概率脱颖而出，进入巡回赛小组，而被淘汰的孩子只能进入基本组。那些进入巡回赛小组的孩子，将接受到更优秀教练的指导和更好更高强度的训练，这些优势一点点累积，等他们到13岁或者14岁时，他们就「真正」变得比那些基本组的孩子「更好」了，而在一开始他们只是因为年龄稍大而在竞争中占据了优势而已。 筛选、分组和区别训练，这三种制度，导致了生日靠近「年龄分组日」的球员在竞争中获得了优势。这些小孩有更大的概率成为职业球员甚至球星，而起点可能仅仅是因为他们比别的小朋友早生了几个月。 冰球队9岁至10岁间的孩子中年纪稍大者获得了更多的指导和训练，从而变得更优秀。在社会学领域，所谓成功就是“优势积累”的结果。职业冰球队员一开始只比最初所在球队的队友好一点点，然而这微小的优势带来的机遇，扩大了他和那些队友之间的差距，随后差距与机会交替发挥作用，微小的差距被越拉越大—最终被选中的队员成了真正出众的天才。由此可以看出，天才并非一开始就表现出众，一开始他只是比别人优秀那么一点点。 10000小时法则天才论人类社会从来不缺乏对天才的争论。其中最著名的案例出现在20世纪90年代，心理学家K·安德斯·埃里克森（K. Anders Ericsson）和他的两名同事在顶尖水平的柏林音乐学院展开了研究。在该学院一些教授的配合下，他们将小提琴专业的学生分为3组。第1组由最优秀的明星学生组成，他们个个都有发展成世界级独奏家的潜质；第2组则由那些仅被认为不错的学生组成；第3组由那些将来不太可能做职业演奏家，只可能在公立学校当音乐教师的学生组成。所有这3组学生都被问及同一个问题：从首次接触小提琴至今，你练琴一共练了多少小时？ 3组学生大约都在5岁那年第一次接触小提琴。在最初几年，所有学生的练琴时间都大致相当—每周2小时至3小时。但当他们到了8岁，不同组别的学生练琴时间开始产生差别。第1组学生练习时间开始明显多于其他两组：9岁时每周练琴时间为6小时，12岁时每周8小时，14岁时每周16小时，这样随着年龄增长，他们练琴时间不断增长，到了20岁上下（这个年纪的学生已经很自觉，能够为了变得更加优秀而主动练习），他们每周练琴时间是30小时。实际上，到了20岁，这些卓越的演奏者在练琴上已经投入了10000个小时了。作为对照，第2组学生到20岁练琴时长累计为8000小时，「未来的音乐教师们」的练琴时间累计只有4000小时多一点。 埃里克森带领团队又着手研究业余组与职业组的区别，相同的情况出现了。业余组中的人在儿童时期每周练琴时间从未超过3小时，到了20岁，练琴时间累计只有2000小时；而职业组的练习时间随着年龄增长而增加，到了20岁，那些未来的演奏大师们的练琴时间已经超过10000小时。 埃里克森的研究中最引人注目的结论是： 第一，根本没有「与生俱来的天才」——花比别人少的时间就能达到比别人高的成就。 第二，也不存在「劳苦命」——一个人的努力程度比别人高却无法比别人更优秀。研究结果表明，一旦一个演奏者进入顶级音乐学校，唯一能使他出人头地的方法就是：刻苦练习。成功的要素在这个阶段变得简单明了。还有一点是，那些顶级演奏家们，他们练琴不只是比其他人更加努力，而是比其他人努力十倍，甚至百倍。 一个人在学习的过程中，要完美掌握某项复杂技能，就要一遍又一遍艰苦练习，而练习的时长必须达到一个最小临界量。事实上，研究者们就练习时长给出了一个神奇的临界量：10000小时。 神经学专家丹尼尔·利瓦廷写道： 研究发现，任何一个领域的世界级水平都需要起码10000小时的训练。随着研究不断深入，作曲家、篮球运动员、作家、滑冰运动员、钢琴家、棋手，甚至江洋大盗……无论你是什么，10000小时这个神奇数字一而再再而三地出现。当然，这并不能解释为什么有些人能从等量的训练中获得更好的效果。但可以肯定的是，目前还未发现任何一位世界级的专家在其专业领域中的训练时长少于这个数字。人的大脑好像必须花费那么长的时间消化理解，才能达到极其精通的水平。 书中举了比尔·乔伊、甲壳虫乐队和比尔·盖茨的例子。 比尔·乔伊，Sun公司的天才创始人。就读密歇根大学安娜堡分校时，该校是世界上第一批实现电脑分时系统的高等学府，在那个时期，世界上没有几个地方的计算机水平能跟密歇根大学相比。而对于这个时期进入密歇根大学的乔伊，这是一个千载难逢的机会。他并不是因为计算机才进入密歇根大学的，但是置身世界上仅有的几个还要想编程就有电脑可以用的大学中，极大激发他对计算机的兴趣，同时也保证了他能有大量时间来进行编程学习。他几乎是没日没夜地编程，而当他进入UNIX项目组时，早已满足了10000小时的练习时长，也早已成为了高水准的计算机工程师。 甲壳虫乐队。他们并不是一出道就惊艳流行音乐界，那时候他们还只是支默默无闻的高中乐队，直到他们受邀进行参与了一次「汉堡之旅」。在汉堡，他们每天表演8个小时，一周表演7天。而在1960年到1962年之间，他们5次造访汉堡，总共表演了270晚。到1964年他们最终成名前，甲壳虫乐队其实已经表演了1200场了，这是非同寻常的，很多流行乐队的整个演艺生涯都无法演出这么多场。在汉堡的超量训练使甲壳虫乐队脱颖而出。 比尔·盖茨。和乔伊一样，他本来也对计算机没有任何兴趣，同样需要一个激发点和长时间联系的机会来引导他日后的成功——这个激发点就是七年级时，他从公立学校转入了西雅图湖滨学校，在转学的第二年学校就创建了计算机俱乐部，有了专门的机房，而在当时很多大学都甚至还没有电脑。更有远见的是，学校购买的是一台电传打字机，这台终端与西雅图计算机中心相连接，并与主机分时共享。要知道分时技术1965年才发明，仅仅三年后，才上八年级的比尔盖茨就已经能通过分时系统学校电脑编程了。而接下来湖滨高中与C-Cubed的合作，盖茨在ISI和TRW的实习经历，保证了他对计算机编程产生浓厚兴趣的同时，有足够的机会和时间来练习，而这在当时并不是每个人都能享受到的条件。这些机遇保证了等到盖茨与保罗艾伦创立微软编写basic时，他早已是一个非常高水准软件开发工程师。 天才之忧门槛效应英国心理学家利亚姆·哈德森（Liam Hudson）写道： 有充足的实例证明，智商170分的人比智商70分的人的思维更加缜密，即便是分值差异小些，但只要存在差异（如100分和130分），情况就都差不多。但是，当两个人的智商都很高，这种规律就被破坏了。一个智商130分的科学家跟一个智商180分的科学家都一样可以获得诺贝尔奖。 用哈德森的话说，智商值更像篮球队中球员的身高值。身高为1.68米的人能不能进职业篮球队？这个可能性几乎没有。想进入职业球队打球，身高起码要1.83米，当然1.88米优于1.85米，1.91米优于1.88米。但是自身高超过某一高度后，身高的作用就会骤减。一个2.03米的球员并不一定会优于一个1.98米的球员。（伟大的篮球运动员迈克尔·乔丹，其身高就是1.98米。）一个篮球运动员只需要身高足够高，超过职业队的身高门槛就可以了。同样的，智力也是如此，智力门槛同样存在。 让我们对「门槛效应」这个概念进一步进行探讨。既然智力因素仅在某种程度上发挥作用，那么超越这一程度，智力发挥不了作用的时候，另外一些因素就开始发挥作用了。这又有点像打篮球：一旦你的身高足够高，人们就开始关注你的速度、球感、灵活性，以及球技和投篮准确性了。 智商对于人的职业生涯或者生活，只起到一个门槛的作用，而且这个门槛在绝大多数情况下都不是很高。 刘易斯·特曼是美国斯坦福大学的著名心理学家，其专长是测试智商。目前世界各国通用的标准智商测试，就是他发明的。从1921年开始，刘易斯·特曼就满腔热忱地把测试智商、发现天才作为自己的终身事业。在联邦基金会的大力支持下，他组织了一个团队到加利福尼亚州的中小学进行测试智商的研究。学校各班的老师首先从班级挑选出聪明的学生，然后对这些学生进行智商测试；测试成绩排在前面10%的学生，进入下一轮的智商测试；在下一轮测试成绩达到130分以上的学生，接着进入第三轮测试。 根据几次测试的筛选,最后挑选出最聪明、最有发展前途的学生。在刘易斯·特曼的亲自组织、指导下,先后对25万名中小学学生进行了智商测试,其中有1470名学生的智商在140至200之间。心理学家心目中的这些年轻天才,被人们称之为「特曼人」。 所有这一切,都被他写进了《天才基因的研究》这本厚厚的红皮书中。他自信地认为,对一个孩子的发展而言,除了道德,几乎没有什么比智商更为重要的事情了。他坚定地相信,特曼人一定是美国未来的精英群体。 但是特曼错了。他过于固执地推崇处于智力金字塔尖上的「特曼人」（1%的佼佼者中精选出来的1%），而忽略了一个事实—智力在现实中的作用并没有那么大。 等到「特曼人」成年，特曼结论的谬误性就显现出来了。这些天才少年长大后有几个后来出书，写文章，在商业方面获得成功；另外几个担任公职，其中有两个担任高等法院法官，一个担任市法院法官，还有两个在加利福尼亚州议会供职，最出色的一个在州一级政府担任高官。但是，「特曼人」之中很少有全国知名的人士。他们的收入还算可以，但并不属于高薪。他们中大多数人的职业只能算是普通，其中一个人的职业成就即便按照特曼自己的标准也算是完全失败的。这些被挑选出来的天才最终没有一个成为诺贝尔获奖得者。实际上，特曼的调查组当年也测试过两个小学生，他们后来成为诺贝尔奖得主——威廉·肖克利和路易斯·阿尔瓦雷斯。但是当时他们两个都没有被选中，因为他们的智商不够高。 社会学家皮特里姆·索罗金在一篇犀利的批评文章中写道，如果特曼当年随机选取和“特曼人”有相同背景（摒除智商因素）的学生作为观察对象的话，多年以后这些学生的成就可能跟他精挑细选出来的差不多。「没有想象力或其他天赋条件，」索罗金说，所谓的天才群体也只不过是一个有天赋的群体。」当特曼出版第4卷《天才基因的研究》时，「天才」一词几乎从他的文字中消失了。「我们发现」，特曼带着失望总结道，「智力与成就之间并不是真有那么大的关联。」 实践智力有这样一种特殊技能，它能让你说服教授把课从上午调到下午，能让你在辩解一宗谋杀案时振振有词。心理学家罗伯特·斯滕伯格（Robert Stemberg）称之为「实践智力」（Practical Intelligence）。斯滕伯格的实践智力包括「知道该向什么人说什么话，该在什么时候说，怎样说才能达到最好效果」。这种技能更像是一种程序化概念：知道如何做某事，而不需要知道为什么知道，也不需要解释为什么。 这种技能本质上是一种实践能力：这不是关于如何辩解的知识，而是帮你正确了解形势从而获得你想得到东西的知识。准确地说，这是一种与智商测试所考查的逻辑分析能力完全不同的能力。用技术术语来说，就是普通智力与实践智力「相互垂直」：一方存在不代表另一方也存在。你可能有很高的逻辑分析能力，却缺乏实践智力，也有可能有很高的实践智力却没什么逻辑分析能力，或者—如同奥本海默（书中的成功例子）一样幸运—这两种能力都很强。 实践智力从何而来呢？我们现在已经知道逻辑能力从哪儿来，逻辑能力起码一部分来自基因。兰根（书中提到的智商比爱因斯坦还高的天才）6个月开始说话，3岁自学阅读，这是天生的能力。智商测试所测量的，在某种程度上说，是天生的能力。但是，社交常识是门学问，是一系列可以习得的技能。我们获得这类技能的场所是家庭。 特曼的研究结果中，这些处于下层社会的家庭出生的天才少年，最终几乎没有一个仅依靠自己的智力获得成功。而他们最欠缺的恰恰就是这种实践智力。 在上半部分「机遇」的最后，作者举了乔·弗洛姆的例子，来说明机遇如何在各个方面影响一个人的命运。 文化传承小镇哈伦在肯塔基州东南部，阿巴拉契亚山脉延伸地带的坎伯兰高原上，有一个名叫哈伦的小城。这里地处偏僻，人烟稀少。1819年，来自不列颠群岛北部地区的8个移民家族在这里建立了哈伦县。他们的祖先在18世纪从英国移民到维吉尼亚。之后，为了开拓更多土地，他们不断向阿巴拉契亚山脉以西挺进。这个小县城一直很贫困。在建城头100年里，这里的人口很少，很多时候不足1万人。第一批移民刚到这里的时候，他们只能养猪、放羊，在山谷中辛苦维系着小片耕地。 而然哈伦能让人印象深刻的，是开辟哈伦的第一批移民中的两大家族——霍华德家族和特纳家族——之间的恩怨情仇。这两个当地古老的家族，时代仇杀，你很难想象，在19世纪的美国，这里奉行的却还是非常血腥暴力的生存法则，经常发生两个家族的混战，导致整个县城秩序大乱，死伤无数。 这是为什么呢？和睦相处就这么难吗？ 「年轻牧羊人的尊严产生于第一次争吵的关键时刻，」民族志学者J·K·坎贝尔在一篇论述希腊牧羊文明的文章中写道，「争吵必然发生在公共场合，可能在咖啡馆，也可能在广场，更可能发生在两家草场边界，一家的牲畜跑到另一家的地盘被人骂被人打的时候，暴力回应便不可避免。」 在英国，这些边陲地区都是天高皇帝远的穷乡僻壤，数百年来争端就没有消停过，当地人一直生活在暴力冲突之中。这些牧羊人竭尽山地所产，在贫瘠的土地上艰难维生。在这样的地方，家族成员紧密团结，应对外部世界的粗鲁与混乱，他们逐渐形成了无条件以鲜血捍卫忠诚的品性。当这些移民来到北美，进入美国那些同样偏远的、不受政府法律管辖的山区或土地肥沃的边界地区—如同哈伦县那样的地方，他们就将旧世界的荣誉文化完好无损地移植到了新世界当中。 文化传承是事件背后更强大的力量，它植入人性，影响长存。经过数代传承，即便产生文化的经济、社会和人口等条件已经消失，这种文化也会一直完好无损留传下来。文化直接决定了我们看待世界的方法和行为模式，其作用如此巨大，以至于没有它，我们将无法认知世界。 稻田与数学看看下面这串数字：4，8，5，3，9，7，6。大声读出来。现在放下书本，花20秒时间记忆一下，然后把数字按正确顺序背出来。 如果你说英语，你只有50%的可能在20秒内记住这串数字。但如果你是中国人，你正确记住数字的可能性几乎是100%。为什么呢？因为人类大脑存储数字的记忆周期是2秒钟，也就是说人们可以很容易记住两秒钟内读完的东西。以中文为母语的人之所以能够很容易记住「4，8，5，3，9，7，6」这串数字，原因是他们的语言系统在两秒钟内就能读出这7个数字。而英语则不行。 作为对照，亚洲学生对数学就不会感觉那么迷惑。他们凭脑子可以记住更多数字，做算术速度也更快。他们的语言对分数的表达就体现了分数的本质—这一切都有可能使他们更倾向于喜欢数学，正是因此，他们在上数学课或做家庭作业的时候就会更努力一点。这样他们就进入了一个良性循环。 中国还有个说法叫作「一年忙到头，吃穿不用愁」。「一年忙到头」？对于悠闲自得采集蒙果果的土著人，或是依靠睡觉过冬的法国农民，或是任何生活在非稻田文明地区的人们来说，这样的谚语真是莫名其妙。 很显然，努力工作的精神品质在亚洲人身上很常见。在西方的各大名校，亚洲学生总被认为是最后离开图书馆的人。他们有时甚至因为这种看法而备感冒犯，因为他们觉得这种模式化的标签是某种轻视的表现。然而亚洲学生依旧视努力工作为美德。 事实上，本书所涉及的成功案例均是那些比同辈更加努力工作的个人和团体。比尔·盖茨还是孩子的时候就沉迷于电脑，比尔·乔伊也一样。甲壳虫乐队花了数千小时在汉堡练习演出，而弗洛姆在机会降临之前，已经在不入流的并购诉讼生意上打拼多年。努力工作是所有成功人士的共性，而稻田中产生的文明的精华是，通过努力工作，在巨大的不确定性和贫穷中寻找人生的真正价值。 这种观念——休息问题影响工作成绩——自然跟亚洲的关于学习和工作的理念不同。亚洲人的这种世界观形成于稻田之间。珠江三角洲的农民每年种植两季甚至三季水稻，休耕时间很短。事实上，稻米的营养成分主要得益于水的灌溉，所以人们耕种的次数越多，收割的粮食也越多。但是西方农业却恰恰相反。无论是麦田还是玉米地，每隔几年必须休耕，否则土地很快会贫瘠。每年冬天都有一些土地需要休耕，而休耕就会减缓春种秋收的节奏。据此，教育改革者对学童大脑耕耘的方式就容易理解了。在建立教育规范的时候，人们通常遵循与此类似的其他规范，而他们只知道小麦的种植需要休耕。所以，头脑即便需要耕耘，也不应过量，否则就会贫瘠。如何避免大脑贫瘠？那就是将暑假假期延长——这项美国特色的文化遗产对美国学生的学习方式影响深远，直至今日。 忽然之间，亚洲人在数学方面拥有优势的根本原因浮出水面。在亚洲，学校的暑假并没有那么长。为什么？因为，凡是崇尚勤奋取得成功的文明，都不会让学童随随便便放3个月那么长的暑假。美国学生每年在校时间平均为180天，而韩国是220天，日本则是243天。 事实上，富裕家庭孩子与贫穷家庭孩子的差距主要是在非在校时间内形成的。 小威廉成绩的提高依靠的就是增加学习时间，假如巴尔的摩所有的小学生也增加学习时间一年，会跟他一样提高成绩。另外第2个表还说明，学生无论贫富，经过同等努力，成绩提高的幅度是一样的。 玛丽塔之幸约翰·霍普金斯大学社会学家卡尔·亚历山大。亚历山大针对巴尔的摩市650名公立小学学生，从一年级开始进行数学与阅读技能的「加利福尼亚测试」，然后随年级增长追踪成绩变化。以下是小学一年级至五年级学生阅读成绩表，按家庭经济状况分——高、中、低收入家庭。 学生一年级入学时，依家庭经济状况不同，他们的知识与能力差别明显。富裕家庭的孩子比贫穷家庭的孩子得分平均高出32点—顺便说一句，巴尔的摩贫困家庭一年级学生的经济状况的确很差。再来看第5列，也就是学生在五年级时的成绩。经过4年的学习，穷人家的孩子与富人家的孩子成绩差距开始成倍扩大。 这种「成绩差异」现象并非偶然，而是被反复观察确定的。对这一现象的解释可能会令某些人不快。第一种解释是，贫穷家庭的孩子没有富裕家庭的孩子学习能力强，因为他们不够聪明；第二种解释—也许比第一种乐观些—我们的学校教育使差学生变得更差：学校没有提供足够的教育。 巴尔的摩市的学校并没有在学年结束的6月让学生进行加利福尼亚测试，但他们在暑假过完，开学后的9月对学生进行测试。亚历山大认为校方举行的第二次考试可以帮助他进行附加分析。他可以比较学生开学时和期末时的成绩，以此精确掌握学生在学年内的成绩变化情况。假如他比较上一学年期末和下一学年开学的成绩，他就可以测算出学生暑假的学习情况。换句话说，他可以——起码是部分地——了解各类学生一个学年内产生了怎样的成绩差异，一个暑假里又产生了怎样的成绩差异。 下表展示的是当年9月开学到来年6月放假前，学生考试成绩增幅情况。其中总计列是小学5年的成绩增幅累计。 第2个表格显示的情况跟第1个表格截然不同。第1个表似乎在表示低收入家庭的孩子在学校教育中落后了，但是第2个表说明事实并非如此。看一下总计栏，低收入家庭学生小学5年成绩累计增长量是189，比富裕家庭孩子的184还高出5个点，他们只是比中产阶级家庭的孩子低。而在小学二年级的时候，低收入家庭的孩子比其他两类孩子的得分都高。 第3个表格显示的是暑假期间学生阅读成绩的变化情况： 看出问题所在了么？我们看看第1列，即小学一年级学生暑假过后的情况。富裕家庭的孩子9月回到学校时，他们的阅读成绩提高了15点；而同期贫困家庭的孩子阅读成绩下降了近4个点。穷人家的孩子在学期中有可能比富裕家庭的孩子学得多，但在暑假期间，他们却大大落后了。 再看这个表格的总计列，即暑假期间的得分总计。穷人家的孩子阅读成绩只增加了0.26。也就是说，在阅读方面，只要没开学，穷人家的孩子就没有任何长进。而富人家的孩子暑假期间阅读成绩跃升了52.49点。 事实上，富裕家庭孩子与贫穷家庭孩子的差距主要是在非在校时间内形成的。 20世纪90年代中期，试验性公立学校KIPP学园项目在纽约卢·贾里格初级中学宣布启动。KIPP学园是个教育项目，它的出现旨在对上述教育问题进行改革，给很多贫穷家庭的孩子提供改变命运的机会。学园采取大班授课的模式：五年级的两个班，每班有35名学生。KIPP的学生入学不需要考试，而是从布朗克斯区适龄四年级学生中随机抽选。学生中有一半是非洲裔美国人；其余的是西班牙裔。这里有3/4的学生来自单亲家庭，有90%的孩子符合学校的「免费午餐」计划——也就是说这些学生家庭的收入很低，需要联邦政府负担孩子的午餐费用。 而KIPP学园最有名的就是超长的学习时间。以下是一个12岁女孩玛丽塔在KIPP学园的一天。 早晨5点45分起床是一天的好开端，”她说，“起床后，刷牙，洗澡。如果起得晚点儿我会在学校吃早餐。因为我吃饭时间长，我经常被老师提醒。我在公交车站会与好友狄安娜和史蒂芬会合，我们通常能坐上第一班车。我下午5点放学。如果在路上没耽误时间，我5点半就会回到家。我跟妈妈简单打声招呼就开始做作业。如果作业不多的话，我做作业会用2小时到3小时，晚上9点左右做完。如果作业里还有篇论文，我可能要做到10点，10点半也试过。妈妈经常打断我做作业，叫我吃饭。我总想做完再吃，但她说要先吃饭。吃饭一般在8点左右，吃半个小时，然后我继续做作业。有时等我完成作业，妈妈还想跟我聊聊学校里的事。我通常只能跟她简单说说，因为我想赶在11点前睡觉。睡前我会把第二天的书包准备好，然后上床。我跟妈妈谈论着白天学校发生的事儿，说不了多久，她就迷迷糊糊快睡着了，这时候一般是11点15分。我也很快就睡着了。第二天，所有这一切就重来。我们生活在同一个房间。但是我们的房间很大，可以分成两个空间。我们在房间的两头有两张床，我跟妈妈总是无话不说。 玛丽塔的生活并不是一个普通12岁女孩应有的生活，也不是我们传统理念所希望的状态。但是对玛丽塔来说，原有的生活环境给予她的品性不足以匹配新环境——即周末和暑假与中产阶级和富裕家庭的孩子一同补课，使自己的成绩大大提高。她的生活圈子没有给足她这些便利。那么，她该怎么办？她只能放弃每天晚上和周末的娱乐，放弃与朋友在一起—这些都是她原先生活圈子的基本要素——回到KIPP加课。 这对孩子来说要求太高了么？的确太高。但是请想一想，玛丽塔因为上了KIPP学园，她的前途有了多么大的改变。玛丽塔与KIPP达成了一项「交易」——玛丽塔必须每天早晨5点45分起床，周六上课，晚上做作业到11点。作为交换，KIPP承诺给予这些身陷贫困的孩子摆脱贫困的机会。KIPP的学生中会有84%的人数学成绩居于同年级平均水平之上，90%的学生毕业后会考取私立或教区高中，而不是布朗克斯区那些教学质量差的高中。高中毕业后，又有80%的KIPP学生最终考取大学。这些孩子很多都是家里的第一个大学生。 故事来自牙买加作者举了一个自己的例子。从基于和文化两个方面，讲述了自己的家族如何从一个牙买加贫困家庭开始，一步步改善生活，甚至改变命运。 总的来说，这是非常有趣的一本书。作者用大量的数据佐证个性作用并非成功的决定因素，非凡的机遇和特殊的文化传承，才是某些人得以在竞争中脱颖而出的关键。而这些先天优势往往被掩盖在个人成功的光环之下。 讨论原文作为结尾： 对于母亲的成功，将其归结为个人奋斗战胜了固有社会身份更容易被传统所理解。这正如乔·弗洛姆的成功——他可谓史上最伟大律师—因为以他的种族，在他所处的时代，他所做出的个人努力是非凡的。他没有出生在律政世家而是服装厂工人家庭，然而这样的身世依然为他提供了独特优势，他凭借这一优势最终战胜了「白鞋」律师公司所代表的社会不公。比尔·盖茨本可以安心接受天才的称号，没必要在回顾人生历程的时候表现出谦卑：「是的，我是幸运的。」他之所以如此回答是因为他明白自己的成功的确因为幸运：没有湖滨学校电脑俱乐部在1968年为他提供电脑，就没有他今天的成就。无论是冰球运动员，比尔·乔伊，罗伯特·奥本海默还是任何意义上的超常之辈，都无法目空一切地说：「我的成就完全依靠我自己。」他们都是历史与环境的产物，是机遇与积累的结晶。超级律师、数学天才和软件企业家的成功依靠的也是人类的一般经验，他们的成就绝非石破天惊也非神秘莫测。他们处在优势与文化传承的网络中央，有些是与生俱来的，有些则是后天养成；有些是自己争取的，有些则仅仅是因为运气—但所有这一切都是他们成功不可分割的一部分。说到底，所谓「异类」从来就不是什么异类。","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"《东京本屋》","slug":"9787208139008","date":"2017-06-12T16:06:13.000Z","updated":"2020-02-22T09:30:45.923Z","comments":true,"path":"2017/06/13/9787208139008/","link":"","permalink":"http://findingsea.github.io/2017/06/13/9787208139008/","excerpt":"COW BOOKS吉井：那 COW BOOKS 在售的外文书多吗？ 松浦：大部分是日文书。外国顾客主要是来买这些日文书，不过也有一些是出于对 COW BOOKS 的好奇面来的。这挺难得的，大老远来看这么小地方。如果只是想买书，在网络上买就好。所以来店的顾客不只是为了买书， COW BOOKS 也不仅仅是一个卖书的地方。有人可能想看看这里的店员是怎么样工作服务的，或者说想知道 COW BOOKS 想向顾客传达什么，这样人们才会过来。","text":"COW BOOKS吉井：那 COW BOOKS 在售的外文书多吗？ 松浦：大部分是日文书。外国顾客主要是来买这些日文书，不过也有一些是出于对 COW BOOKS 的好奇面来的。这挺难得的，大老远来看这么小地方。如果只是想买书，在网络上买就好。所以来店的顾客不只是为了买书， COW BOOKS 也不仅仅是一个卖书的地方。有人可能想看看这里的店员是怎么样工作服务的，或者说想知道 COW BOOKS 想向顾客传达什么，这样人们才会过来。 媒体介绍 COW BOOKS 时，常说是一家「二手书店（古本屋）」，这个理解没有错，但我个人的感觉是 COW BOOKS 就是一家普通的书店，更进一步地说，像鱼店、肉铺、花店一样的「个人商店」，这种店是老板在凌晨时刻到市场，用自己的眼睛选择东西并进货，回到自己的店，经自己的手卖给客人。因为老板自已选料，所以客人问他这个蔬菜是哪里生产的、这条鱼应该怎么处理，他都能轻松回答 COW BOOKS 也一样，我们自己看过，面且对内容有相当的认可，才会放在书架上。书的种类也没有特别固定，若要说的话……就是「松浦弥太郎」类 今野书店吉井：西获窪已经有不少年轻人开的「Book＆Cafe」，这些点和贵店会不会形成竞争关系？ 今野：这倒不会，可以说完全没有。他们的经营模式一般来说是二手书＋咖啡，经营的种类和我们新刊又不一样。我觉得他们和我们的店是可以共存共荣的，一批年轻人去那些「Book＆Cafe」，翻阅一些书，把看书这事儿养成习惯后，就有望成为一批读书人。那么，那些人还是会到我们店买些书呀，我觉得这是有可能的 西获窪是很有意思的地方，离吉祥寺只有一站距离，但这里的生活成本没有吉祥寺高。来往JR中央线沿线、去东京繁华区或神保町等地方也都很方便，所以不少作者和出版界人士住在西获窗。也许是因为这个原因，我们店的人文、文艺类的图书卖得相当不错，而且大家偏爱购买单行本，这点和其他书店情况不太一样。若是一般小书店文库本的销量应该是单行本的两倍，毕竟文库本比较便宜嘛。而在我们店，单行本跟文库本的销量几乎持平，这意味着，我们的客人喜欢购买新鲜的、当红的作品，为自己喜欢或感兴趣的书，很愿意掏腰包。所以对我们店来说，新刊是生命线，新刊出来就一定要进货。这点我是很在意的。 说到竟争，对我来说，最大的威胁是来自亚马逊等网络书店和图书馆。日本的图书价格是由“再贩制度”来保持“定价销售”的状态书是不能打折的。但亚马逊提供了免费送货以及积分等服务，这些等于变相打折。我个人认为，这样的竞争对一个小书店来说，还是带来了一定的影响面对亚马逊等网络书店的冲击，我们实体书店的长处何在？我认为，首先是实体书拿在手里的感觉。大家购买之前，在书店里能看到实体书，并翻阅浏览。你来的时候也许没买到本来要买的，但实体书店还能提供机会让大家遇到之前并不知道的作者和书。第二个好处在于交流一和店员的交流，听听他们的推荐，这些实体书店才会有的交流和这种温暖。我们店也确实有一批常客，他们说“买书还是得在今野桑那里买”，我也会好好珍惜同这些客人的交流。另外，还是得说一下图书馆，我个人很反对他们的“复本”＂。现在的图书馆过于重视利用人数和借阅量，为了吸引更多的周边居民而购买不少所谓的畅销书，像畅销书《火花》（２０１５年，文艺春秋）”有的公立图书馆甚至有９０册复本。我反对的原因有两个：第一，这对作者没有任何好处；第二，图书馆的存在意义不是给大家看畅销书。一般读者在普通书店买不到的专业书或资料，才是图书馆值得备藏的。 Books Fuji不过，做生意方面还是容易产生些矛盾的。我们店的所在地属于大田区，过去是东京的工业重镇，现在还有几千个小工厂生产世界顶尖而且有的产品。我朋友是这里一家工厂的厂长，目前和几家中国公司合作。他会跟我抱怨，中国公司让他做样品，若中方喜欢样品就会要求把所有信息包括设计图统统提供给他们。也就是说，做好样品就拜拜了这真不像话。但我朋友说，和中国公司合作，经常发生这种事儿。 所以我认为，个人对个人，没什么1司题。一旦要谈钱，就会出问题。(笑)现在很多中国人来日本爆买。买东西是可以的，但我希望他们买西的同时，能够感觉到为什么日本商品做得好，这个背后的理念。比如，日本的电子商品很好用，也很方便，这是设计师站在消费者的立场绞脑汁想出来的结果；日本的商品很耐用，这是制造方站在买方的立场想。买了没多久就坏掉，肯定不舒服。。而中国的制造方，最基本的想法就不一样，看到好东西就要模仿、要设计图，跟日方说。以后我们自己来，谢谢。。 我刚跟你说过，喜欢看非虚构的书。前一阵子看了本田宗一郎、松下幸之助他们的书，我看，那些人的心底是蛮感性的。他们做一个东西，原动力就是梦想或理想。不管是汽车还是书，实体性的商品是经过很多人的手而生产的，和很多人有关系，这等于说，这商品包含了很多人的心意。 所以，外国人在日本买东西的时候，希望大家能够感受到日本人心底的这些想法。他们是付钱买东西，这也很正常，可能你觉得我太罗嗦，但我还是希望他们能够感受到这种日本人的生活和精神。 森冈书店吉井：您2015年开的森冈书店(银座)，每天都有各国顾客慕名而来。我很想多了解一些。本周的一本。这个概念诞生的过程。 森冈：是从原来的茅场町店的经验里萌生的。在那里的十年中，每年有几次举办新刊纪念活动的机会。这些活动当中，我遇到不少客人就是为了这本新刊而过来。就是为了一本书从远方花时间到我的店。累积同样的经验后，我开始相信作为一家书店，卖的书哪怕只有一本也行，是可以开下去的。 有一次，办了关于鸟类摄影集的出版纪念会，我对动物了解不多，所以这方面一直没有什么很深的理解，在展览过程中才发现喜欢小鸟的人真多!他们散发的热情和热量让我大为震惊。最吸引人的是作者和读者的沟通和对话。这样的沟通，给读者和作者的双方都会带来意想不到的收益。作者从读者的一句话得到灵感，或许在展期中就和别人谈起下一次作品的出版方案。这样的场所能发出一种。幸福感。。所以我一直想，若有机会再办一家书店，它的重点要放在这种交流上。 BACH吉井：书的种类实在太多，每天都有新刊。这种情况，我们很容易把自己出手的范围控制下来，只愿意翻阅自己熟悉的东西。就像乒搜索一样，网上信息太多，看上去什么都能搜索出来，但实际上我们自己能观照到的信息，还是限于自己比较熟悉的范围。 幅：是的。而且现在网络的方便性，导致大家更加要求「效力」。现在畅销的大部分书，就是给大家提供快速解答的。什么「让你一个月减五公斤」、「按照这个习惯生活你能达到幸福」之类的。大家看这种答案和书的定价，加上读这本书所需的时间来算一算：这本书1000日元，大概花两个小时能看完······好的，买吧。可是，书本不是这样的东西。看书的最大收获不是你获得某种答案，而是在你里产生一个疑问。产生疑问的过程才能让你心里充满喜悦。从这个度来看，书是一种工具，是一把钥匙，让你思考。是让你不停地思一辈子的伙伴。它的价值绝不能用那种效率来计算的。 吉井：所以您是倾向于同时读几本书的。并读。派，而不是。精读派? 幅：看情况吧，一般情况下。我会一口气买下几本书，看看这本又看那本。看书的心情每天都不一样，就像你的身体情况，你今天很想吃肉，但明天也许有点感冒，就想吃清淡点的东西，嫩豆腐上撒点葱末，加生姜那种。今天也许你很会看重量级大作家的书，但明天没心情，那就看漫画也挺好的。 本屋B&amp;B吉井：对您来说，值得卖给客人的书，会是什么祥子的呢? 内沼：就像我刚刚跟你说的，现在日本每年有八万种新刊出来。市场上的书还不止这些，加上过去出版的书，这数量是挺可怕的。很遗憾，这么多的书当中有一部分不是特别理想，做得不够细心。我选书的时候，会比较注意书的内容和领域的多样性，不能有太大的偏向。因为我想通过B&amp;B让大家认识到世界有多大，多么不一样。本屋B&amp;B的面积是大约30坪，但你逛一圈就能感觉到这里和外面的庞大世界是有一种通道的。这是书和书店有意思的地方，只有30页的书告诉你的世界，不一定比1000页的书拥有的世界小。B&amp;B除了新刊和杂志外，还有不少zine和个人出版的little press，其销量一直在上升。大家来B&amp;B,多多少少也就是为了找到新的东西和以前不知道的世界。我经常和大家说，好的书店，就是能够让毫无目的地进来的人买书的店。 BOOK TRUCK三田：我也和朋友讨论过，为什么早餐这么流行，我认为，主要因是经济不景气，你想想，晚上出去喝几杯酒，跟早上去吃好一点东西，那个比较划算?晚上的活动花钱多，早上出来活动可以省钱的。 我是1982年出生的，所以大概初中二年级，不，大概小学年级的时候，日本的泡沫经济崩溃了。经济快速发展的时候流行的《ELLE DECO》风格，比如意大利名牌的家居呀，专业设计师细心出来的、时装方可搭配的风格，这些后来几乎都被淘汰了。现在，我们喜欢的是更亲近生活的氛围。(拿起手边的生活杂志《Apartamento》）你看，这就是现在的时尚杂志，看起来很轻松、舒服、不做作，丑就是现在的风格。料理也是，过去的时尚意味着出去发现好餐厅，享受受美味菜肴的同时必须穿得好看、有风格。现在大家开始在家自己做饭，买些好一点的调料，按照自己喜欢的方式慢慢做菜，这是现在时尚。 吉井：中国媒体也很快就学到了这点，现在他们的杂志、网媒中也都是这种生活化的文字和图片。可能这种风格的内容给人感觉确实亲近，马上能应用到自己的生活里。 三田：但我身边的设计界的朋友说，这种风格最难模仿，因为几乎没有绝对的标准。比如，名牌那些东西，有几种必备就好，媒体会告诉你手提包要买哪一种，家居要从哪里买。但不做作的风格时尚呢，你自己生活和文化的累积就很重要。 没有了绝对的标准后，我们依据什么因素来选购才好?这就得靠自己的感觉。有时候，就是因为一些小东西，我们的生活变得很特别那么决定这个小东西的特别性是什么呢？就是自己。 后记，本屋桑巡礼日本人对书店有两种称呼，「书店(shoten)」和「本屋(honya)」。前者比较书面，后者则偏口语，带着一种亲切感，我们通常会在「本屋」面加上一个「桑」。我小时候，没事儿就老往离家不远的小书店跑。母亲听到门口穿鞋的动静，问我去哪儿，我总回答「去本屋桑」。 随着年龄的增长，我慢慢远离了家门口的「本屋桑」。喜去更大的书店买书，开始相信选择要越多越好，书要越新越好哪怕买同一本女性杂志，也觉得用大书店的纸袋装着显得洋气站前小店的黑色塑料袋（烫金印着Happy Day和几颗星星）很土。自己想看小说，又舍不得几千日元，就跑去图书馆一口气借上十本……然而有一天，发现不起眼的小书店忽然消失时我却会一脸遗憾道「可惜了，我还蛮喜欢它的呢」。 在一次次的采访中，我越发感觉到「本屋桑」们正绞尽脑汁做着各种尝试努力。如果还是被淘汰了的话，那么让这些小店关门大吉的，可能并非网络或连锁书店，而是你我这样的普通读者。在此我带着反省之心呼吁：小书店是要当地人来培养和支持的，否则书店消失时，你我连感慨的资格都没有。","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"《哲学家们都干了些什么》","slug":"9787550242234","date":"2017-06-12T16:02:14.000Z","updated":"2020-02-22T09:30:45.923Z","comments":true,"path":"2017/06/13/9787550242234/","link":"","permalink":"http://findingsea.github.io/2017/06/13/9787550242234/","excerpt":"《哲学家们都干了些什么》是一本讲述哲学史的书，语言相当通俗幽默，作者是想要最生趣易懂的方式讲述哲学的历史和理论。本篇笔记以作者讲述哲学史上的大事件为标志来展开。","text":"《哲学家们都干了些什么》是一本讲述哲学史的书，语言相当通俗幽默，作者是想要最生趣易懂的方式讲述哲学的历史和理论。本篇笔记以作者讲述哲学史上的大事件为标志来展开。 宗教与哲学。哲学起源于古希腊，苏格拉底、柏拉图、亚里士多德，伴随着这些名字的是哲学的上古辉煌。当哲学经历了古希腊和古罗马前期的发展，它遇到另一股难以共存的强大势力——宗教。宗教和哲学是存在本质上的矛盾的，宗教要求信仰，哲学要求怀疑。当宗教非常强大时——中世纪欧洲的基督教——所有学科理论都要为宗教服务，哲学也不例外。 基督教在传播初期，就利用了大量的哲学思想来完善自身理论，甚至使徒保罗本身就拥有非常深厚的哲学功底，将哲学的思维应用到传教中，撰写了大量神学文章，这些后来被称为《保罗书信》，是《新约》的重要组成部分。在哲学史上这被称为「教父哲学」。然而，这种依附在宗教下的哲学，始终只能是工具和宣传的幌子。到了基督教当道的时代，所有和教义不符的哲学著作成批地被销毁，即便这时的哲学已经具有很浓重的基督教色彩，也难逃魔爪，雅典的柏拉图学院被关闭，希腊哲学家被驱逐，希腊哲学在欧洲几乎失传。大批哲学家逃难到罗马帝国边界，最后反倒通过阿拉伯学者和伊斯兰文明保存下来，并随着阿拉伯帝国的扩张，重返欧洲。 希腊哲学最后得以保存也是经历了非常曲折的一条路：首先，是希腊哲学家被基督徒驱逐，来到叙利亚。在这里，希腊著作从拉丁文被翻译成叙利亚文。然后是“百年翻译运动”，阿拉伯学者把希腊著作从叙利亚文翻译成了阿拉伯文。然后希腊哲学到了西班牙，其中有的神父不懂阿拉伯文，就请人把希腊著作从阿拉伯文译为西班牙文，他再从西班牙文译成拉丁文。所以那时的希腊著作是从最早的拉丁文翻译成叙利亚文，再翻译成阿拉伯文，再到西班牙文，再到拉丁文。 经院哲学家。哲学在外面绕了一圈之后，终于回到了欧洲。基督教的神学家们，为了维护自己教派的观点，又用哲学武装起了自己，他们意识到希腊哲学的价值，千方百计地从东方获取希腊文献。到1260年，亚里士多德的著作成为了每个教会学校的必修课。此时的哲学被称为「经院哲学」。 「经院哲学」的最重要目标就是证明：上帝是存在的。举其中一例： 世上万事万物都要有另一个事物作为它的原因。那么必然有存在一个最初的原因，这个原因就是上帝。 这个证明（在当时）的精彩之处在于：它完全靠推理，而不是神学逻辑来证明上帝的存在。这样摆脱了仅仅无条件要你相信教义的粗浅说辞。但是显然，这个证明是有漏洞的。既然万事万物都有一个存在的原因，那么上帝存在的原因是什么？如果上帝的存在还要有自己的原因，如果上帝的存在还要依赖另一个事物，那么上帝就不是基督教所说的「全知全能」；如果上帝的存在不需要原因，那么「世上万事万物都要有另一个事物作为它的原因」就不成立。大量的经院哲学都经不起这种反驳。 经院哲学家想用哲学去证明宗教的想法是好的，为的是让宗教也能符合理性的思考。但是用哲学证明宗教，本身就有一个致命弱点，那就是怀疑是总教的核心精神，而宗教的本质是要求人们无条件地相信。当神学家试图证明上帝存在时，不也就意味着上帝有可能不存在吗？按照基督教的教义，教徒不能质疑上帝的存在，那么可以说，当神学家把哲学引入到神学的那一刻起，他们就已经开始背离自己的信仰了。 造纸术与宗教改革。中世纪罗马教会对人们思想的绝对控制，建立在他们垄断了经文教义的传播媒介，拥有对教义的绝对解释权。古登堡改良的造纸术，让原先被教会垄断的经文和教义也能被普通百姓阅读到，马丁路德的宗教改革，将对经文的解释权从教会手里剥离出来，大大削弱了教会的权威和力量。思辨和理性主义的崛起，终于让哲学走出了宗教的阴影，开始真正的发展。 我思故我在。讲理性主义之前，不得不先提笛卡尔。这句话原本是用来回答一个难住了很多哲学家的问题：明明知道我所生活的、所感受的这个世界无比真实，但是，到底怎么能严格地去证明它是真实的呢？笛卡尔的回答是：不管我再怎么怀疑这个世界是否真实，「我怀疑」这件事是确定的，它肯定存在吧？那么，只要有了怀疑的念头，就说明「我」肯定是存在的——“我”要是不存在就不会有这些念头了。这句话包含了一层意思：意识的存在。以此为基础，笛卡尔开始建立的「理性主义」哲学流派，让哲学摆脱了稚嫩期，进入健壮发展期。 这句话虽然很有名，但是经常被误读。有的人以为，这话的意思是“我存在是因为我思考”，更有人引申为“人生意义就是去思考，不思考人就无所谓存在不存在了”。这些解释都是错的。 「我思」和「我在」不是因果关系，而是推理演绎的关系。即：从前者为真可以推导出后者为真。也就是从「我思」为真，可以推导出「我在」为真。而不是说「我不思」的时候就「我不在」了，在不在我们不知道。 理性主义。笛卡尔从欧式几何的推导中受到启发，将其应用自己的哲学体系中：以一些不言自明的公设为前提，以推理和演绎的方式来推导出整个哲学世界来。往后这种以公设为前提，以数学逻辑推导为证明手段的哲学派被称为「理性主义」。 形而上学。「形而上学」这个词英文是metaphysics。在古希腊，亚里士多德是个百科全书式的学者，他写过很多的著作，从哲学到物理学，涉及了很多学科。但是那个时候没有现代学术界「哲学」「物理学」这样的分科。对于这些著作该怎么分类、命名呢？ 一个叫安德罗尼柯的人想了一个好办法。他用「研究有形体的事物」和「研究没有形体的事物」，把亚里士多德的著作分成了两大类。前一类著作编在一起，起名叫《物理学》。后一类作品，也就是亚里士多德的哲学作品，也编在一起，放在《物理学》的后面。当时没有合适的名字称呼，就给起了一个名叫metaphysics，意思是「物理学之后」。 安德罗尼柯起这个metaphysics的原本目的，应该是他没有现成的词汇可用，于是就说这部分著作是「编排在《物理学》之后的内容」。但这个词的含义也可以引申成「物理学之后的学问」。也就是说，形而上学研究的是那些高于物理学的、看不见、摸不着的学问。这就是“形而上学”这个词最早的来历。 「形而上学」的中文译名也很棒，称得上是中文翻译史上最棒的译名之一。典出《易经》:「形而上者谓之道，形而下者谓之器。 《易经》的这句话很精彩，也很好理解。「形」，就是有外形、可以触摸、可以感知的东西。「道」，就是「道理」的「道」，指的是「道理」「概念」这些抽象的东西。老子说「大道无形」，就是这个意思。「器」是「器具」，就是指「东西」「物质」。《易经》的这句话，和安德罗尼柯的思路是一模一样的。《易经》的「道」，对应的就是安德罗尼柯的metaphysics。《易经》的「器」，对应的就是安德罗尼柯的「物理学」。 日本哲学家井上哲次郎先生在看到metaphysics这个词后，联想到《易经》，把metaphysics翻译成了「形而上学」。 二元论。从笛卡尔对「意识」的理解上可以发展出：世界分成两个部分，一个是我们自己的心灵，一个是心灵之外的部分。心灵一个元，外界一个元，一共二元。这两个元是相互独立的、平等的，虽然可以互相影响，但谁也不能完全决定另一个。这可以说哲学史上第一个非常有影响力的结论。因为世界分成了二元了，那这二元之间如何联系的，就成了大问题。往后的数百年，无数哲学家都在「精神世界如何才能真实反正客观世界」上花费了大量的功夫，却也难以得到令人满意的答案。 反对二元论的学派中就有我们熟悉的唯物主义，说世界的本质是物质的，我们的精神世界不过是大脑生理活动的结果。换句话说，精神是从物质中产生的。这种观点就叫作物质一元论。当然，相应的也有唯心主义的一元论，认为世界的本质是精神的，外面的世界不过是我自己心灵的产物罢了。 唯我论。笛卡尔从怀疑一切到确信「我在」的论证都是令人信服的，但是他往后的工作都不太可信。假设我们只停留在「我在」的阶段，我们只能确认我自己存在，外界的一切存在不存在我不知道，这就叫「唯我论」。这是怀疑主义经常得出的一个结论。虽然看起来荒谬，但很难被完全驳斥。我们永远都可以怀疑自己生活的世界是一篇幻觉，就跟《盗梦空间》一样，但我们甚至没有判别是否在梦中的「陀螺」。 经验主义。这里的「经验主义」不是指日常生活的「教条主义」的意思，而是指在科学归纳法中，最重要的是实验数据，是观测结果，它们是科学理论的基础和证据，这些东西可以用一个词来统称：经验。以英国科学家洛克为代表的，推崇这种归纳法思想的科学家派为成为「经验主义」。 理论名称 理性主义 经验主义 代表人物 数学派哲学家 科学派哲学家 研究方法 演绎法 归纳法 优点 严谨 产生新的知识 缺点 不产生新的知识，公设未必可靠 结论不能保证绝对正确，永远有出错可能 机械论。牛顿发现万有引力定律，给哲学界带来的极大的震动。万有引力定律如此优雅简洁，又如此普世通用地解释小到一块石头、大到一颗星球，乃至整个宇宙的运动规律。再庞大的世界，也敌不过几个数学公式。由此让有些人相信包括人类意识在内的整个世界都可以用物理学来解释。这就是「机械论」。辩证唯物主义是学校里教过的，机械论就是除掉了辩证法之后的唯物主义，也可以叫作「机械唯物主义」。 机械论虽然可以条理清晰地解释这个世界，但是按照机械论的说法，人类不过是这个世界中可有可无的一件事物而已，和桌子板凳、花鸟鱼虫没有本质的区别。我们的意识不过是一系列物质作用的结果，随时可以消失，毫无永存的希望，更谈不上还有什么人生意义。就像世间的其他事物一样，存在就存在了，消失就消失了。这很容易推导出虚无主义和享乐主义。 这还不是最可怕的，当我们从机械论再往左走时（更激进的方向），会触及到哲学光谱上最可怕的极端理论之一。 决定论。既然世间万物都可以用物理规律来解释，那么每一个事件之间必然要遵循严格的因果关系。如果人的意识是完全由物质决定的，那肯定也得服从严格的物理定律。那么，整个世界该如何发展，该走向何处，都是由自然定律决定好了的。就像人们根据力学可以预测星辰位置一样，人们也可以根据自然规律来预测未来所有的事件。 一个支持决定论的证据是，在20世纪之前，人们认为世界上不存在真正的随机数。我们在生活中可以靠掷骰子获得随机数。但如果以物理学的观点看，骰子最终的点数是被骰子的形状、密度、摇晃它时的手劲等等一系列客观原因决定的，骰子的运动也得严格遵守物理规律。只要我们知道之前任何一瞬间的全部的物理数据，我们就可以计算出骰子最终的点数。普通人以为骰子是随机的，只不过是因为所有数据的计算量太大，超过了人类的能力而已。 同样的道理，我们今天摇500万大奖的抽奖设备，无论再怎么设计，最终落下的是哪一个数字小球，也要被物理定律严格决定。只不过人们会把各个小球的质量、形状做得尽可能一样，以至于摇奖时间的一点点改变或者一丁点儿细微的震动，都可能改变最后的结果。使得影响最终结果的因素多到人类很难计算的地步，才能导致出所谓的随机效果。 其实计算机里也不存在真正的随机数。计算机生成的所谓随机数，实际上是取一个现成的数字（比如系统时间），经过一系列固定公式计算出来的。 刘慈欣以决定论的思想为基础，创作了短片小说《镜子》。在小说里主人公就有这么一台用超级计算能力的机器，只要输入初始参数，能从大爆炸开始模拟整条地球的时间线。经过多次尝试之后，主人公终于得到了能模拟出当前地球时间线的初始参数，从此过去、现在、未来都没有什么秘密可言了，一切从那几个初始参数开始就决定好了。 休谟的质疑。休谟是英国人，也是经验主义者。他对于理性主义和经验主义关于「何事为真实存在」的争论给出的回答是：我们根本不知道。休谟认为，经验就是人的感觉印象，我感觉到了什么就是什么，至于这种感觉是真是假，我们无从知晓。 笛卡尔说「我思故我在」，就算我们怀疑一切事物，「我」这个概念是怎么也怀疑不掉的。换句话说，「我」的概念可以超越一切事物。「我」到底是什么呢？你心里肯定产生了很多念头，或许是自己的名字，或许是自己的身体，或许是过去的一段记忆。不管是什么，这些念头都属于感官经验，都是由耳朵、眼睛等感官来感受到的。你试试能不能不依靠任何感官经验来形容「我」是什么？形容不出来了，是吧？因此休谟认为，所谓的「我」，不过是一堆经验片段的集合而已，并没有一个独立于经验的、实在的「我」存在。 那有什么是切实可信的？休谟认为有两种： 第一种是不依赖于经验的知识。比如几何学，它自身是不矛盾的，完全符合逻辑规则，而且不依赖经验存在。在现实世界中观察不到任何严格的三角形，但是我们仍旧有三角形这个概念。三角形不依赖外物存在。 第二种是我们自己感受到的经验，摸到什么、看到什么，这些都是可信的。 因此他很彪悍地说： 我们去图书馆随便拿起一本书，问这些书中包含着数和量的抽象推论吗？包含着关于实在事实和存在的任何经验的推论吗？如果都没有，就可以烧掉，因为里面只有诡辩和幻想。 实际上，休谟对知识的界定很靠谱。从理性主义和经验主义的争论来看，人类仅有两种获得知识的办法，一个是靠演绎推理（而且还没得到新的知识），一个是靠经验。休谟把其中最不靠谱的——理性主义者们的那些公设都给去掉了。剩下的除了经验之外，还留下了纯粹靠演绎推理能成立的知识。 这种界定，对科学来说是个灾难——因为「因果律」不属于这两种知识中的任何一种。我们无法不依靠经验纯从逻辑推导出因果律，所以它不属于第一类知识；同时，我们从经验观察只能得到两件事情是相关的，而得不出因果。一个很有名的例子： 假设农场里有一只鸡，每次一看到农场主来，就被喂食物，那么这只鸡就会以为农场主和给它喂食之间有因果联系。但结果有一天，农场主带来的不是鸡食而是一把猎枪，农夫把鸡杀了。换句话说，鸡通过观察发现，农夫和喂食这两件事总在一起发生，便以为其中有因果关系。但实际上，耗费它毕生时间得到的观察结果，仍旧不能证明这两件事之间有必然联系或者因果关系。 首先，除非能在所有时间跨度上观察两件事情的发生情况，不然就永远可能存在反例；其次，哪怕这能做到前一点，我们还是只能证明两件事情是相关的，而不一定是因果。（「相关不代表因果」是统计学上非常经典的准则） 休谟对「因果律」的质疑，带来了多米诺骨牌式的崩坏效应。首当其冲的就是归纳法，由于归纳法就是以因果律为前提的，如果因果律都不存在，那也就没有「从个别事件推导出普遍规律」这一说了。接着是科学本身就受到质疑，科学研究的前提是承认自然存在普遍规律，但是规律本身就值得怀疑了（永远可能存在反例）。再者哲学也遭殃了，理性主义被驳斥为独断论了（显然那些不言自明的公设在休谟看来根本不可信），经验主义倚重的归纳法也失效了。 休谟有一句名言，说你怎么知道明天的太阳会照样升起。对休谟不屑一顾的人，把这句话当作休谟白日做梦的笑话。而对于被休谟说服了的人，这句话代表的是休谟结论的可怕结果。当然，对抗大神的质疑，自然需要另一位大神登场。 值得一提的是，「黑天鹅理论」就是建立在休谟的怀疑主义上：「所有的天鹅都是白的」有数万只白天鹅作为证明，但推翻它，只要一只黑天鹅就足够了。 康德。哲学史上属于德国的时代要来了。首当其冲的就是康德，面对休谟对因果律的质疑，他提出了自己的理论。首先康德也承认，人类永远都无法认识到自己生活的这个世界是否真实；其次，人类所感受到的这个世界，是通过心灵加工的，这种加工机制称为「先天认识形式」；再次，世界的真面目，称为「物自体」；最后，「物体自」通过「先天认识形式」加工后得到的东西——也就是我们的认识——称为「表象」。 通俗讲，我们看到的世间万物，都是这个世界的表象，它们的真面目是物自体，到底是什么样子的，我们无从得知。同时，先天认识形式是伴随人类本身存在的，每个人都一样，而且是先天的，无法改变。在康德的世界里，所以知识都要经过心灵的加工才能被人类认识，不是心灵感受经验，而是心灵加工经验，心灵产生了经验，而这种加工方式还是固定的。 就如同我们每个人都是带着有色眼镜在看世界，所以我们看到的世界是这个世界的真实面目（物自体）加上有色眼镜（先天认识形式）得到的结果（表象），而我们永远都看到真实的世界是什么样子的，但同时因为我们每个人都带着同样的有色眼镜，所以我们看到的世界是相同的。 康德认为这个世界是人类永远无法真正认识的，因为我们看到的只是表象，但因为所有人的先天认识形式都相同，所以对同一个东西，我们的感受和经验是相同的，因此我们感觉不到事物是不是真的被扭曲了。 那么因果律呢？康德提出了在先天认识形式里包含了很多处理知识和经验的工具（十二个先天范畴），其中之一就是因果律。因此因果律只存在于先天认识形式里，而我们只拿它研究表象（因果律也只能研究我们感受到的经验）。对于这整个体系，康德有一套非常复杂的证明，这里只举先天认识形式的例子，康德的证明方法是，人不可能从零开始接受学习经验，在接受外部知识之前，一定要有基础，比如空间和时间概念，是人学习一切知识之间必须先具备的先天认识形式。 用一个四维空间的例子解释：我们虽然很聪明，我们虽然有数学家也有计算机，但是我们永远无法从感性上认识四维空间。这就是我们认识的局限，只要我们是人，无论我们用任何办法，都超越不了。四维空间里是什么样子、有什么东西，我们永远不可能知道。我们只能知道的是四维物体投影在三维空间里的「表象」。这不就是康德的世界观吗？ 黑格尔的辩证法。黑格尔认为，之前的哲学家都认为存在一个固定「真理」的想法是一个根本性错误。这样静态地、孤立地看待世界是过于幼稚的。要追求绝对的真理，就要先有绝对真是正确的知识作为基础，也就是「认识论」的问题，也就是之前理性主义和经验主义争得不可开交的问题。但研究「认识论」所用的方法也是知识的一种，好比康德写了一本《纯理性的批判》，讨论理性思维的不可靠，但是他在书里的用的也是理性思维，岂不是应该受到自己的批判。哲学家们的工作情形就好比有一块大石头，叫作「理性」，哲学家们打算去研究这玩意儿了。但哲学家们唯一能用的工具也只能是「理性」。黑格尔之前的哲学家们，用手中的理性工具去钻研面前的理性石头，一番努力之后，面前的理性石头变了模样。最终，哲学家们看着石头，抹抹头上的汗说：「我的工作完成了，我终于发现终极真理了！」但是这帮哲学家们都忘了，眼前的理性石头变样后，他手里的理性工具也随之变样了！所以出现了一代一代哲学不停推翻前人的理论，并且争论不到头的现象。 黑格尔认为，世界本来就是没有绝对真理的，一个判断并不是永远的。传统的逻辑，也就是我们一般人能接受的逻辑，都要遵守「矛盾律」。「矛盾律」的意思是，一件事不能自相矛盾，事物和事物之间也不能互相矛盾。但在黑格尔的辩证法里，界不是容不得矛盾的，而恰恰相反，到处都是矛盾，矛盾就是世界的本质。因为凡是找到一个概念，我们都可以找到和它相反的概念。这很像中国古代的「阴阳说」，阴和阳无处不在，凡事有阴又有阳。阴阳也不是你死我活的关系，而是既有冲突也可和谐共存的。黑格尔认为，矛盾的双方可以共存，但是处在互为差异、甚至互相冲突的动态之中。事物的正题和反题会发生强烈的冲突，这个冲突的结果并不是一方消灭另一方，而是正题和反题最终化为「合题」达到了协调，升华了。 有一个正题就可以找到它的反题，因此新的合题产生之后，它的反题也随之产生，这样就又产生了新的矛盾，又要有新的冲突和升华，再产生新的合题。因此黑格尔认为，事物是不断变化的，这种变化是自发的、抑制不住的。同时，这种变化不是无序的，而是有方向的，这个方向就是较低级的正题和反题不断变成更高级的合题，也就是事物不断在向高级形态变化，变化到最后，就是终极真理，黑格尔称为「绝对精神」。 叔本华和悲观主义。叔本华是黑格尔坚定的反对者，原因很简单，因为叔本华是康德的门徒，而他的哲学理论就来自于对康德的「自物体」的新诠释。他认同康德的形而上学，但是不认为物自体是完全不能认识的。理由很简单。因为「我」自己就是物自体啊。物自体是超越理性，不能用理性知识体验的。但是我们观察自己的时候，可以不靠理性，而是靠非理性的「直觉」。 而且物自体只有一个。 康德的自物体是由多个的，而且和表现出的事物一一对应。比如桌子有一个它对应的物自体，「我」也有一个「我」对应的物自体。因为我们在区别两个事物的时候，离不开空间概念。比如两个东西形状不同，摆放的位置不同，等等。可是物自体不具备空间属性啊，所以我们不可能把物自体区分成一个一个不同的样子。叔本华认为，万物的物自体是统一的，只有一个。这个物自体，叔本华给它起了个名字，叫作「生命意志」。 那么生命意志是个什么东西呢？简单地说，是一股永不停歇的力量。这股力量驱使着万物去运动，去发展。比如人和动物的食欲性欲，比如植物破土而出的欲望。动物没有理性，可是动物生下来就知道觅食、交配、躲避危险，在很多情况下比人的求生能力还要强。动物这么强大的生存能力哪儿来的呢？叔本华认为，这是背后的生命意志驱使的。生命意志的概念比一般的生物欲望还要宽泛，还包括没有生命的事物在内。叔本华认为，宇宙中万事万物背后都有生命意志在驱动。小到磁石相吸，大到星球运行，背后的本质原因都是生命意志。在叔本华看来，生命意志是世界上最本质的东西，是不可抗拒的，是永不停歇的。因为物自体是非理性的，所以生命意志也是非理性的，也就是盲目的。对于人来说，生命意志主要表现在人的生存欲望。中国儒家主张用理性的人伦纲常来克制男女私欲，这在叔本华看来是不可能的。因为他认为人的求生欲望来自于物自体，比理性更本质。举例子说，我们以为自己生活、恋爱、结婚、工作是根据我们的理性选择的。而叔本华认为，真正驱动你的都是种种欲望：生殖的欲望、享乐的欲望、征服的欲望，等等。你以为你在靠理性生活，实际上躲在理性背后的是生命意志，生命意志在驱动你作出种种选择。 理性的危机。叔本华对哲学史的最大价值在于，他的理论暗示了一个重大危机——理性的没落。因为他的悲观主义阐述了非理性的生命意志才是最本质最重要的东西，而且人类的所谓理性，也仅是受到生命意志驱使的产物而已。 尼采。尼采继承了叔本华的形而上学。叔本华说物自体是「生命意志」，尼采给改造成了「权力意志」。尼采把人分成了强者和弱者。强者体现了权力意志，他们的特征是积极向上、勇于进取、勇于牺牲、善于创造。弱者相反，特点是胆小、保守、善妒、虚伪。传统欧洲人相信基督教的普世精神和卢梭的人文主义，两者强调的都是对弱者的关怀，强调人人平等。尼采不同意。他认为，同情弱者没错。但弱者不能以此为理由，去要挟、榨取强者，去拖强者的后腿，这样做是可耻的。打个比方，强者看待弱者，就跟人类看待猿猴一样。猿猴对人类有用吗？如果不关在笼子里而和人类混居，那一定会给人类添乱。强者眼中的弱者也是一样。对弱者不应该光是怜悯，还应该限制他们的能力，免得他们给强者捣乱。尼采认为，基督教道德是典型的奴隶道德，本质是伪善的。基督教鼓励人们变得谦卑，其实就是鼓励人们做弱者。所以尼采大喊「上帝死了！」意思是，他想去掉上帝。如果没了上帝，人们也就不需要无条件地遵守基督教道德了。尼采推崇强者，可是尼采发现，大部分强者都被奴隶道德压抑着，不能摆脱弱者对他们的束缚。 因此，尼采希望「超人」出现。「超人」这个词在尼采的理论里不是指拥有强大权力的人，不是说这人一定要当总统、当将军，而是指能够完全按照自己的意志行动、能充分发挥自己的创造力，并且能摆脱奴隶道德、不被弱者束缚的强者。超人是尼采对人类的一种理想，在尼采眼里，整个人类历史里也很少有人能成为真正的超人。尼采和叔本华一样，认为这世界是悲观的。但他的解决方法和叔本华不同。尼采的世界观带有强烈的激情，他认为叔本华的禁欲是胆小者的逃避行为。他觉得人不应该像叔本华宣扬的那样避免痛苦，而是应该承认痛苦，迎战痛苦。简而言之，尼采推崇的是一种精英主义。 随着工业革命，科学技术迅猛发展，对哲学造成了重大打击。首先是进化论对基督教形成了重大冲击，接着非欧几何、相对论以及量子力学使得人们对「先验理性」的信念动摇。 逻辑实证主义和实用主义。罗素和维特根斯坦是逻辑实证主义的领导者，这个理论的目的是建立一套严谨的逻辑语言来研究哲学，逻辑符号重铸，形成通用的罗家演绎语言，强调实证来拓展新的知识，这种「两条腿走路」的想法很好，但是他们失败了，当用逻辑工具去一一考察所有哲学命题，把所有没有意义、不可证实的命题都剔除掉后，除了「重演是命题」（桌子是桌子）和「描述片段经验的命题」（这朵花是红色的）之外什么都没剩下了，所以这条路注定失败了；实用主义则倾向于哲学在实际运用中的价值，例如判例法、改良式资本主义和进化论都是实用主义的佐证，但是由于缺乏严谨性，这种理论难以大范围地被接受。 形而上的终结。此前不管是科学研究，都把中心放在逻辑推理和证实上，但是很多命题是无法真正证实的（例如世界上所有的乌鸦都是黑色的），但是依次怀疑推翻所有科学由显然是不合理，因为它们已经被证明具有很好的实用价值。直到奥地利科学家波普尔提出了「证伪主义」：科学理论必须能提出一个可供证伪的事实，假如这个事实一经验证，便承认该理论是错的（而在此之前，它就暂时是真的）。 证伪主义的科学观是，人类提出的各种科学理论有点像是基因突变，科学家们发散思维，想出各种充满想象力的假说。证伪就如同自然环境对基因的筛选，经不住证伪的假说都被淘汰，留下的都是经得住检验的，也就是暂时正确的科学理论。 那些留下来的理论，科学家们也在不断地尝试证伪，一旦证明是错的，就进行修改。这样科学理论就会越来越完善。这个试错、修改、完善的过程是无休止的，科学也因此会越来越接近真理。 到当前为止，证伪已经成为区分科学与伪科学的重要理论依据。 证伪主义动摇了形而上学的根基——演绎推理。演绎推理的规则就是从一个绝对为真的命题出发，推理出一个绝对为真的结论，只有这样才能保证每个结论都是正确的。证伪主义反对的，恰恰是这绝对为真的命题——因为绝对为真的命题是不可证伪的，所以也是不可信的。 辩证唯物主义。唯物主义的升级版。 永恒的终结。在理性的领域里，面对「人生的意义是什么」等等形而上学问题，要么去求助心理医生，要么就没有答案了。这就是本书的结论。形而上学走不通，形而上学的问题都没有答案。我们说过，形而上学的任务，是用理性思维去研究世界本质等「大问题」。形而上学走不通，也就是说，理性不可能回答「世界的本质是什么」「有没有终极真理」「终极真理是什么」「人生的意义是什么」等大问题。硬要回答，答案一定是独断论的，或者在推理上有错误。 实际上，所有的形而上学都会陷入无法证明自身的困境。 经验主义者们的论断「只有来源于经验的知识才是可靠的」，并非来自于经验。康德用来批判理性的工具却没经过自己的批判。黑格尔讲辩证法，但是他的辩证法到最后却并不辩证。尼采说所谓的真理都是谬误，那他自己的理论不也是谬误了吗？逻辑实证主义用来分析语句的规则，经过自己的分析都变成无意义的了。波普尔的证伪主义理论，是不能被证伪的。后来到实用主义的时候，罗素批评说：实用主义以「是否实用」为标准评价真理，但是「是否实用」的标准是什么呢？如此追问下去，必然会形成无限回溯，得不出结论。 我们会发现，这种情况在哲学史上不是偶然，几乎每一个哲学流派，都面临着自己不能证明自己的窘境。那么，这种“怀疑者不能怀疑自身”的质问只是一种抬杠吗？如果我们是怀疑者，那我们把原则改成「我们可以怀疑一切，除了本原则之外」不就可以了吗？不行。因为哲学研究的是“什么知识真实可信”的问题，是认识论的问题。按照怀疑精神，任何知识必须先确认是可信的，才能被我们接受。然而，我们用来确认知识是否可信的方法（也就是各种哲学理论），本身也属于知识的一种，它们在给别的知识提出限制的同时，也就是在给自己提出限制。形而上学的任务之一是保证一切知识的来源是可靠的，如果它连自己的可靠性都不能保证，就正好说明它是独断论。 存在与虚无。如果形而上学走不通了，那么接下来该怎么办呢？该怎么回答「人生意义是什么」的问题呢？最直接的答案是不可知论和虚无主义。 既然形而上学的问题都没有答案，那么就意味着我们不知道人类的一切知识是否可靠，这个世界就没有了终极真理，没有了本质，人生也就没有了意义。这是一个很自然但也很偷懒的答案。这个答案如果推到极致，相当于反对一切秩序和道德，拒绝一切知识。如果相信了绝对的不可知论，那人就连拿起杯子喝一杯水的能力都没有。如果相信了绝对的虚无主义，那人只能走向精神崩溃。实际上，没有任何一个人会真正接受这个答案。 萨特与加缪。过去的哲学家们——如理性主义者，如康德——都相信存在着某种先验真理。这些真理先于人类存在，它们是世界的本质。这世上是先有的先验真理，然后才有了万物和人类，所以万物的本质先于万物的存在。但既然这样的形而上学是不可能的，那么先验真理也就没有了。它们没了，那最先出现在这个世上的，就剩下人的存在了。 因此萨特有一句名言：「存在先于本质。」在萨特看来，哲学最应该关心的，是「我存在」这事本身。在形而上学毁灭之后，这世上没有了绝对真理，也没有了先验真理。世界上不再有什么确信无疑的事，只有「我存在」是毋庸置疑的。实际上我们可以说，哲学到了这里，画了一个大圆，又回到笛卡尔的「我思故我在」了。我们现在又什么都不确信，唯一确信的只有「我存在」了。 加缪和萨特同为存在主义哲学的代表人物，他最有名的观点是，世界是荒谬的。 假如这个世界上有终极真理，那么就意味着在这个世界里有某种高于一切、比任何事物都重要的东西。那么人的存在就是有目的的，目的就是找到这个最最重要的真理，或者按照这个真理的指导来生活。这就是形而上学下的人生意义。然而哲学的结论告诉我们：人生其实是没有目的的。当人意识到人生没有目的的时候，对目的的本能渴望和没有目的的现实就会发生强烈的冲突，让人产生荒谬感。 那么，面对这荒谬的世界，我们该怎么办呢？ 加缪的名篇《西西弗的神话》里讲了一个希腊神话。说西西弗被众神惩罚，必须把一块巨石推上山顶。但是石头一到山顶，马上又自己滚下来。西西弗必须再次重复这苦役，一直到永远。加缪用这个例子来说明我们生活的荒谬。人们的世俗生活就像工人每天重复着机械的工作、却不知道自己工作的意义何在一样。解决办法是什么呢？加缪说，西西弗的胜利在于他意识到了这种荒谬，他从此不再是荒谬的奴隶，而是自己的主人。虽然他无法改变自己的处境，但是他内心是充实的，所以他可以在荒谬中寻找到幸福。 人生的意义。当我们跋山涉水，从自我认知的第一缕曙光，走过人类智者的一个又一个高峰，达到终点时，突然发现我们依然没有对这个问题的答案。或许是这个问题本来就没有（固定的）答案吧。「意义」本身就是因人而异的，参差多态才是幸福的本源，并没有一个统一的能让全人类都朝之努力的答案。每个人人生的意义，也许就是回答：「我为什么活着？」等价于回答：「我为什么不立刻自杀？」如同加缪说的：「真正严肃的哲学问题只有一个，那就是自杀。」 假如你能顺利地回答这个问题，比如「我不想死，是因为我还想到处旅游，吃好吃的」「我不想死是因为我不能让父母伤心」。那么，也许这些答案就是你现在的人生意义。","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"《巨人的陨落》","slug":"Fall-of-Giants","date":"2017-06-12T15:53:33.000Z","updated":"2020-02-22T09:30:45.923Z","comments":true,"path":"2017/06/12/Fall-of-Giants/","link":"","permalink":"http://findingsea.github.io/2017/06/12/Fall-of-Giants/","excerpt":"前言《巨人的陨落》是我今年到目前为止看得最满意的一本书，好久没有这种一看完就忍不住向身边人推荐的好书了。当时在朋友圈和豆瓣的书评是：","text":"前言《巨人的陨落》是我今年到目前为止看得最满意的一本书，好久没有这种一看完就忍不住向身边人推荐的好书了。当时在朋友圈和豆瓣的书评是： 作者将虚构故事嵌入真实历史的功力，令人叹为观止。以第一次世界大战为背景，将包含亲情、爱情、友情的五条故事线，穿插进影响世界的大事件中。虽然以设定来说全书时间跨度只是五年，但仅仅五年世界和人物命运都发生了天翻地覆的变化，一口气读完有恍若隔世的感觉。 作为小说，我觉得故事内容本身不用多讲，一来是剧透了再读的乐趣就少得多，二来是故事本身大多都是俗套的，我想尝试讲的，是这本书在形式和技巧上吸引人的东西，当你跳脱开小说内容的猎奇，而关注作者怎么把这么一个故事讲得令人手不释卷，就能发现更多有趣的事情。 史实与虚构这是本书最有趣的地方，本身大量的情节都是历史真实事件。以第一次世界大战为背景，英国工党崛起，俄国十月革命，德国如何发动战争，美国如何摇摆，在这些史实中间，安插进本书的几条故事线。最有趣的是，这些虚构的故事和历史之间结合地天衣无缝，简直让你相信这些故事可能真的发生过。 这个形式一下让我想起金庸的作品和电影《阿甘正传》。金庸的大量作品都是有历史史实作为背景的，《天龙八部》里乔峰的契丹人身份，《神雕侠侣》里郭靖保卫襄阳，《倚天屠龙记》里的明教，这些作品里面的大量主线情节，都是构建在真是历史之上的，然后再嵌入虚构的故事加以发挥。电影《阿甘正传》更是将这种技巧发挥到了极致，整部电影里都是美国七八十年代的象征性事件，猫王，越战，要做爱不熬作战，水门事件，乒乓外交，黑人平权，苹果公司等等，导演和编剧把阿甘完美地塞进这一系列历史著名事件中，而且利用了剪辑手法，直接用当时真正的历史影响资料来展现，仿佛阿甘真的是这些大事件的亲历者。 我觉着这种手法之所有这么吸引人，主要是因为： 历史认识。这些都是大家耳熟能详的历史事件，当读者读到看到的时候，对那段时间的历史认识就会被调动起来，这使得故事背景在读者脑中是非常立体，比从零开始构建一个故事背景要更有说服力和吸引力。 历史感。可以看这些文艺作品里面选择的历史背景都是非常具有代表性，这些历史本来就是波澜壮阔的，在后世都是被不断讨论的，所以这些历史本身就给人一种沧桑感，给读者一种向往，一种非常特殊的具有吸引力的「历史感」。 编排的技巧。一遍是真实的历史，一遍是虚构的故事，如何把它们穿插编排起来，是非常考验技巧的一件事，既要保证史实的真实性，又要体现故事的戏剧张力。看作者如何见缝插针地安插进虚构的情节，又如何编排让虚构的人物推动真实历史的发展，这本身就是一件非常有乐趣的事情了。 多线叙事多线叙事其实并不新奇，但是本书做到了五线叙事，同时没有明显纰漏，这就比较值得称道了。同时，这五条线的安排，包含了不同阶级、不同国家、不同信仰的冲突，再融入亲情、爱情、友情的不同情感，可以说大时代下的众生相刻画地非常细腻鲜明。 一谈起多线叙事，我就想起马丁老爷子的《冰与火之歌》，那简直是多线穿插的集大成者。要知道如此众多的任务和情节，平行推进的时候，是非常难以把控的，尤其是时不时地各个主线之间还要进行互动，一条线里埋下的伏笔，在另一条线里要能被挑起来。在这方面马丁老爷子的功力简直令人叹为观止。在这点上，作为一个哈迷，我不喜欢《哈利波特与凤凰社》的最主要原因，就是觉得罗琳在核心人物增多之后表现出控制乏力。 本书的多线内容都经得住推敲（当然一部分也得益于本身有真实历史作为背景），这是非常难得了。毕竟这种技巧无关灵感或者其实玄学的东西，而是实打实地考验作者的笔下能力。 节奏与厚度本书的情节推进是非常快的，尤其是在多线切换的时候。这个时候适当地省略直接情节描写，然在往后的情节中带出让读者自己推断（同样参考《冰与火之歌》），能大大加快节奏的同时，避免显得冗长繁复。 得益于这种又快又鲜明的节奏，能把读者钉在书前，同时又快速地积累情节。所以当我看完全书，在大结局处看到与全书开头照相呼应的情节时，突然觉得开头那一幕好像就发生在昨天，又好像发生在遥远的过去。虽然全书的时间跨度设定也才五年，但是这本来就是世界天翻地覆的五年，而书中的人物在大历史浪潮下挣扎、抗争、奋斗，在结尾处回看时，早已物是人非，沧海桑田。 这种厚重感，让人觉得仿佛自己也在书中度过了五年时光，不免掩卷长叹。 矛盾与冲突矛盾、冲突，这是戏剧张力的来源，也是能抓住读者眼球的重点。作者在这点的设置上，巧妙地利用了史实，让人物之间的矛盾和冲突显得尖锐又不突兀。 在英国，作者选择了阶级矛盾。虽然英国早已是君主立宪制国家，但在一战以前，贵族仍享受着非常大的优越感，不管保守党本身的政治势力，还是贵族在社会资源上的优势，都让他们和工人阶级形成了强烈矛盾。 在俄国，那就不用说了，毕竟是阶级和主义的矛盾，轰轰烈烈的十月革命，把这个矛盾和冲突最大化了。 在德国，作者利用爱情安排了国家民族矛盾。一个英国女伯爵和一个德国男伯爵之间，本来是门当户对的爱情，但由于英德交战，他们的国家和人民互相视对方为敌人。他们要拼命冲破历史的阻碍，才能获得自己的爱情。 可以看到作者对这几个矛盾和冲突点，设置地都非常巧妙，这也使得读者在阅读过程中不能觉得情节里有特别生硬或者突兀的地方，可以非常流畅地读懂并体会到作者要表达的点。 结语综上，我觉得《巨人的陨落》是真的值得一读和推荐给身边人的书，从中你能体会到很多阅读的乐趣。","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"2015年11月阅读报告","slug":"november-reading-report","date":"2015-12-24T10:44:43.000Z","updated":"2020-02-22T09:30:45.922Z","comments":true,"path":"2015/12/24/november-reading-report/","link":"","permalink":"http://findingsea.github.io/2015/12/24/november-reading-report/","excerpt":"本月总共看了2本书。 以下内容均由豆瓣读书报告生成器自动生成。","text":"本月总共看了2本书。 以下内容均由豆瓣读书报告生成器自动生成。 《爱你就像爱生命》 力荐。『我和你就像两个小孩子，围着一个神秘的果酱罐，一点一点地尝它，看看里面有多少甜。』一方面，其实是很难想象一个大作家表达自己的爱情的时候，如此直白还带点肉麻；但同时，你能感觉他的爱情如此真实，如此单纯，又如此勇敢。他的爱情里，有细腻，有童稚，有好奇，又有时带点懊恼。他的爱情，是直面的，是勇敢的，是不娇柔做作的。像真正的骑士。&lt;divclass=”clear”&gt; 《社会动物》 力荐。本书一种不同之处在于虚构了两个人物，通过两个人主人公的成长脉络，揭示和串联人在各个阶段的社会属性和社会活动。本书的重心在于描述社会活动对人的重要意义，以及对人各类活动的全面影响，强调第一认知阶段的重要性，阐述了第一认知阶段在人类各类情感触发中分发挥的作用。总之是一本故事性和学术性并重的读物，同时作为社会性理学综述类参考书也非常好。&lt;divclass=”clear”&gt;","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"2015年10月阅读报告","slug":"october-reading-report","date":"2015-11-16T08:39:31.000Z","updated":"2020-02-22T09:30:45.922Z","comments":true,"path":"2015/11/16/october-reading-report/","link":"","permalink":"http://findingsea.github.io/2015/11/16/october-reading-report/","excerpt":"10月份由于终于处理好了工作的事情，所以能花在读书上的时间也更多，总共看了8本书。","text":"10月份由于终于处理好了工作的事情，所以能花在读书上的时间也更多，总共看了8本书。 以下内容均由豆瓣读书报告生成器自动生成。 《一个人的朝圣》 力荐。整个故事构建在一个再平凡不过的人决心要用一种再平凡不过的方式去做一件不平凡的事。整条『朝圣』的路分成了很多个阶段，每个阶段都有不同的勇气和徘徊，每个阶段都有希望和失望抑扬起伏，整条路以现实起，以一个近似『信仰』的目标前进，最后以现实终。你会为这个过于平凡的人物牵挂，为他遇到的阻碍而叹息，为他不可思议的目标而犹豫，为他每次遇挫后的勇气而鼓舞，也为他每次取得的小小成就而欢欣。哈罗德进行的是一场『朝圣』，更是一场自我救赎。 《目送》 力荐。虽然不太习惯龙应台这本书里的淡酒清愁，但是她关于亲情的诸多细节无法不令人动容。为人子女的，目送考妣渐老，在尽头处难得安宁，叫你看了徒生心痛；为人父母的，目送子女渐长，在拐角处毫不留恋，叫你感同身受曾经留下的凄凉。父子母女，今世的缘分就是目送他渐行渐远。 《黄金时代》 力荐。张佳玮：『在黄金时代，王小波这样的人可以信马由缰的流浪和叙述。而在我们这样的时代（或者，他那样的时代）他才会显得有些那么奇妙和格格不入——就像王小波崇敬的那些诗人翻译家，就像《黄金时代》里与周围格格不入的陈清扬和王二，以及《红拂夜奔》里老了之后的红拂。重复一遍《黄金时代》后记里那段子：人们看到印象派画家画出紫色天空，便加以嘲笑。而王小波之于我们的时代，就是那个明白真相，而且始终追寻蓝色天空的人，是曾经生活在这个时代的第欧根尼。』 《如果这是宋史.7》 对于《如果这是宋史》的书评就和在一起讲吧：填到第七卷（北宋灭亡）之后，终于受不了不再继续填这个坑了。这样一套书，从后周太祖起到宋仁宗止的四卷，是非常推荐一看的。然而自英宗以降的部分，就变味变得没法看了。由于作者对王介甫同学的实在过分敬仰，其浓浓的崇敬之情简直腻得能从纸上渗出油来，从神宗开始，我就不知道我看的是《宋史》，还是《伟人王安石》。另外，作者十分幼稚和初级的历史观也在越往后的卷册里表现得越明显：个人情感代入过重，『如果』式意淫，马后炮分析等等。总之，仅以前四卷论，有《明朝》一多半的水准，往后基本只剩起点中文网二流作者水平。 《如果这是宋史6 后改革时代卷》 《如果这是宋史5 王安石变法卷》 《如果这是宋史4：仁宗盛世卷(下)》 《博尔赫斯谈话录》 中国道家的老子，据说某一天骑着一头青牛遁入戈壁，越过文明的边境，在那里创作了他的诗篇和语言。佛陀离开了他的宫殿，隐入山林打坐冥想，将他的教化口述为诗节。博尔赫斯直到最后一刻，不断在口授诗歌、寓言，以及一些散文和故事，但他越来越多借助的媒介还是『谈话』，这是现代人的辩证术。在那些带着问题的同行和听众面前，这位语言大师用他的谈话创造一份我们时代的公开约书，这约书在性质、强度和范畴上，与他和朋友们的私人闲谈并无不同，这在他成年后的大部分时间，一直是他的『道』，是他分享那些未成文的文字的方式。——后记","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"Sliding Window Maximum@LeetCode","slug":"Sliding-Window-Maximum-LeetCode","date":"2015-10-09T09:17:07.000Z","updated":"2020-02-22T09:30:45.922Z","comments":true,"path":"2015/10/09/Sliding-Window-Maximum-LeetCode/","link":"","permalink":"http://findingsea.github.io/2015/10/09/Sliding-Window-Maximum-LeetCode/","excerpt":"Sliding Window Maximum核心的思路是：既然要达到O(n)的复杂度，那么就要保持窗口内的最大值在窗口边界上。","text":"Sliding Window Maximum核心的思路是：既然要达到O(n)的复杂度，那么就要保持窗口内的最大值在窗口边界上。达到这个效果的方法就是滤掉窗口中没用的元素。维护一个双向队列，队列保存数组的下标，每当有新元素进入队列时，从队尾开始，删掉连续的比新元素小的元素，然后将其插入到队列末尾。之所以可以这样删掉元素是基于：这些元素永远都不会在一个窗口中成为最大的元素。这样就保证了队首的元素始终是窗口（队列）中最大的，并且队列中始终保持了所有可能在一个窗口中成为最大元素的元素。至于队首元素的弹出，则只要判断目前窗口的位置即可。 实现代码： 123456789101112131415161718public class Solution &#123; public int[] maxSlidingWindow(int[] nums, int k) &#123; if (nums == null || nums.length == 0) return nums; int[] result = new int[nums.length - k + 1]; LinkedList&lt;Integer&gt; queue = new LinkedList&lt;Integer&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; while (!queue.isEmpty() &amp;&amp; nums[queue.peekLast()] &lt; nums[i]) queue.pollLast(); queue.add(i); if (queue.peekFirst() == i - k) queue.pollFirst(); if (i &gt;= k - 1) result[i - k + 1] = nums[queue.peekFirst()]; &#125; return result; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Java泛型：类型擦除","slug":"java-generic-type-erasure","date":"2015-10-09T03:59:43.000Z","updated":"2020-02-22T09:30:45.922Z","comments":true,"path":"2015/10/09/java-generic-type-erasure/","link":"","permalink":"http://findingsea.github.io/2015/10/09/java-generic-type-erasure/","excerpt":"前情回顾Java泛型：泛型类、泛型接口和泛型方法","text":"前情回顾Java泛型：泛型类、泛型接口和泛型方法 类型擦除代码片段一1234567Class c1 = new ArrayList&lt;Integer&gt;().getClass();Class c2 = new ArrayList&lt;String&gt;().getClass(); System.out.println(c1 == c2);/* Outputtrue*/ 显然在平时使用中，ArrayList&lt;Integer&gt;()和new ArrayList&lt;String&gt;()是完全不同的类型，但是在这里，程序却的的确确会输出true。 这就是Java泛型的类型擦除造成的，因为不管是ArrayList&lt;Integer&gt;()还是new ArrayList&lt;String&gt;()，都在编译器被编译器擦除成了ArrayList。那编译器为什么要做这件事？原因也和大多数的Java让人不爽的点一样——兼容性。由于泛型并不是从Java诞生就存在的一个特性，而是等到SE5才被加入的，所以为了兼容之前并未使用泛型的类库和代码，不得不让编译器擦除掉代码中有关于泛型类型信息的部分，这样最后生成出来的代码其实是『泛型无关』的，我们使用别人的代码或者类库时也就不需要关心对方代码是否已经『泛化』，反之亦然。 在编译器层面做的这件事（擦除具体的类型信息），使得Java的泛型先天都存在一个让人非常难受的缺点： 在泛型代码内部，无法获得任何有关泛型参数类型的信息。 代码片段二123456789List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();Map&lt;Integer, String&gt; map = new HashMap&lt;Integer, String&gt;();System.out.println(Arrays.toString(list.getClass().getTypeParameters()));System.out.println(Arrays.toString(map.getClass().getTypeParameters()));/* Output[E][K, V]*/ 关于getTypeParameters()的解释： Returns an array of TypeVariable objects that represent the type variables declared by the generic declaration represented by this GenericDeclaration object, in declaration order. Returns an array of length 0 if the underlying generic declaration declares no type variables. 我们期待的是得到泛型参数的类型，但是实际上我们只得到了一堆占位符。 代码片段三1234567public class Main&lt;T&gt; &#123; public T[] makeArray() &#123; // error: Type parameter 'T' cannot be instantiated directly return new T[5]; &#125;&#125; 我们无法在泛型内部创建一个T类型的数组，原因也和之前一样，T仅仅是个占位符，并没有真实的类型信息，实际上，除了new表达式之外，instanceof操作和转型（会收到警告）在泛型内部都是无法使用的，而造成这个的原因就是之前讲过的编译器对类型信息进行了擦除。 同时，面对泛型内部形如T var;的代码时，记得多念几遍：它只是个Object，它只是个Object…… 代码片段四1234567891011121314151617181920212223public class Main&lt;T&gt; &#123; private T t; public void set(T t) &#123; this.t = t; &#125; public T get() &#123; return t; &#125; public static void main(String[] args) &#123; Main&lt;String&gt; m = new Main&lt;String&gt;(); m.set(\"findingsea\"); String s = m.get(); System.out.println(s); &#125;&#125;/* Outputfindingsea*/ 虽然有类型擦除的存在，使得编译器在泛型内部其实完全无法知道有关T的任何信息，但是编译器可以保证重要的一点：内部一致性，也是我们放进去的是什么类型的对象，取出来还是相同类型的对象，这一点让Java的泛型起码还是有用武之地的。 代码片段四展现就是编译器确保了我们放在t上的类型的确是T（即便它并不知道有关T的任何类型信息）。这种确保其实做了两步工作： set()处的类型检验 get()处的类型转换 这两步工作也成为边界动作。 代码片段五1234567891011121314151617181920public class Main&lt;T&gt; &#123; public List&lt;T&gt; fillList(T t, int size) &#123; List&lt;T&gt; list = new ArrayList&lt;T&gt;(); for (int i = 0; i &lt; size; i++) &#123; list.add(t); &#125; return list; &#125; public static void main(String[] args) &#123; Main&lt;String&gt; m = new Main&lt;String&gt;(); List&lt;String&gt; list = m.fillList(\"findingsea\", 5); System.out.println(list.toString()); &#125;&#125;/* Output[findingsea, findingsea, findingsea, findingsea, findingsea]*/ 代码片段五同样展示的是泛型的内部一致性。 擦除的补偿如上看到的，但凡是涉及到确切类型信息的操作，在泛型内部都是无法共工作的。那是否有办法绕过这个问题来编程，答案就是显示地传递类型标签。 代码片段六12345678910111213141516public class Main&lt;T&gt; &#123; public T create(Class&lt;T&gt; type) &#123; try &#123; return type.newInstance(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; public static void main(String[] args) &#123; Main&lt;String&gt; m = new Main&lt;String&gt;(); String s = m.create(String.class); &#125;&#125; 代码片段六展示了一种用类型标签生成新对象的方法，但是这个办法很脆弱，因为这种办法要求对应的类型必须有默认构造函数，遇到Integer类型的时候就失败了，而且这个错误还不能在编译器捕获。 进阶的方法可以用限制类型的显示工厂和模板方法设计模式来改进这个问题，具体可以参见《Java编程思想 （第4版）》P382。 代码片段七1234567891011public class Main&lt;T&gt; &#123; public T[] create(Class&lt;T&gt; type) &#123; return (T[]) Array.newInstance(type, 10); &#125; public static void main(String[] args) &#123; Main&lt;String&gt; m = new Main&lt;String&gt;(); String[] strings = m.create(String.class); &#125;&#125; 代码片段七展示了对泛型数组的擦除补偿，本质方法还是通过显示地传递类型标签，通过Array.newInstance(type, size)来生成数组，同时也是最为推荐的在泛型内部生成数组的方法。 以上，泛型的第二部分的结束。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://findingsea.github.io/tags/Java/"}]},{"title":"2015年9月阅读报告","slug":"september-reading-report","date":"2015-10-06T08:31:04.000Z","updated":"2020-02-22T09:30:45.922Z","comments":true,"path":"2015/10/06/september-reading-report/","link":"","permalink":"http://findingsea.github.io/2015/10/06/september-reading-report/","excerpt":"九月在各种笔试面试和继续实习之余读了两本书： 《大型网站技术架构》和 《活着》。","text":"九月在各种笔试面试和继续实习之余读了两本书： 《大型网站技术架构》和 《活着》。 以下内容均由豆瓣读书报告生成器自动生成。 《大型网站技术架构》 作者的背景可谓是强力背书，而且从书中也可以看出作者本身的工程经验非常丰富，对架构技术的方方面面都应该涉猎不少。本书的优点是对大型网站的技术架构有一个系统性的梳理，让人看起来很有条理；缺点是讲得太浅，不过要一个人一本书讲透架构所有的方方面面也显然是不太现实的。 所以总得来说，感觉入门是极好的选择，能让你对大部分的架构技术有一个宏观了解，继续深入则是后续的工作了。 《活着》 余华描写的是一种沉重，生活的苦难，命运的压迫，捻灭一个又一个的渺小希望，不留任何余地。 余华描写的又是一种释然，人生起起落落，希望所起之处，往往又是绝望暗生之地，最后这些无常都随风而逝，留下的只是平静地活着。","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"Scrappy入门：百度贴吧图片爬虫","slug":"scrapy-step-1","date":"2015-10-03T12:11:27.000Z","updated":"2020-02-22T09:30:45.922Z","comments":true,"path":"2015/10/03/scrapy-step-1/","link":"","permalink":"http://findingsea.github.io/2015/10/03/scrapy-step-1/","excerpt":"Scrapy是Python非常有名的爬虫框架，框架本身已经为爬虫性能做了很多优化：多线程、整合xpath和图片专用管道等等，开发人员只要专注在功能需求上。","text":"Scrapy是Python非常有名的爬虫框架，框架本身已经为爬虫性能做了很多优化：多线程、整合xpath和图片专用管道等等，开发人员只要专注在功能需求上。 基本Scrapy使用教程参考：初窥Scrapy和Scrapy入门教程。 学习一种技术或者一个框架最好的方式当然是用它做一些小工程，入门第一步我先选择了百度贴吧图片爬虫，因为既够简单又比较实用。 因为这次涉及到图片的下载，而Scrapy本身为此提供了特殊的图片管道，所以果断直接用Scrapy的图片管道来帮助完成。Scrapy中管道的定义如下： 当Item在Spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item的处理。每个item pipeline组件(有时称之为“Item Pipeline”)是实现了简单方法的Python类。他们接收到Item并通过它执行一些行为，同时也决定此Item是否继续通过pipeline，或是被丢弃而不再进行处理。 对于管道的典型应用场景如下： 清理HTML数据验证爬取的数据(检查item包含某些字段)查重(并丢弃)将爬取结果保存到数据库中 Scrappy图片管道的使用教程参考：下载项目图片。 使用Scrapy最重要的就是编写特定的spider类，本文指定的spider类是BaiduTieBaSpider，来看下它的定义： 123456789101112131415import scrapyimport requestsimport osfrom tutorial.items import TutorialItemclass BaiduTieBaSpider(scrapy.spiders.Spider): name = 'baidutieba' start_urls = ['http://tieba.baidu.com/p/2235516502?see_lz=1&amp;pn=%d' % i for i in range(1, 38)] image_names = &#123;&#125; def parse(self, response): item = TutorialItem() item['image_urls'] = response.xpath(\"//img[@class='BDE_Image']/@src\").extract() for index, value in enumerate(item['image_urls']): number = self.start_urls.index(response.url) * len(item['image_urls']) + index self.image_names[value] = 'full/%04d.jpg' % number yield item 这里要关注Scrappy做的两件事情： 根据start_urls中的URL地址访问页面并得到返回 parse(self, response)函数就是抓取到页面之后的解析工作 那么首先就是start_urls的构造，这里是观察了百度贴吧里的URL规则，其中see_lz=1表示只看楼主，pn=1表示第一页，根据这些规则得出了一个URL数组。然后再观察单个页面的HTML源码，得出每个楼层发布的图片对应的img标签的类为BDE_Image，这样就可以得出xpath的表达式：xpath(&quot;//img[@class=&#39;BDE_Image&#39;]/@src&quot;)，来提取楼层中所有图片的src，赋值到item对象的image_urls字段中，当spider返回时，item会进入图片管道进行处理（即Scrapy会自自动帮你下载图片）。 对应的item类的编写和setting.py文件的修改详见上文的教程。 到这里下载图片的基本功能都完成了，但是有个问题：我想要按顺序保存图片怎么办？ 造成这个问题的关键就是Scrapy是多线程抓取页面的，也就是对于start_urls中地址的抓取都是异步请求，以及item返回之后到图片管道后对每张图片的URL也是异步请求，所以是无法保证每张图片返回的顺序的。 那么这个问题怎么解决呢？试了几种办法之后，得到一个相对理想的解决方案就是：制作一个字典，key是图片地址，value是对应的编号。所以就有了代码中的image_names和number = self.start_urls.index(response.url) * len(item[&#39;image_urls&#39;]) + index，然后再定制图片管道，定制的方法详见上文给出的教程链接，在本文中定制需要做的事情就是重写file_path函数，代码如下： 123456789101112131415161718192021import scrapyfrom scrapy.contrib.pipeline.images import ImagesPipelinefrom scrapy.exceptions import DropItemfrom tutorial.spiders.BaiduTieBa_spider import BaiduTieBaSpiderclass MyImagesPipeline(ImagesPipeline): def file_path(self, request, response=None, info=None): image_name = BaiduTieBaSpider.image_names[request.url] return image_name def get_media_requests(self, item, info): for image_url in item['image_urls']: yield scrapy.Request(image_url) def item_completed(self, results, item, info): image_paths = [x['path'] for ok, x in results if ok] if not image_paths: raise DropItem(\"Item contains no images\") item['image_paths'] = image_paths return item file_path函数就是返回每张图片保存的路径，当我们有一张完整的字典之后，只要根据request的URL去取相应的编号即可。 这个方法显然是比较消耗内存的，因为如果图片很多的话，需要维护的字典的条目也会很多，但从已经折腾过的几个解决方案（例如不用管道而采用手动阻塞的方式来下载图片）来看，它的效果是最好的，付出的代价也还算可以接受。 Scrappy入门第一个小demo就写到这里。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://findingsea.github.io/tags/Python/"}]},{"title":"所以，『读书』这么小的蛋糕，还要多少人来分呢？","slug":"E-book-reading-experience","date":"2015-09-01T12:18:36.000Z","updated":"2020-02-22T09:30:45.922Z","comments":true,"path":"2015/09/01/E-book-reading-experience/","link":"","permalink":"http://findingsea.github.io/2015/09/01/E-book-reading-experience/","excerpt":"前几天，刷RSS的时候突然刷出一条新闻——腾讯推出『微信阅读』，心里第一反应：霍，又来一个。 我本身可以算是一个『中度』阅读者，阅读的风格可见我的豆瓣书单。所以各种各样的阅读软件和阅读器都多多少少玩过，家里的纸质书更是多得满出书柜。","text":"前几天，刷RSS的时候突然刷出一条新闻——腾讯推出『微信阅读』，心里第一反应：霍，又来一个。 我本身可以算是一个『中度』阅读者，阅读的风格可见我的豆瓣书单。所以各种各样的阅读软件和阅读器都多多少少玩过，家里的纸质书更是多得满出书柜。 我刚开始读电子书用电子书阅读器的时候，身边人对于电子阅读还嗤之以鼻，Kindle还只有PaperWhite一代，多看的排版还能秒杀一切友商，豆瓣阅读还是那个又难看又难用还万年才更新一次的版本，其他的各种像掌阅（iReader）、GoodReader和Documents也是各有优劣。 到今天，Kindle换成了Voyage依然是我的主力阅读器，多看的精排优势在消失同时平台上开始充斥低质量书，豆瓣终于把它的阅读软件换上了自家的小清新风格，百度做了自己的百度阅读，淘宝有自己的淘宝阅读（还是挖了多看的高管，虽然现在看起来是要倒），京东也出了自己的阅读器，掌阅不再满足只做电子书平台也出了阅读器，然后就是最近腾讯也出手推出了微信阅读。 一瞬间，好像电子阅读这个市场突然就变得异常拥挤，小小的蛋糕却吸引得大批厂商蜂拥而至，但是毕竟现在一般人肯静下心阅读的时间就那么一点，根本经不起这样瓜分。不过电子阅读市场这么『繁荣』的样子，不禁让我想起当初自己对于各大平台的试水取舍经历。 电子书 VS 纸质书最早的电子书概念应该算是那些放在功能机（甚至是MP3）上的txt文件，那个时候我真是见识过在一次只能看一行的MP3上硬生生读完一大本小说的人，那样纯粹的阅读的乐趣现在也是很少了。 我当时在电子书和纸质书之间做抉择的时候，已经到了多看在Android上发出第一版的时间点了。当时我是大三到大四的暑假，已经在实习了，软件公司（导师公司）的工作时长会严重压缩的业余生活，每次早上7点半起床到晚上7点半吃完饭，基本上都算是工作时间，偏偏还遇上保持着『你主管都没走，你怎么能走』管理哲学的老板（导师），所以下班时间基本只晚不早。 就是在这样的背景下，我发现根本做不到像以前那样自在读书，一天除去工作和生活琐碎，已经没剩多少时间，而且书还没法随手就拿到，晚上有时候待教室有时候待实验室有时候直接回寝室，又不可能把书整天随身带却只为了能看那么半个小时。 在这样的情况下，电子书就变成一种不错的选择，电子书对比纸质书的优势点是非常明显的： 便携：其实就是带着手机就行，我们对手机的依赖程度，使得阅读电子书基本是零额外携带成本，完爆纸书。同时，邻近毕业了怎么处理自己那么多书一直是我的困扰，所以几乎每次都要一再遏制自己再买书的冲动，非常痛苦。 笔记：看纸书让我最头痛的一点就是做笔记，因为带着书就已经很不容易了，还要随身带着笔记本实在太麻烦，除非是去图书馆的这样专门的长时间的阅读行为，不然为了偶尔的几句笔记却需要额外带一个笔记本，实在接受不能（但是在真正需要记笔记却记不了的时候更令人抓狂）。电子书基本完美解决这个问题，做笔记基本算是各家电子书阅读软件最平常的必备功能，却完美解决了纸书的一大痛点。 碎片化阅读：很显然，现在在工作日还能挤出大段连续完整时间的人已经不多了，但是各种碎片空闲时间零零总总却也不少：等公交车等地铁的时间、排队买饭的时间、工作的间隙等等。这些时间单看都特鸡肋，长不长短不短，但是一天下来这些时间总和却不算少。而且这些时间由于各种局限，其实能做的事情并不多，但是很适合用来做手机上的短篇阅读。那些对上下文依赖没那么强的文本类型，都很适合在这些时候用电子书阅读，而且积少成多，一本书很快不知不觉就读完了（我在多看上看完的第一本书就是《黑客与画家》，基本可以算是用等车和坐车的碎片时间看完的）。 当然了，劣势也同样明显： 书少：纸质书本身作为记载人类智慧的最大载体，存在这上千年形成的巨大知识宝库，体量比电子书大太多了。而且纸质书一般都具有首发优势，加之很多书受版权限制暂时出不了电子版，都是电子书的巨大劣势。当然，价格可能也是一个，一本纸质书卖几十块钱没人会抱怨什么，但是一本电子书卖十几块钱就会有很多嫌贵了，毕竟大众没有培养起来为虚拟产品付费的奇怪（各类应用APP同理）。 排版差：纸质出版社，出版一本书需要大量的时间和人力成本放在排版设计和校对上，电子书出版不可能也花那么多时间和人力（首先是没有这么多资源，其次是如果这么做那电子书就会和纸质书定价差不多，那样更没人会买）。所以市面上的电子书（特指2012到2013年左右的那段时间），不管是官方的（亚马逊）还是个人的（盗版或是其他渠道），排版都不尽如人意，校对也是乱七八糟，即便是以精排版著称的多看也是有让人难以忍受的时候（当初在多看 for Kindle上看《基业长青》那个痛苦还历历在目）。 在车上用多看看完了几本书之后，我算是终于踩进了电子书的坑，在手机和iPad上常年保持着多看和豆瓣阅读，同时在毕业当天，买了一台Kindle。 多看阅读 多看的优点非常明显，而且保持地很好： 排版好：相对其他平台，多看更注重单本书的排版质量，而不是亚马逊式的先把量提上来。不过这个优势在渐渐变小，其一是由于别家的排版也开始渐渐好起来，前期冲量的时间段过去之后，大家都开始注重质了；其二是由于多看上的书多了之后，难以兼顾到每本书的质量（就像上文提到的《基业长青》，基本上几页就会有一个错别字、断行错误或者漏排之类的错误）。 多平台支持：就我用过而言，多看支持Kindle（不知道最新的型号还支不支持）、Android、iOS和Web，而且每个平台的体验都不错并且很统一，切换毫无压力且支持云同步。这个优势是非常吸引人的，豆瓣阅读不支持Kindle并且自家的APP做得难用，Kindle在Android和iOS上的APP体验简直槽糕透顶并且不支持Web。这个优势可以说多看保持到了现在，不过由于目前多看对Kindle有点战略性放弃的意思，所以在平台的支持性上豆瓣阅读已经慢慢和多看持平了。 笔记管理方便：多看支持标注、笔记和导出笔记到EverNote，这些基础功能多看做得有扎实又好，尤其是导出到EverNote这对我而言简直是Killer Feature（我是EverNote年付费用户）。别家的话，Kindle上做标注和笔记的体验不提也罢，豆瓣阅读上的笔记竟然不能同步到豆瓣读书上（起码当时是这样），完全浪费了豆瓣这么个大平台的优势。 很长一段时间以来，多看都是我首选的阅读平台，这得益于它以上的优点。但是入了Kindle之后，也渐渐少用了，毕竟多看的这些软件优势已经被逐渐赶上，但是Kindle的硬件优势暂时还无人撼动。 豆瓣阅读 我对豆瓣是相当有感情的，其一是豆瓣拥有我需求粘性最高的几个功能——书评、影评和音乐推荐等；其二是豆瓣是少数还没被我玩得乌烟瘴气的社交平台，也是少数我愿意打开推送的平台。 所以当发现豆瓣也开始（顺理成章地）进入电子书市场，我第一时间都开始用了，最大的体会就是豆瓣的优势还是在于它的软实力： 选书：豆瓣阅读的选书可以说秉承了一贯豆瓣平台的『高逼格』气质，有一段时间我想看的书只能在豆瓣阅读上找到，那自然我不会放弃这个平台。 平台：豆瓣阅读的背后是豆瓣这么大一个平台，所以它不仅仅是一个阅读软件，还是一个优质文字资源平台（优质的书和优质的作者）。 豆瓣阅读这个APP本身在第一个大版本号的时候真是惨不忍睹，尤其在多看的面前。当然这都是过去了，现在豆瓣阅读迎来第二个大版本号，全面改版，久违的小清新风格又回来了。 就发展而言，我非常看好豆瓣，原因在于： 以前留下的坑基本填完。现在书量也上去了，APP也改版了，和豆瓣平台的其他应用也增加了交互。 优点依旧。选书品味这事还真不是一天两天能练出来的，豆瓣阅读现在仍然保持了很高水平的单本质量，相比多看平台一打开就是各种『畅销书』，豆瓣阅读无疑有着更高的水准。 平台优势发挥。现在豆瓣阅读最吸引我的，反而是它的作家专栏，很多优质的知识不见得要写成书（成本问题），用专栏的方式更容易传播和阅读，但这个能做成的关键点就是要有一批优质的专栏作家，这恰恰是豆瓣在前期积累的成果，这个平台上聚集了一批专业能力和写作水平都属上乘的用户，放以前他们如果想在纸媒开专栏可能还是强人所难了，但是现在豆瓣阅读这个平台为他们提供了一个低门槛的专栏，那些愿意分享的用户只要提供内容就行，豆瓣提供了便捷的发布和良好的阅读体验。其实这个和知乎专栏的情况有点像，只是知乎自己不做阅读软件。这里需要注意的是，豆瓣阅读专栏门槛低成本低，可是是输出内容的质量一点也不低，这样的优势真是别的平台学不来呀。 Kindle Kindle有一种神奇的魔力，你没用过Kindle之前会觉得它丝毫没有吸引力，但是你一旦真正用它看过一两本书之后却再也停不下来，再也拿不起其他平台了。 Kindle是一种优缺点极其鲜明，优势劣势都极其大的存在： 媲美纸书的阅读体验：E-link水墨屏带来的是和纸书相差无几的视觉效果，它和LED屏的区别不是好坏，而是它们完全是两个世界的东西。一个阅读平台或者一款阅读器最最核心的功能毋庸置疑就是『看书』，其他的一切一切再好也只是装饰，你在使用产品的时候，80%的时间其实就是一动不动地看着屏幕而已。而在这80%的几乎零交互时间里，Kindle完爆其他同类产品。完美的水墨显示效果，现代电子产品上的复古打印风格，这种奇妙的组合真是拿起来就放不下。 安静：看书本来是一件非常个人的非常安静的活动，但是电子设备难免都会有各种纷繁复杂的功能，令人眼花缭乱的同时，也大大打扰了阅读的完整性。Kindle是纯粹地为阅读而存在的设备，所以使用Kindle阅读的过程中，除了你自己没什么能打断你。（其他设备不光是有各种其他应用，还包括可能会有反光，可能因为长时间握持太重了，这些都会打断你的阅读，而这些问题在Kindle上都不存在。） 平台：Kindle背后的Amazon真是太大了，这个平台的实力和野心都远远超过了上面提到的两家（豆瓣和小米）。Amazon前期快速地扩张书籍资源，在积累到一定量之后，再精细化，同时对阅读器本身的雕琢和改进却一直没有停止，最新的Voyage简直赏心悦目。所以Kindle之于多看和豆瓣阅读，有点像iPhone之于Android一样，它不仅是一个阅读软件，一个书库平台，它更是一个阅读器硬件，更是一个亚马逊巨大的资源整合（想象一下以后可以在Kindle上直接买外文书）。Kindle提供给了更闭环的平台生态，更贴近纸质书的阅读体验和更广阔的想象空间，没法不吸引人。 买Kindle几乎成为我最近几年最超值的消费，一年在Kindle上看掉的书要在20到30本左右。出了交互操作实在渣渣（E-link屏幕刷新频率的限制），其他都完美解决我的痛点（便携，阅读感和手持体验），尤其是最新版的Kindle Voyage，连以前有点受诟病的外观都变得出挑并且更进一步优化了握持体验。 有一个亚马逊官方统计显示：Kindle会增加用户的纸质书购买量——购买了Kindle的用户，他们购买纸质书的数量也随之增加了。也就是买了Kindle的人，Kindle让他爱上的不是Kindle，而是『读书』这件事本身。 最后这一两年，我的阅读量都在45到50本左右（不含杂志），其中电子书占比在50%左右。同时我感觉到电子书大大促进了我的阅读欲望，因为你能更方便地更快捷地接触到那些优秀的作品，所以这一年我的纸质书购买量不减反增（因为整体的阅读量上升了）。 现在买书的流程都是先审一遍书的评价，专业书和我觉得有收藏价值的书会直接买纸质，流行书是一般只（先）买电子版，看得好了再买纸质版用来收藏。 电子书的阅读也是Kindle为主，多看和豆瓣阅读为辅。主要感兴趣的书都在Kindle上看，杂志在多看上看，一些专栏和多看上未上架的书在豆瓣阅读上看。 最后，因为看到腾讯推出了微信阅读而有感而发的文章，不知不觉写了这么多。回到微信阅读上，我比较讨厌的是把读书的多少作为比拼的排行。在我看来，读书是非常私密的事情，分享当然是好的，但是用读书来比较难免失去了读书的初衷和快乐。 这世上有那么多作家那么多书，他们自有其存在的价值，我们要做的是尽量去多看多读，去见识更广阔的存在，去消弭身上的戾气和偏见。这么开心的事情，别搞得太功利了。：）","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"2015年8月阅读报告","slug":"august-reading-report","date":"2015-08-30T15:37:42.000Z","updated":"2020-02-22T09:30:45.921Z","comments":true,"path":"2015/08/30/august-reading-report/","link":"","permalink":"http://findingsea.github.io/2015/08/30/august-reading-report/","excerpt":"7月直接跳票了，因为实习刚入手，很多工作做起来效率很低，需要不停学习，所以整个月一本书也没读完。也正因为此，8月份格外努力（当然也是因为手头的工作都熟了，效率也提高了），共计读了6本书： 《灯下尘》，《我们仨》，《近在远方》，《永不退场：蒂姆·邓肯传》，《做个快乐读书人》和《被淹没和被拯救的》，以及两本自出版电子书：《硬派健身·减肥篇：知乎斌卡自选集 (知乎「盐」系列)》和《吃很重要》。","text":"7月直接跳票了，因为实习刚入手，很多工作做起来效率很低，需要不停学习，所以整个月一本书也没读完。也正因为此，8月份格外努力（当然也是因为手头的工作都熟了，效率也提高了），共计读了6本书： 《灯下尘》，《我们仨》，《近在远方》，《永不退场：蒂姆·邓肯传》，《做个快乐读书人》和《被淹没和被拯救的》，以及两本自出版电子书：《硬派健身·减肥篇：知乎斌卡自选集 (知乎「盐」系列)》和《吃很重要》。 以下内容，由豆瓣读书报告生成器自动生成。 《灯下尘》 推荐。作为一个读者，最幸福的事情莫过于能遇到一个可以一起成长的作者。诚然七堇年的水平和大作家们相差甚远，短篇总是过于无力，长篇略显拖沓，散文和随笔倒是尚可。可是她的文字总是弥漫出一种熟悉的氛围，如同和旧友谈天，你不用高山仰止，不用倾心受教，你们只是倾谈一些生活的感悟，用彼此熟悉的节奏，无论谈到哪个话题都不会尴尬，她平静而沉缓，却总有只言片语，恰好击中你的心和灵魂。所以，这世上大作家千千万，七堇年却只有一个。：） 《我们仨》 力荐。杨绛先生的文字简洁干练又带点小狡黠。才华不输须眉却甘为绿叶；人生几番大起大落却从不大声抱怨；名声在外却只愿安居一隅。所有这一切都从她的文字里细细流出。这是一本写一家人的书，满纸温馨本不奇怪，但想到这一家人所经历过的所有苦难，便能明白这温馨背后的巨大坚强。书中杨绛通篇都在寻找和构建一个『家』的概念，对她而言有默存和阿瑗的地方就是『家』，只是她现在又成了一个人，又失落了她的『家』，只能慢慢等待，等待踏上归途。 《近在远方》 一般。让我觉得很奇怪的是，为什么有这么多文章弥漫着一股暧昧的气氛，有很多跟主题无关的娇柔做作和无病呻吟，无法理解的约稿对象和审稿标准。包括七堇年自己的那篇，总有一股难以名状的和主题无关的情感，总有一种淹没感，一种过于灰色的情绪，难以赞同这种情绪成为旅行的主调。 《永不退场：蒂姆·邓肯传》 推荐。最近两年『21号新秀』和『未来是你的』的梗都被玩烂了，呆子和马刺在终将要到来的谢幕之前，又回到了篮球世界的舞台中央。相比于同时代奥胖洪荒巨兽般的统治力，KG不世出的天赋和铁血，科比燃不尽的斗志，纳什基德司机们的璀璨辉煌，邓肯更像一个沉默的将军，德州白沙如雪，我自横刀立马，淡看星起星落。在他身上你看不出变化，因为他足够强大，强大到在和时间的角力中可以胜出那么一点点。作为后乔丹时代最伟大的胜利者，虽然不及神在90年代只手遮天让整个联盟活在他的阴影下，但横跨三个十年的五个冠军足够让他在万神殿也有一个显赫的位置。最后多希望他能真的战胜时间，多希望他能在多年之后拥抱着詹姆斯的儿子，对他说：『未来是你的，但谢谢你让我们先拥有这个冠军。』：） 《做个快乐读书人》 老实说，这是一次选书没选准的阅读。本书是刘墉写过她女儿的，更准确点是他记录了教育女儿生活中的点点滴滴，然后写给长大之后的女儿和其他读者看的。我对刘墉的教育观念都没什么意见，典型的受了一点西方教育思想影响但根子里还是坚持传统的中式教育观，我自己也是抱持着差不多的观点。只是我本身不是这本书的受众，读起来难免感觉味道不够。 《被淹没和被拯救的》 力荐。非常沉重的一本书。作者是亲历了奥斯维辛集中营并幸存下来的犹太人。全书讨论了很多在极端环境下的人性——世俗的道德在集中营里是否还适用？人性中的灰色地带是否应该被审判？是什么让德意志在二战时陷入了民族性的麻木？集中营有多少无用的暴力？又有多少存在的意义？莱维博士是被拯救的，可更多的犹太人是被淹没在了集中营的白骨里，回顾痛苦的历史和记忆永远都是有意义的，这能让痛苦最大限度地只留在历史和记忆里。","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"Shortest Palindrome@LeetCode（以及关于KMP的理解）","slug":"Shortest-Palindrome-LeetCode","date":"2015-08-06T07:09:08.000Z","updated":"2020-02-22T09:30:45.921Z","comments":true,"path":"2015/08/06/Shortest-Palindrome-LeetCode/","link":"","permalink":"http://findingsea.github.io/2015/08/06/Shortest-Palindrome-LeetCode/","excerpt":"Shortest Palindrome用Java暴力是可以过的，思路也很简单：补充完成之后的回文串中心必定在原字符串中，所以原字符串以第一个字符为起点必然存在至少一个回文串（长度可以为1），那么任务就变为找到原字符串中以第一个字符为起点最长的回文串，找到之后剩下的工作就是把剩余部分的翻转补充到原字符串头部即可。","text":"Shortest Palindrome用Java暴力是可以过的，思路也很简单：补充完成之后的回文串中心必定在原字符串中，所以原字符串以第一个字符为起点必然存在至少一个回文串（长度可以为1），那么任务就变为找到原字符串中以第一个字符为起点最长的回文串，找到之后剩下的工作就是把剩余部分的翻转补充到原字符串头部即可。 这样代码逻辑就很简单，就是从原字符串的头部开始截取子串，长度递减，直到获取到第一个是回文串的子串，此时就找到了需要截断的部分，从该位置开始到原字符串末尾就是需要截取并翻转拼接的部分。算法复杂度是O(n^2)。 实现代码： 123456789101112131415161718192021222324252627public class Solution &#123; public String shortestPalindrome(String s) &#123; if (s == null || s.length() == 0 || s.length() == 1) return s; int len = s.length(), tail = len; StringBuilder builder = new StringBuilder(); while (1 &lt; tail) &#123; if (isPalindrome(s.substring(0, tail))) &#123; builder = builder.append(s.substring(tail, len)).reverse(); break; &#125; tail--; &#125; if (builder.length() == 0) &#123; builder = builder.append(s.substring(tail, len)).reverse(); &#125; return builder.append(s).toString(); &#125; private boolean isPalindrome(String str) &#123; int len = str.length(); for (int i = 0; i &lt; len / 2; i++) &#123; if (str.charAt(i) != str.charAt(len - i - 1)) return false; &#125; return true; &#125;&#125; LeetCode做多了也就知道O(n^2)的算法必然有改进版，自己思考了下没有悟出来，就参考了这篇文章：[LeetCode] Shortest Palindrome 最短回文串。 其实思路也很简单： 求字符串s的翻转s_rev 将两个字符串进行拼接：{s}#{s_rev} 找出新字符串中最长公共前缀后缀长度comLen s_rev.substring(0, s.length() - comLen)就是在原字符串头部插入的子串部分 举个例子： 对于字符串s：babcd，先求rev_s：dcbaba，拼接之后：babcd#dcbaba。上文已经解释过，s的前缀必然是一个回文串（长度可能为1），任务就是求这个回文串的最长长度，因此拼接之后的{s}#{s_rev}必然有公共前缀后缀，任务就是求这个公共前缀后缀的最长长度，那么这个时候就需要祭出KMP算法了。有了解的同学，估计一看就看出这个就是求KMP里的next数组。由于之前学KMP的时候也只学了个一知半解，所以这次又重新学习了下从头到尾彻底理解KMP（2014年8月22日版），这下对KMP又有更好的理解了。 详细的KMP算法上面提到的文章里讲的非常详细，就不从头说了。这里讲一讲我之前一直困惑现在理解了的点。 对于KMP算法，核心的地方就是求next数组，而求next数组中比较难理解的地方就是当当前位置的字符和目标字符不匹配的时候。对于字符串s，已经有p[0]到p[i-1]，且p[i-1]=j，求p[i]（p即next数组，其中p[k]表示从0到k位置为止公共前缀后缀的长度，例如：abacaba，公共前缀后缀长度是3，当p[k]=m则表示s.substring(0,m)和s.substring(k-m+1,k+1)是相等的）： 若s[i]=s[j]，也就是当前字符延续了之前的公共前缀后缀，那么p[i]=p[i-1]+1即可 若s[i]!=s[j]，即s.substring(0,j)和s.substring(i-j+1,i+1)是不匹配的，但是仍然可能存在s.substring(0,x)和s.substring(i-x+1,i+1)，这一点就是我以前最不能理解的地方，这次结题的经历加深了我这部分的理解。 到目前位置，期望i位置的最长公共前缀后缀为j+1的期望已经失败，那我是否可以期望下缩短长度之后能有匹配的公共前缀后缀呢？答案是肯定的，因为对于位置i-1来说，其实是可能存在多个公共前缀后缀的，只是p[i-1]只记录其中最长的，那么次长的是多少呢，答案就在p[j-1]里。对于位置i-1来说，已知0到j-1的子串和i-j+1到i-1子串是相等的，而对于位置j-1来说，从0到p[j-1]-1的子串和从j-p[j-1]到j-1的子串是相同的，更进一步和i-p[j-1]到i-1的子串也是相同的，那如果现在比较一下i和p[j-1]是否相等同样可以求出最长公共前缀后缀的值（因为p中记录是到每个位置为止的最长公共前缀后缀，所以这样每次递推下去每次得到都是当前可能的最长公共前缀后缀）。 梳理一下，就是对于位置i-1而言，公共前缀后缀的长度依次为：p[i-1],p[p[i-1]-1],p[p[p[i-1]-1]-1],……。在此基础上，对于位置i而言，只要比对某几个特定的位置，看s[i]是否能符合条件（即是否和当前公共前缀后缀后的第一个字符相等）就能求得p[i]的值。当然，如果比对某个位置的时候p[x]已经为0，那么就可以马上结束比较跳出循环，然后只要和首字母比对下就行了（因为这种情况说明可能的公共前缀后缀都已经被比对完了，s[i]依然不符合条件，那么只能从头开始了）。 应用了KMP之后的实现代码： 12345678910111213141516171819public class Solution &#123; public String shortestPalindrome(String s) &#123; StringBuilder builder = new StringBuilder(s); return builder.reverse().substring(0, s.length() - getCommonLength(s)) + s; &#125; private int getCommonLength(String str) &#123; StringBuilder builder = new StringBuilder(str); String rev = new StringBuilder(str).reverse().toString(); builder.append(\"#\").append(rev); int[] p = new int[builder.length()]; for (int i = 1; i &lt; p.length; i++) &#123; int j = p[i - 1]; while (j &gt; 0 &amp;&amp; builder.charAt(i) != builder.charAt(j)) j = p[j - 1]; p[i] = j == 0 ? (builder.charAt(i) == builder.charAt(0) ? 1 : 0) : j + 1; &#125; return p[p.length - 1]; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"我达达的马蹄是美丽的错误","slug":"beautiful-mistake","date":"2015-08-04T05:23:09.000Z","updated":"2020-02-22T09:30:45.921Z","comments":true,"path":"2015/08/04/beautiful-mistake/","link":"","permalink":"http://findingsea.github.io/2015/08/04/beautiful-mistake/","excerpt":"我打江南走过 那等在季节里的容颜如莲花的开落 东风不来，三月的柳絮不飞 你底心如小小寂寞的城","text":"我打江南走过 那等在季节里的容颜如莲花的开落 东风不来，三月的柳絮不飞 你底心如小小寂寞的城 恰若青石的街道向晚 音不响，三月的春帷不揭 你底心是小小的窗扉紧掩 我达达的马蹄是美丽的错误 我不是归人，是个过客…… —— 郑愁予《错误》","categories":[],"tags":[{"name":"life","slug":"life","permalink":"http://findingsea.github.io/tags/life/"}]},{"title":"不错过你","slug":"miss-you","date":"2015-07-22T08:43:28.000Z","updated":"2020-02-22T09:30:45.921Z","comments":true,"path":"2015/07/22/miss-you/","link":"","permalink":"http://findingsea.github.io/2015/07/22/miss-you/","excerpt":"","text":"我 错过春花和秋月 错过夏蝉与冬雪 却不错过你","categories":[],"tags":[{"name":"Life","slug":"Life","permalink":"http://findingsea.github.io/tags/Life/"}]},{"title":"Java+Windows+ffmpeg实现视频转换","slug":"Java-Windows-ffmpeg-video-convert","date":"2015-07-22T03:15:50.000Z","updated":"2020-02-22T09:30:45.921Z","comments":true,"path":"2015/07/22/Java-Windows-ffmpeg-video-convert/","link":"","permalink":"http://findingsea.github.io/2015/07/22/Java-Windows-ffmpeg-video-convert/","excerpt":"旧文，源地址见这里。 最近由于项目需要，研究了一下如何用Java实现视频转换，“着实”废了点心思，整理整理，写出给自己备忘下。","text":"旧文，源地址见这里。 最近由于项目需要，研究了一下如何用Java实现视频转换，“着实”废了点心思，整理整理，写出给自己备忘下。 思路由于之前没有没法过相关功能的经验，一开始来真不知道从哪里入手。当然，这个解决，google一下立马就发现了ffmpeg，网上讲解用Java+ffmpeg来进行视频转换的文章也不在少数，我主要参考的这篇文章。 上文提到的这篇文章，基本已经把开发流程什么的讲的很清楚了，这里总结下： 核心是利用ffmpeg进行视频转换，我们自己并不写转换视频的代码，只是调用ffmpeg，它会帮我们完成视频的转换。ffmpeg支持的类型有：asx，asf，mpg，wmv，3gp，mp4，mov，avi，flv等，这些类型，可以利用ffmpeg进行直接转换。ffmpeg不支持的类型有：wmv9，rm，rmvb等，这些类型需要先用别的工具（mencoder）转换为avi(ffmpeg能解析的)格式。 了解Java如何调用外部程序，这会是最困难的，也会是坑最多的地方。 根据我们的需求设置ffmpeg的参数。（这类文章网上已经有很多了，我也不用复制黏贴了，见这里） 代码上文中提到的那篇文章中的代码其实已经写的很友好了，基本拿来就能用，不过仍然存在许多问题，接下来会讲到，下面是文中的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153import java.io.File; import java.util.ArrayList; import java.util.Calendar; import java.util.List; public class ConvertVideo &#123; private final static String PATH = \"c:\\\\ffmpeg\\\\input\\\\c.mp4\"; public static void main(String[] args) &#123; if (!checkfile(PATH)) &#123; System.out.println(PATH + \" is not file\"); return; &#125; if (process()) &#123; System.out.println(\"ok\"); &#125; &#125; private static boolean process() &#123; int type = checkContentType(); boolean status = false; if (type == 0) &#123; System.out.println(\"直接将文件转为flv文件\"); status = processFLV(PATH);// 直接将文件转为flv文件 &#125; else if (type == 1) &#123; String avifilepath = processAVI(type); if (avifilepath == null) return false;// avi文件没有得到 status = processFLV(avifilepath);// 将avi转为flv &#125; return status; &#125; private static int checkContentType() &#123; String type = PATH.substring(PATH.lastIndexOf(\".\") + 1, PATH.length()) .toLowerCase(); // ffmpeg能解析的格式：（asx，asf，mpg，wmv，3gp，mp4，mov，avi，flv等） if (type.equals(\"avi\")) &#123; return 0; &#125; else if (type.equals(\"mpg\")) &#123; return 0; &#125; else if (type.equals(\"wmv\")) &#123; return 0; &#125; else if (type.equals(\"3gp\")) &#123; return 0; &#125; else if (type.equals(\"mov\")) &#123; return 0; &#125; else if (type.equals(\"mp4\")) &#123; return 0; &#125; else if (type.equals(\"asf\")) &#123; return 0; &#125; else if (type.equals(\"asx\")) &#123; return 0; &#125; else if (type.equals(\"flv\")) &#123; return 0; &#125; // 对ffmpeg无法解析的文件格式(wmv9，rm，rmvb等), // 可以先用别的工具（mencoder）转换为avi(ffmpeg能解析的)格式. else if (type.equals(\"wmv9\")) &#123; return 1; &#125; else if (type.equals(\"rm\")) &#123; return 1; &#125; else if (type.equals(\"rmvb\")) &#123; return 1; &#125; return 9; &#125; private static boolean checkfile(String path) &#123; File file = new File(path); if (!file.isFile()) &#123; return false; &#125; return true; &#125; // 对ffmpeg无法解析的文件格式(wmv9，rm，rmvb等), 可以先用别的工具（mencoder）转换为avi(ffmpeg能解析的)格式. private static String processAVI(int type) &#123; List&lt;String&gt; commend = new ArrayList&lt;String&gt;(); commend.add(\"c:\\\\ffmpeg\\\\mencoder\"); commend.add(PATH); commend.add(\"-oac\"); commend.add(\"lavc\"); commend.add(\"-lavcopts\"); commend.add(\"acodec=mp3:abitrate=64\"); commend.add(\"-ovc\"); commend.add(\"xvid\"); commend.add(\"-xvidencopts\"); commend.add(\"bitrate=600\"); commend.add(\"-of\"); commend.add(\"avi\"); commend.add(\"-o\"); commend.add(\"c:\\\\ffmpeg\\\\output\\\\a.avi\"); try &#123; ProcessBuilder builder = new ProcessBuilder(); builder.command(commend); builder.start(); return \"c:\\\\ffmpeg\\\\output\\\\a.avi\"; &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; // ffmpeg能解析的格式：（asx，asf，mpg，wmv，3gp，mp4，mov，avi，flv等） private static boolean processFLV(String oldfilepath) &#123; if (!checkfile(PATH)) &#123; System.out.println(oldfilepath + \" is not file\"); return false; &#125; // 文件命名 Calendar c = Calendar.getInstance(); String savename = String.valueOf(c.getTimeInMillis())+ Math.round(Math.random() * 100000); List&lt;String&gt; commend = new ArrayList&lt;String&gt;(); commend.add(\"c:\\\\ffmpeg\\\\ffmpeg\"); commend.add(\"-i\"); commend.add(oldfilepath); commend.add(\"-ab\"); commend.add(\"56\"); commend.add(\"-ar\"); commend.add(\"22050\"); commend.add(\"-qscale\"); commend.add(\"8\"); commend.add(\"-r\"); commend.add(\"15\"); commend.add(\"-s\"); commend.add(\"600x500\"); commend.add(\"c:\\\\ffmpeg\\\\output\\\\a.flv\"); try &#123; Runtime runtime = Runtime.getRuntime(); Process proce = null; String cmd = \"\"; String cut = \" c:\\\\ffmpeg\\\\ffmpeg.exe -i \" + oldfilepath + \" -y -f image2 -ss 8 -t 0.001 -s 600x500 c:\\\\ffmpeg\\\\output\\\\\" + \"a.jpg\"; String cutCmd = cmd + cut; proce = runtime.exec(cutCmd); ProcessBuilder builder = new ProcessBuilder(commend); builder.command(commend); builder.start(); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; &#125; 接下来是我自己经过修改后的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202import java.io.File;import java.io.IOException;import java.util.ArrayList;import java.util.Calendar;import java.util.List;public class ConvertVideo &#123; private static String inputPath = \"\"; private static String outputPath = \"\"; private static String ffmpegPath = \"\"; public static void main(String args[]) throws IOException &#123; getPath(); if (!checkfile(inputPath)) &#123; System.out.println(inputPath + \" is not file\"); return; &#125; if (process()) &#123; System.out.println(\"ok\"); &#125; &#125; private static void getPath() &#123; // 先获取当前项目路径，在获得源文件、目标文件、转换器的路径 File diretory = new File(\"\"); try &#123; String currPath = diretory.getAbsolutePath(); inputPath = currPath + \"\\\\input\\\\test.wmv\"; outputPath = currPath + \"\\\\output\\\\\"; ffmpegPath = currPath + \"\\\\ffmpeg\\\\\"; System.out.println(currPath); &#125; catch (Exception e) &#123; System.out.println(\"getPath出错\"); &#125; &#125; private static boolean process() &#123; int type = checkContentType(); boolean status = false; if (type == 0) &#123; System.out.println(\"直接转成flv格式\"); status = processFLV(inputPath);// 直接转成flv格式 &#125; else if (type == 1) &#123; String avifilepath = processAVI(type); if (avifilepath == null) return false;// 没有得到avi格式 status = processFLV(avifilepath);// 将avi转成flv格式 &#125; return status; &#125; private static int checkContentType() &#123; String type = inputPath.substring(inputPath.lastIndexOf(\".\") + 1, inputPath.length()) .toLowerCase(); // ffmpeg能解析的格式：（asx，asf，mpg，wmv，3gp，mp4，mov，avi，flv等） if (type.equals(\"avi\")) &#123; return 0; &#125; else if (type.equals(\"mpg\")) &#123; return 0; &#125; else if (type.equals(\"wmv\")) &#123; return 0; &#125; else if (type.equals(\"3gp\")) &#123; return 0; &#125; else if (type.equals(\"mov\")) &#123; return 0; &#125; else if (type.equals(\"mp4\")) &#123; return 0; &#125; else if (type.equals(\"asf\")) &#123; return 0; &#125; else if (type.equals(\"asx\")) &#123; return 0; &#125; else if (type.equals(\"flv\")) &#123; return 0; &#125; // 对ffmpeg无法解析的文件格式(wmv9，rm，rmvb等), // 可以先用别的工具（mencoder）转换为avi(ffmpeg能解析的)格式. else if (type.equals(\"wmv9\")) &#123; return 1; &#125; else if (type.equals(\"rm\")) &#123; return 1; &#125; else if (type.equals(\"rmvb\")) &#123; return 1; &#125; return 9; &#125; private static boolean checkfile(String path) &#123; File file = new File(path); if (!file.isFile()) &#123; return false; &#125; return true; &#125; // 对ffmpeg无法解析的文件格式(wmv9，rm，rmvb等), 可以先用别的工具（mencoder）转换为avi(ffmpeg能解析的)格式. private static String processAVI(int type) &#123; List&lt;String&gt; commend = new ArrayList&lt;String&gt;(); commend.add(ffmpegPath + \"mencoder\"); commend.add(inputPath); commend.add(\"-oac\"); commend.add(\"lavc\"); commend.add(\"-lavcopts\"); commend.add(\"acodec=mp3:abitrate=64\"); commend.add(\"-ovc\"); commend.add(\"xvid\"); commend.add(\"-xvidencopts\"); commend.add(\"bitrate=600\"); commend.add(\"-of\"); commend.add(\"avi\"); commend.add(\"-o\"); commend.add(outputPath + \"a.avi\"); try &#123; ProcessBuilder builder = new ProcessBuilder(); Process process = builder.command(commend).redirectErrorStream(true).start(); new PrintStream(process.getInputStream()); new PrintStream(process.getErrorStream()); process.waitFor(); return outputPath + \"a.avi\"; &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; // ffmpeg能解析的格式：（asx，asf，mpg，wmv，3gp，mp4，mov，avi，flv等） private static boolean processFLV(String oldfilepath) &#123; if (!checkfile(inputPath)) &#123; System.out.println(oldfilepath + \" is not file\"); return false; &#125; List&lt;String&gt; command = new ArrayList&lt;String&gt;(); command.add(ffmpegPath + \"ffmpeg\"); command.add(\"-i\"); command.add(oldfilepath); command.add(\"-ab\"); command.add(\"56\"); command.add(\"-ar\"); command.add(\"22050\"); command.add(\"-qscale\"); command.add(\"8\"); command.add(\"-r\"); command.add(\"15\"); command.add(\"-s\"); command.add(\"600x500\"); command.add(outputPath + \"a.flv\"); try &#123; // 方案1// Process videoProcess = Runtime.getRuntime().exec(ffmpegPath + \"ffmpeg -i \" + oldfilepath // + \" -ab 56 -ar 22050 -qscale 8 -r 15 -s 600x500 \"// + outputPath + \"a.flv\"); // 方案2 Process videoProcess = new ProcessBuilder(command).redirectErrorStream(true).start(); new PrintStream(videoProcess.getErrorStream()).start(); new PrintStream(videoProcess.getInputStream()).start(); videoProcess.waitFor(); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125;&#125;class PrintStream extends Thread &#123; java.io.InputStream __is = null; public PrintStream(java.io.InputStream is) &#123; __is = is; &#125; public void run() &#123; try &#123; while(this != null) &#123; int _ch = __is.read(); if(_ch != -1) System.out.print((char)_ch); else break; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 问题 原文的代码中有一个很大的问题，便是不知道视频转换到底什么时候结束。看原文中的这两处代码： 98行处 123builder.command(commend); builder.start(); return \"c:\\\\ffmpeg\\\\output\\\\a.avi\"; 145行处 123builder.start(); return true; 在进程开始之后，直接就返回结果了。要知道，这样的写法，是不会阻塞当前进程的，也就是说，当然程序返回的时候，转码程序（ffmpeg和mencoder）还在执行。如果需要mencoder进行中间转码，那原文中的写法会造成在avi文件还未转换完成时，程序就调用了ffmpeg进行转换。而对于最终的flv文件，我们也无法知道到底是什么时候转换好的，这显然是无法满足我们的业务需求的 。 解决方案 最先想到的办法自然就是阻塞当前进程（主进程），实例代码： 123Process process = new ProcessBuilder(command).start();process.waitFor();return true; 采用这种的方案运行程序，发现视频转到十几秒的时候就不转了，但是程序还没返回，打开进程管理器一开，ffmpeg进程还在，内存还占着，但是CPU为0。 当时不知道什么原因，在网上查了半天，才明白这是死锁了，但是不知道是什么原因造成的。当时就一直觉得死锁是waitFor()函数造成了，看来用它来判断子进程是否结果是不行了，所以又在网上查了半天其他判断子进程结束的办法（这里其实就已经走弯路了）。有人说可以用exitValue()，于是就有了下面的代码： 1234567891011Process process = new ProcessBuilder(command).start();while (true) &#123; try &#123; if (process.exitValue() == 0) break; &#125; catch (IllegalThreadStateException e) &#123; continue; &#125;&#125;return true; 当子进程没有结束的时候，如果执行exitValue()就会抛出异常，我采用的办法是捕获这个异常然后不去理他，直到程序结束exitValue()返回0为止。但是，还是失败了，出现的情况和用waitFor()方式时的一模一样，我才觉得可能是另外的原因，在去google，发现可能是是由于JVM只提供有限缓存空间，当外部程序（子进程）的输出流超出了这个有限空间而父进程又不读出这些数据，子进程会被阻塞waitFor()永远都不会返回，就会造成死锁。 官方解释： Because some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, and even deadlock. 知道问题了就要对症下药（其实当时我也不知道这是不是就是我遇到的问题，只能各种打散弹了，打中了算）。关于如何读出子进程的输出流，如何解决这个死锁，网上的办法都大同小异，写的比较好的可以看这个地址。 于是程序被改成这样： 123456789101112131415161718192021222324252627282930313233Process process = new ProcessBuilder(command).start(); new PrintStream(process.getInputStream()).start(); process.waitFor();PrintStream类如下：class PrintStream extends Thread &#123; java.io.InputStream __is = null; public PrintStream(java.io.InputStream is) &#123; __is = is; &#125; public void run() &#123; try &#123; while(this != null) &#123; int _ch = __is.read(); if(_ch != -1) System.out.print((char)_ch); else break; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行，发现还是不对，症状和之前的一模一样，我还以为是不是输出流太多了，一个线程读的不够快（好吧，真的很傻很天真，人被逼急了真的什么想法都有），于是我就再开了几个一模一样的线程，结果还是一样。 就在我快要放弃的时候，在百度知道上，看了个无关痛痒的例子，于是做了个小修改，在进程启动之前，重定向了下错误输出流，如下： 1234567Process videoProcess = new ProcessBuilder(command).redirectErrorStream(true).start(); new PrintStream(videoProcess.getInputStream()).start(); videoProcess.waitFor(); return true; 然后，然后，然后就可以了，凌乱。。。 结论 其实有两种写法可以解决这个问题，这种事像我上面那样写，还有一种如下： 123456789Process videoProcess = new ProcessBuilder(command).start(); new PrintStream(videoProcess.getErrorStream()).start(); new PrintStream(videoProcess.getInputStream()).start(); videoProcess.waitFor(); return true; 其实道理还是一样的，就是读出ffmpeg的输出流，避免ffmpeg的输出流塞满缓存造成死锁。但是不知道为什么，ffmpeg的输出信息是在错误输出流里面的，我看了下控制台打印结果，发现只是一些当前转换状态的信息，并没有错误，令人费解。 在Process类中，getInputStream用来获取进程的输出流，getOutputStream用来获取进程的输入流，getErrorStream用来获取进程的错误信息流。为了保险起见，在读出的时候，最好把子进程的输出流和错误流都读出来，这样可以保证清空缓存区。 其实，我深刻地感觉到，这些解决的问题的经历是标准的散弹式编程，打到哪算哪，以后引以为戒。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://findingsea.github.io/tags/Java/"},{"name":"Windows","slug":"Windows","permalink":"http://findingsea.github.io/tags/Windows/"},{"name":"ffmpeg","slug":"ffmpeg","permalink":"http://findingsea.github.io/tags/ffmpeg/"}]},{"title":"豆瓣阅读报告生成器","slug":"doubanreader-notes","date":"2015-07-20T02:36:10.000Z","updated":"2020-02-22T09:30:45.921Z","comments":true,"path":"2015/07/20/doubanreader-notes/","link":"","permalink":"http://findingsea.github.io/2015/07/20/doubanreader-notes/","excerpt":"DouBanReader是一个自动根据你的豆瓣读书标记生成读书报告的脚本。适用对象是像我这种豆瓣读书的重度用户，会在豆瓣上标记自己读过的每一本书，并且会很负责地打分与写review。对于这样的用户，这个项目可以帮你一键生成读书报告，并且格式化成MarkDown格式，之后你再发布到各大博客平台或者自己转成其他格式（HTML，PDF和图片等）都非常容易。","text":"DouBanReader是一个自动根据你的豆瓣读书标记生成读书报告的脚本。适用对象是像我这种豆瓣读书的重度用户，会在豆瓣上标记自己读过的每一本书，并且会很负责地打分与写review。对于这样的用户，这个项目可以帮你一键生成读书报告，并且格式化成MarkDown格式，之后你再发布到各大博客平台或者自己转成其他格式（HTML，PDF和图片等）都非常容易。 动机我自己自己是一个重度豆瓣读书用户（注意这里要区分豆瓣读书和豆瓣阅读的区别）。最近两年的年阅读量都在45到50本之间，今年上半年更是因为工作任务比较少的关系，有几个月的月阅读量都在5本以上。同时，我也信奉光读书不动笔相当于没读的道理，所以从去年开始，我就开始写每个月的阅读报告。那么这就带来一个问题——一篇阅读报告中，很多工作其实都是重复的： 对于每一个本书的review其实我已经在豆瓣读书上都写过了（一般刚一读完我就会着手写心得然后发在豆瓣读书上） 组织阅读报告格式时，要去豆瓣搜集书的信息：封面的图片和豆瓣链接 这些工作做起来又无聊又容易出错（复制黏贴很容易黏错或者黏漏了），所以我就萌生了做一个自动生成阅读报告的工具。 功能点做一个项目之前肯定要先确认需要做哪些功能点，所以这里先列一下这个项目的功能点以及完成情况。 豆瓣授权由于要读用户的豆瓣数据，那么就要接入豆瓣的API，那么就要先向豆瓣API申请授权。具体的授权流程可以参见：使用OAuth2.0访问豆瓣API，具体的豆瓣API说明可以参见：豆瓣开发者服务。 获取用户的读书信息核心功能点。要获取的数据分三块：图书链接、图书封面和用户书评(review)。同时这些数据的获取要能按照时间区间区分（用数字代表月份，0代表全年）。 主要调用API参见：图书Api V2。具体的流程分成两步： 获取用户在特定时间段内的『已读』数据信息集合（这一步就可以获取到图书链接和封面图片了） 获取用户对每本书的书评(review) 其中，第一步很好做，因为API直接提供了这些数据，第二点就是坑多且深，因为API并不直接提供，这也是非常值得吐槽的点：豆瓣的开放API有两版，但是V2现在就像是还没做完就放弃了一样，根本没有完全覆盖到V1，再具体到用户书评这一点上，V1虽然相较V2是提供了相关的接口，但是普通权限只能读一个人的所有书评并且还不是全文，高级权限也没有提供具体到特定用户对特定图书的书评的数据接口。 因此，对于第二步，还得将其拆分成三个小步骤：获取已读图书ID–&gt;获取相应图书所有书评–&gt;筛选出当前用户书评并直接获取相应页面信息–&gt;对书评页面的HTML代码进行正则匹配找出书评内容。本来在我看来是应该由API提供的数据，因为豆瓣开放平台没有提供，所以只能绕这么大一圈，而且还留下了很多隐患：遍历所有书评需要多次网络请求，增加了不可靠性；用正则匹配来处理HTML页面的时效性问题…… 生成MarkDown文件根据模板，将获取到的数据填充进去，生成一篇MarkDown格式的文章。具体的格式可以可以参见：四月份阅读报告 生成图片（未完成）设定这个功能的初衷本来是想方便发微博和微信，而且以为这个功能应该是有库可以支持和提供的。但是等到准备开始做的时候，调查一圈之后发现：库只有图片绘制库，想要完成这个功能需要自己写很多代码，而且如果想要生成的图片格式好看，需要的工作量不亚于再开一个小工程。有鉴于此，就将这个功能点先延后了，以后如果有时间的再进行补充。 豆瓣API的那些坑这个是我在做这个项目时，遇到的豆瓣开发平台的坑，坑是指在API文档中没有指明的或者很容易让人误解的地方，这些地方你遇到错误的时候完全不知道你自己错在哪里，等在网上查到原因的时候，第一反应就是：『卧槽，这文档上根本就没写嘛，这我怎么能知道？！』，或者『卧槽，这里怎么能这样设计，算几个意思呀，真特么麻烦呀！』。把这些坑写出来也是为了能给以后的开发人员节省点时间（虽然我现在都觉得以豆瓣API V2的这个质量，还有没有开发人员原因为其开发应用了）。 在获取access_token时（https://www.douban.com/service/auth2/token）需要在headers中加入&#39;Content-Type&#39;: ‘application/x-www-form-urlencoded’，不然会一直报400错误，提示”required_parameter_is_missing: client_id”。 在获取当前用户信息时（https://api.douban.com/v2/user/~me）需要在headers中加入&#39;Authorization&#39;: ‘Bearer ‘ + access_token，不然会一直报403错误。 获取用户书籍收藏信息时，所给出的时间区间参数需要带『时区』不然会被直接无视。正确的GET请求URL应为：api.douban.com/v2/book/user/findingsea_ly/collections?status=read&amp;from=2015-06-01T13:14:15+08:00&amp;to=2015-07-01T13:14:15+08:00。 豆瓣的API对于评论的读取限制非常多，没有办法用用户ID和图书ID就直接获取到特定用户对于特定图书的评论(reivew)，同时如果获取特定图书的所有评论信息进行遍历，其中也只能得到用户评论的summary（非全文，三个省略号结尾），暂时想到的办法也只能通过对所有信息的遍历，得到特定的那一条后再根据其中的评论链接，用爬虫进行爬取。 项目依赖由于生成图片的功能点没有完成，所以本次只额外用到了一个网络请求包：Requests: HTTP for Humans。 项目总结总体而言，DouBanReader是一个解决了我的实际需求的小项目，就功能点上来说，并没有难的地方，但同样能学到很多小细节，比如字符串写入文件前的格式化（Python2中文操作不可避免的）和正则表达式的使用技巧（去除各种空白、URL解析和HTML正则查找等）。所以我对这个项目的完成度和学习度就还是挺满意的，再接再厉吧。 GitHub - findingsea/DouBanReader 以上。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://findingsea.github.io/tags/Python/"},{"name":"项目总结","slug":"项目总结","permalink":"http://findingsea.github.io/tags/项目总结/"}]},{"title":"2015年6月阅读报告","slug":"jun-reading-report","date":"2015-07-14T11:05:51.000Z","updated":"2020-02-22T09:30:45.921Z","comments":true,"path":"2015/07/14/jun-reading-report/","link":"","permalink":"http://findingsea.github.io/2015/07/14/jun-reading-report/","excerpt":"六月份只读了2本书（因为实习入职准备和回家）：《全球通史(上)》和《程序员的呐喊》","text":"六月份只读了2本书（因为实习入职准备和回家）：《全球通史(上)》和《程序员的呐喊》 《全球通史(上)》 力荐。斯塔夫里阿诺斯教授在在历史学领域的权威性毋庸置疑，本书最大的特点在于：对历史的态度。书中多出明确表示出历史不仅仅只是过去发生的一些事情而已，历史是对今天的启发，而且在每一章的正文结束后，斯塔夫里阿诺斯教授都专门写了一小节关于这段历史对于今天的意义。同时，这本书的难点在于作者旨在完全一本贯穿人类起源时代到20世纪末的世界通史，所以在很多地方都力求精简篇幅，很多作者没有着墨的地方，就需要另外的背景资料来填充，才能使全书充分立体。所以读这套书的时候，你还不光是在读这一套书，其实你是在经历一场很宏大的历史洗礼，请保持你的谷歌和维基百科连接通畅。 《程序员的呐喊》 作者本身的技术背景毋庸置疑，基础应该是非常扎实工程能力够强经验也够老道，所以不少抱怨的确是在痛点上，不管是在语言上还是在工程上，读了很有共鸣。同时作者多年的大公司工作经历，也让其对于大公司软件工程架构的优缺点都了解地非常深入，说法也足够让人信服。但是同样又有很多牢骚实在是多余，使得文章写得拖拖拉拉婆婆索索，读起来让味道差了很多。","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"四月份阅读报告","slug":"april-reading-report","date":"2015-05-08T03:15:00.000Z","updated":"2020-02-22T09:30:45.920Z","comments":true,"path":"2015/05/08/april-reading-report/","link":"","permalink":"http://findingsea.github.io/2015/05/08/april-reading-report/","excerpt":"四月可谓是奋发图强，三月份搞定了实习之后，就开始更用功看书，所以四月份一口气读了9本书：《一路向前 : 星巴克创始人董事会主席霍华德·舒尔茨亲笔自传》，《观念的水位》，《费马大定理 : 一个困惑了世间智者358年的谜》，《不能承受的生命之轻》，《恶意》，《沉默的大多数 : 最新修订插图典藏版》，《王小波散文 : 插图珍藏版》，《开放的智力：知乎采铜自选集 (知乎「盐」系列)》和《深度学习的艺术：知乎采铜自选集 (知乎「盐」系列)》","text":"四月可谓是奋发图强，三月份搞定了实习之后，就开始更用功看书，所以四月份一口气读了9本书：《一路向前 : 星巴克创始人董事会主席霍华德·舒尔茨亲笔自传》，《观念的水位》，《费马大定理 : 一个困惑了世间智者358年的谜》，《不能承受的生命之轻》，《恶意》，《沉默的大多数 : 最新修订插图典藏版》，《王小波散文 : 插图珍藏版》，《开放的智力：知乎采铜自选集 (知乎「盐」系列)》和《深度学习的艺术：知乎采铜自选集 (知乎「盐」系列)》 《一路向前 : 星巴克创始人董事会主席霍华德·舒尔茨亲笔自传》 说实话，我自己是很喜欢星巴克，不管是门店整体的气氛和咖啡师的热情，都让我在星巴克的时候不论喝咖啡看书或者聊天都感觉非常自在，所以我也很好奇这家公司是如何形成这样的文化，就挑了这本书来看。从书里面看出，舒尔茨其实是很老派的人，但是是我喜欢的那种老派风格，这种风格也完美地体现在星巴克整体的装潢和咖啡制作，也是我在星巴克这么享受和自如的原因。但是有点令人失望的是，舒尔茨明显不是一个好作家，这本书本来是记录自2008年金融危机之后，星巴克面临一系列的困境，如何外部应对危机和内部推进改革。这其实是很好的题材和背景，但是舒尔茨写成了流水账和宣传资料，他在书里写了很多他在内部改革过程中的心路历程，可以感觉出他内心是真正相信他所坚持的星巴克的理念，并且尽力向世人传递这些理念。可惜就可惜在舒尔茨自己的写法实在是太琐碎，很多他渴望表达的东西翻来覆去写了很多遍，读的时候只好开启加速模式，唉，下次舒尔茨还是花钱请个专业的传记作家吧。 《观念的水位》 刘瑜的文章一读就知道书读得够多，而且难能可贵地不掉书袋。很多道理都能用浅白的语言组织出来的，时不时也不忘抖个机灵，至于具体深度够不够还得看你自己的深度够不够。只是这类评论集实在是看过太多，各种观点和写作特色也都见识过了，口味彻底被养叼，刘瑜到底也没带来新的惊喜。 《费马大定理 : 一个困惑了世间智者358年的谜》 这本书我非常推荐。写的非常浅显易懂，即便是文科生看懂整个逻辑也是没有任何问题（好像不小心黑了谁），配合BBC同名纪录片效果更佳呦。正经来说，这本书的最大价值在于，从一个非常好的侧面反应了解决一个数学（科学）问题所需要的付出有时是惊人的，也许要费尽一整代人的努力才能在问题中前进一小步，同时，那些为了追求真理和绝对正确而倾注了毕生心血的数学家（科学家）们，真正地推动了人类文明的前进，今天我们所享受的一切，追本溯源，也许就来自于他们的某一句证明，或者某一次实验。当然，我相信，还是会有人一辈子都无法理解为什么证明形如x^n + y^n = z^n 的不定方程在n &gt; 2时没有自然数解值得一代又一代这个星球上最聪明的人花费360年时间来完成。 《不能承受的生命之轻》 过于经典的作品，实在是难以评价。《轻》显然不是适合刚入门的人来读的书，所以很多人说看不懂。要像评价别的作品一样评价这本书，我的确是还做不到。这本书给我最大的收获，就是更深入理解了『媚俗』的原始概念，很多作家都提到过米兰·昆德拉和他所提出的『媚俗』，这次可谓是见到了真身。 《恶意》 东野圭吾对于人性的理解的角度之多，程度之深，真是不得不让人感叹。套用前言里的一句话： 《白夜行》为了爱粉身碎骨，《恶意》因为恨万劫不复。 《沉默的大多数 : 最新修订插图典藏版》和《王小波散文 : 插图珍藏版》 王小波杂文的高超之处在于反讽和教育意义的完美结合。令人会心一笑的黑色幽默和令人拍案的前瞻性并存。二十多年前的中文环境下写下的文字，到今天依然通读流畅，并且其中的道理依然适用当下的中国社会。即便读过那么多各式各样的评论集和杂文集，王小波依然是我认为最好的。 《开放的智力：知乎采铜自选集 (知乎「盐」系列)》和《深度学习的艺术：知乎采铜自选集 (知乎「盐」系列)》 采铜在知乎的回答一直质量很高，这次也算是系统地读了一遍。优点很明显：接地气，把理论化的东西用当下的语境通俗地表达出来，看了就能直接拿来指导自己；缺点同样明显：以一个个具体问题为起点的组织方式，难免使整体结构略显凌乱，在以知乎回答为内容主体的情况下，难免显得浅尝辄止点到即可。不过这本书还是反应了采铜广阔的阅读范围，作为一个通俗心理学主题阅读的接入点是非常好的。","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"三月份阅读报告","slug":"march-reading-report","date":"2015-05-08T03:13:00.000Z","updated":"2020-02-22T09:30:45.920Z","comments":true,"path":"2015/05/08/march-reading-report/","link":"","permalink":"http://findingsea.github.io/2015/05/08/march-reading-report/","excerpt":"由于2月过年期间落下了进度，所以3月边找实习边发奋看书。这个月总共看了6本书：《当彩色的声音尝起来是甜的》，《洗澡》，《乖，摸摸头》，《当我谈跑步时我谈些什么》，《引爆点 : 如何引发流行》和《信》。","text":"由于2月过年期间落下了进度，所以3月边找实习边发奋看书。这个月总共看了6本书：《当彩色的声音尝起来是甜的》，《洗澡》，《乖，摸摸头》，《当我谈跑步时我谈些什么》，《引爆点 : 如何引发流行》和《信》。 《当彩色的声音尝起来是甜的》 科学松鼠会出品，非常好的科普读物。虽然内容上我多少还是觉得过于偏向动物学植物学遗传学之类的，工科的东西太少，但仍不可否认，内容实用同时写的浅显易懂。把科学变成一件有趣的事情，并且用有趣的方式讲出来，这都是科学松鼠会一直追求并且努力实践的，这本书就是最好的证明。 《洗澡》 杨绛的文字功底不遑多说，我想即便和钱钟书相比也不遑多让。全书行文流畅，故事性很强。但是感觉美中不足的是，感觉结尾处理的过于简单了，感觉故事的起承转合都非常饱满，但是在接近尾声的时候，却戛然而止了，总让人有种故事没有讲完的遗憾。 《乖，摸摸头》 看完之后上豆瓣看了看评论，写了这样的评论： 与其说这是一本书，不如说是大冰的扯闲篇语录。抛开文学性，大冰讲故事起码是一把好手。他的故事或者文字，为我们展现了现在贫瘠的公共价值观下的另一些生活方式的可能。至于是不是鸡汤，认真读过一遍的人自然能够自行分辨。只是有些人可能自带鸡汤味蕾，喝清水都自带鸡汤味儿吧。 大冰的这本书的确不如第一本——《他们最幸福》，但是我觉得大冰的书的意义就在于给我们讲故事，故事告诉我们生活其实是有另外一种面貌的，无论你是不是追求，无论你是不是赞同，这世上还是有那么一群人，在随心地过着自己想要的生活，而且简单却又深刻地幸福着。 当时看完之后，我在豆瓣对这本书打了5星，评完分之后，突然意识到一个事实：我给《刀锋》只打了4星，我给《洗澡》只打了4星以及我给《看不见的城市》也只打了4星，而我却给大冰的这本书比这些成名大作都要高的评分。论文学性，论深刻程度，论传世性，这些做作家和这些作品，都在大冰和他的书之上。仔细想想为什么会这样之后，我发了条微博感叹下： 太纠结评分这事也是无奈，一本传世之作和一本当下畅销书，起评点根本就不在一个层次。 的确，以前我是很在意评分这种事，总觉得对一个作品的评价体现了一个人的品味和水准，在意识到上文说到的事情之后，我突然想起一句老话：『文无第一，武无第二』。一个读者所处的心境不同，他对一部作品的感知也是不同的了；同样，一个作家或者一部作品，处在的上下文不同，被赋予的期望不同，实现是很难用简单的4星或者5星来评价和比较。 想清楚了之后，感觉也许这就是文学的魅力吧，每一部作品都是这样的独特，每一个作家都是如此个性，正是它们的独特和他们个性，才形成了可以称之为璀璨的人类文学和文化史。 至于应该给每部作品打几分？ Forget it. 《当我谈跑步时我谈些什么》 出了名的『跑步书』，很多人因为看了这书，或者或多或少受这本书影响，爱上了跑步，然后一发不可收拾。你很容想象村上这种人就会喜欢长跑这种运动，平稳，缓慢而又韧性十足。简直可以完美地概括他的作品人格。 村上的文字胜在平静优雅，不做作。他是安静地诉说，你可以捧着一杯咖啡，安静地倾听。 《引爆点 : 如何引发流行》 非常好的一本解释关于引发流行和传播的社会心理学读物，读这类书的时候，我都喜欢做思维导图，感觉能比较清晰地把握到书里传递的知识。所以话不多说，直接放图。 ![《引爆点 : 如何引发流行》思维导图](http://findingsea-blog-images.qiniudn.com/The Tipping Point mind notes.png) 《信》 看惯了东野各种悬疑侦探小说之后，连看了《解忧杂货店》和《信》之后，对东野的整体评价和好感迅速提升。这本书里，东野对于人性的懦弱和生活的无奈，把握地无比准确。主人公的立场数次翻转，但每次都不知道这次是不是走到了一条正确的路上。 尤其是后半部分中，让武岛直贵稍微体会了下作为受害者一方的滋味之后，整本书折射出来的现实和无奈，更是让人持卷叹息。 人生很多时候，就和书里的故事一样——即便不一定是犯了这么严重的事——无论你觉得自己多么真诚与无奈，当把你放到视角的对面之后，你仍然会觉得原来的自己是多么的不可原谅。","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"二月份阅读报告","slug":"february-reading-report","date":"2015-05-08T03:11:00.000Z","updated":"2020-02-22T09:30:45.920Z","comments":true,"path":"2015/05/08/february-reading-report/","link":"","permalink":"http://findingsea.github.io/2015/05/08/february-reading-report/","excerpt":"二月份只读了两本书，低于预期：《霍比特人》和《月亮和六便士》。都觉得终于放假了有机会好好读书，反而发现其实越是有时间越是诱惑多越是不想看书越是看书少，越是没时间越是事情多越是想看越是看书多。","text":"二月份只读了两本书，低于预期：《霍比特人》和《月亮和六便士》。都觉得终于放假了有机会好好读书，反而发现其实越是有时间越是诱惑多越是不想看书越是看书少，越是没时间越是事情多越是想看越是看书多。 霍比特人 没有电影情节那么复杂，因为电影中是把很多旁支线路的情节也加进来丰富剧情了，书要更加纯粹一点。如果只是一本《霍比特人》那么真的是很好的炉边童话，但是加上魔戒等一系列剧情之后，那真的就是史诗级的神话了。也许看倦了各种宏大的场面和复杂的故事情节之后，回到一切最开始的地方，真是个不错的感觉。 月亮和六便士 可能是毛姆最著名的小说了。典型的毛姆式叙事风格，不紧不慢，仿佛一个文雅却略带点刻薄的英国老绅士，一边做着手边活，一边和你讲着他年轻时候的故事。思特里克兰德先生，这个世界总是对天才非常吝啬，尤其当他们的光芒还没有充分展现的时候。 上帝的磨盘转动很慢，但是却磨得很细。","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"Dungeon Game@LeetCode","slug":"dungeon-game-at-leetcode","date":"2015-05-06T02:45:00.000Z","updated":"2020-02-22T09:30:45.920Z","comments":true,"path":"2015/05/06/dungeon-game-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/05/06/dungeon-game-at-leetcode/","excerpt":"Dungeon Game","text":"Dungeon Game 典型的动态规划题。维护一个二维数组dungeon，dungeon[i][j]表示从第i行第j出发到终点所需要的最低血量（包含当前位置的消耗），最低血量不大于1。 递推公式为： 1dungeon[i][j] = Math.max(1, -dungeon[i][j] + Math.min(dungeon[i + 1][j], dungeon[i][j + 1])); 实现代码： 12345678910111213141516171819public class Solution &#123; public int calculateMinimumHP(int[][] dungeon) &#123; int rows = dungeon.length, cols = dungeon[0].length; dungeon[rows - 1][cols - 1] = Math.max(1, -dungeon[rows - 1][cols - 1] + 1); for (int j = cols - 2; j &gt;= 0; j--) &#123; dungeon[rows - 1][j] = Math.max(1, -(dungeon[rows - 1][j]) + dungeon[rows - 1][j + 1]); &#125; for (int i = rows - 2; i &gt;= 0; i--) &#123; for (int j = cols - 1; j &gt;= 0; j--) &#123; if (j == cols - 1) &#123; dungeon[i][j] = Math.max(1, -(dungeon[i][j]) + dungeon[i + 1][j]); &#125; else &#123; dungeon[i][j] = Math.max(1, -dungeon[i][j] + Math.min(dungeon[i + 1][j], dungeon[i][j + 1])); &#125; &#125; &#125; return dungeon[0][0]; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Maximum Gap@LeetCode","slug":"maximum-gap-at-leetcode","date":"2015-05-06T01:01:00.000Z","updated":"2020-02-22T09:30:45.920Z","comments":true,"path":"2015/05/06/maximum-gap-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/05/06/maximum-gap-at-leetcode/","excerpt":"Maximum Gap","text":"Maximum Gap 要求连续元素的最大差值，那必然要排序，但是又要求在O(n)的复杂度内完成，自然就想到了桶排序。维护left和right两个数组，left[i]表示第i个桶的最左端元素，right[i]表示第i个桶的最右端点元素。除最后一个桶之外，每个桶都是前闭后开，最后一个桶是前闭后闭。当元素落到相应的桶内就更新相应桶的最左最右元素值，当所有元素都放入桶中之后，对桶区间进行遍历，计算相邻桶的前桶最大元素和后桶最小元素的差值，最大差值即是题目所求。 这里需要注意的是，对于最小值为min，最大值为max，个数为n的数组，相邻元素的最大差值必然大于等于(max - min) / (n - 1)，所以用这个值作为桶区间的长度，这样可以保证最大差值必然出现在桶和桶之间。特别考虑最大差值等于(max - min) / (n - 1)的情况，此时数组中每个相邻元素的差值都是(max - min) / (n - 1)，那么每个桶内只要一个元素，同样最大差值出现在桶和桶之间，之前的计算方法依然适用。 1234567891011121314151617181920212223242526272829303132333435public class Solution &#123; public int maximumGap(int[] num) &#123; if (num.length &lt; 2) return 0; int minNum = num[0], maxNum = num[0], lengthOfNum = num.length; for (int i = 1; i &lt; lengthOfNum; i++) &#123; minNum = Math.min(minNum, num[i]); maxNum = Math.max(maxNum, num[i]); &#125; int step = (maxNum - minNum) / (lengthOfNum - 1); step = step == 0 ? 1 : step; int[] left = new int[(maxNum - minNum) / step + 1]; int[] right = new int[(maxNum - minNum) / step + 1]; for (int i = 0; i &lt; lengthOfNum; i++) &#123; int range = (num[i] - minNum) / step; if (range == left.length) range--; left[range] = left[range] == 0 ? num[i] : Math.min(left[range], num[i]); right[range] = right[range] == 0 ? num[i] : Math.max(right[range], num[i]); &#125; int maxGap = 0, leftMax = 0, rightMin = 0; for (int i = 0; i &lt; left.length; i++) &#123; if (left[i] == 0 &amp;&amp; right[i] == 0) continue; if (leftMax == 0) &#123; leftMax = right[i]; continue; &#125; rightMin = left[i]; maxGap = Math.max(maxGap, rightMin - leftMax); leftMax = right[i]; &#125; return maxGap; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"所以，再战一年吗？","slug":"so-one-more-time","date":"2015-05-05T02:22:00.000Z","updated":"2020-02-22T09:30:45.920Z","comments":true,"path":"2015/05/05/so-one-more-time/","link":"","permalink":"http://findingsea.github.io/2015/05/05/so-one-more-time/","excerpt":"马刺到底还是输了，虽然看了前六场之后多多少少有预感，以现在的状态，在斯台普斯，应该很难晋级了。但是当事实真的发生的时候，还是有点难以接受，尤其是以如此接近如此可惜的方式。","text":"马刺到底还是输了，虽然看了前六场之后多多少少有预感，以现在的状态，在斯台普斯，应该很难晋级了。但是当事实真的发生的时候，还是有点难以接受，尤其是以如此接近如此可惜的方式。 马刺犯了太多错误，无论是整个系列赛的状态问题，还是本场比赛很多细节，甚至是常规赛没能赢下鹈鹕，所有这一切今天都累加到了一起，终于把马刺逼上了绝路。 丹尼格林，整个系列赛投丢了太多应该进的三分球，在GDP逐渐退居二线的时候，他应该承担更多的责任。 莱昂纳德，没有了常规赛后段的稳定，尤其是最后两场，FMVP之后，他还需要一个系列赛证明自己的顶薪价值，可惜他错过了。 斯普利特，进攻端作用几乎归零了，在篮下处理球犯了太多太多错误。 迪奥，不能要求胖子更多了，虽然一手三分球是越来越不稳定了，但是他还是能在关键时刻出来帮助球队。 米尔斯，我始终觉得波波维奇给米尔斯的上场时间太少了，虽然我也理解一上米尔斯肯定会被保罗强吃，但是在帕克这种状态下，马刺太需要外线的一个稳定攻击点。 贝利内里，他已经做了他能做了的一切。 帕克，跑车的状态不好可以从很多方面解释，年纪大了，伤病，对保罗的防守消耗了太多体力，但是他仍然是第七场的罪人，犯了太多错误，尤其是快攻多打少和阵地战进攻选择上，而这些错误都被快船抓住了，巴恩斯，雷迪克，纷纷抓住这些错误，让快船留在了比赛中，直至等到了保罗的最后一球。 吉诺比利，秃子现在已经开始越来越边缘化了，去年他起码还能在板凳起来给出很多切入和三分，今年面对快船的运动能力和凶悍防守，他实在是突不进去也要不到犯规了。 邓肯，21号新秀几乎做到了一切，除了带走这个系列赛的胜利，内线单打，护框，协防，篮板，高位策应，他给出的已经远远超过人们的预料，可惜面对快船内线的凶残和本队内线的羸弱，他的付出还是显得无力了点。 波波维奇，做篮球教练做到老头这个层次，很多想法可能真不是我们所能理解的，也许他真的看到了很多我们没看到的东西，站在结果上反推总是很容易的，难的是在巨大压力下的临场决断，在常规对垒上，波波已经比里弗斯棋高一着了，在最后时刻，波波选择相信莱昂纳德，这也无可厚非，只是那些投丢的球和保罗最后的绝杀，已是天意，非他所能控制的。 已经输了，便无可抱怨，恭喜快船，他们完全配得上这个系列赛的胜利。 哨响之后，便该放下一切，篮球毕竟还不是生活的全部。 只是对马刺，对邓肯，对吉诺比利，有太多太多放不下的东西。 所以，老头们，再战一年吗？","categories":[],"tags":[{"name":"Life","slug":"Life","permalink":"http://findingsea.github.io/tags/Life/"}]},{"title":"Find Minimum in Rotated Sorted Array I II@LeetCode","slug":"find-minimum-in-rotated-sorted-array-i-ii-at-leetcode","date":"2015-05-05T01:40:00.000Z","updated":"2020-02-22T09:30:45.920Z","comments":true,"path":"2015/05/05/find-minimum-in-rotated-sorted-array-i-ii-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/05/05/find-minimum-in-rotated-sorted-array-i-ii-at-leetcode/","excerpt":"Find Minimum in Rotated Sorted Array","text":"Find Minimum in Rotated Sorted Array 其实直接遍历也是可以也可以AC，但是更加优化的解法应该是采用二分查找的思想。如果中间值比起点大就收缩起点，如果中间值比终点大就收缩终点，直到收缩到起点和终点相邻，也就是找到了翻转的部分。这里需要注意的是，数组可能是没有翻转过的，所以mid的初值赋0。 实现代码： 1234567891011121314151617public class Solution &#123; public int findMin(int[] num) &#123; int begin = 0, end = num.length - 1, mid = 0; while (num[begin] &gt; num[end]) &#123; if (end - begin == 1) &#123; mid = end; break; &#125; mid = (begin + end) / 2; if (num[begin] &lt; num[mid]) begin = mid; else end = mid; &#125; return num[mid]; &#125;&#125; Find Minimum in Rotated Sorted Array II理论上这题应该也用二分法，碰到起点终点相同的情况就只能进行遍历，但是那样代码会更复杂并且效率上并不见得提高多少，所以这里我直接采用遍历的方法。 实现代码： 12345678910111213141516public class Solution &#123; public int findMin(int[] num) &#123; int min = num[0], length = num.length; if (num[0] &gt;= num[length - 1]) &#123; int index = 1; while (index &lt; length) &#123; if (num[index - 1] &gt; num[index]) &#123; break; &#125; index++; &#125; min = index == length ? num[index - 1] : num[index]; &#125; return min; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Max Points on a Line@LeetCode","slug":"max-points-on-a-line-at-leetcode","date":"2015-05-04T11:26:00.000Z","updated":"2020-02-22T09:30:45.919Z","comments":true,"path":"2015/05/04/max-points-on-a-line-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/05/04/max-points-on-a-line-at-leetcode/","excerpt":"Max Points on a Line","text":"Max Points on a Line 题目本身不难，一次AC可能有点困难，因为要考虑的东西还是挺多的。两层循环，外层遍历所以点，内层遍历外层点之后的所有点，同时在内层循环用一个HashMap来保存每个斜率对应的，这样在内存循环中，斜率相同就代表是在同一条直线上了。这里要注意的有两点： 对于垂直与x轴的直线，采用Float.POSITIVE_INFINITY来表示它的斜率。 相同点，用一个变量专门来记录相同点有多少，在内层循环结束之后，加到总计数中。 其实总体思想就是：求出一点所在直线的最多点数是多少，然后对每个点都求一遍，那么最后必然得到了全局点数最多的直线，同时注意在外层循环算过的点在内层就不必再算，因为再算也不会比之前得到的点数更多，这样可以减少循环次数。 实现代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Definition for a point. * class Point &#123; * int x; * int y; * Point() &#123; x = 0; y = 0; &#125; * Point(int a, int b) &#123; x = a; y = b; &#125; * &#125; */public class Solution &#123; public int maxPoints(Point[] points) &#123; int length = points.length; if (length &lt; 3) return length; int max = 2; for (int i = 0; i &lt; length; i++) &#123; int pointMax = 1, samePointCount = 0; HashMap&lt;Double, Integer&gt; slopeCount = new HashMap&lt;Double, Integer&gt;(); Point origin = points[i]; for (int j = i + 1; j &lt; length; j++) &#123; Point target = points[j]; if (origin.x == target.x &amp;&amp; origin.y == target.y) &#123; samePointCount++; continue; &#125; double k; if (origin.x == target.x) &#123; k = Float.POSITIVE_INFINITY; &#125; else if (origin.y == target.y) &#123; k = 0; &#125; else &#123; k = ((float) (origin.y -target.y)) / (origin.x - target.x); &#125; if (slopeCount.containsKey(k)) &#123; slopeCount.put(k, slopeCount.get(k) + 1); &#125; else &#123; slopeCount.put(k, 2); &#125; pointMax = Math.max(pointMax, slopeCount.get(k)); &#125; pointMax += samePointCount; max = Math.max(pointMax, max); &#125; return max; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"LRU Cache@LeetCode","slug":"lru-cache-at-leetcode","date":"2015-04-28T02:25:00.000Z","updated":"2020-02-22T09:30:45.919Z","comments":true,"path":"2015/04/28/lru-cache-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/28/lru-cache-at-leetcode/","excerpt":"LRU Cache","text":"LRU Cache 数据结构用列表。get()和set()方法就不多讲，重要的是遇到下两种情况： 元素被访问过，要将其放到列表头部，实现函数：moveToHead(Node node) 元素个数达到最大值，删除尾部元素，实现函数：removeTail() 同时为了快速选中元素，就采用HashMap&lt;Integer, Node&gt;来保存键值。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class LRUCache &#123; private int capacity; private Node head, tail; private HashMap&lt;Integer, Node&gt; keyNodeMap; public LRUCache(int capacity) &#123; this.capacity = capacity; head = new Node(-1, -1); tail = new Node(0, 0); head.next = tail; tail.pre = head; this.keyNodeMap = new HashMap&lt;Integer, Node&gt;(); &#125; public int get(int key) &#123; Node node = keyNodeMap.get(key); if (node != null) &#123; moveToHead(node); return node.value; &#125; return -1; &#125; public void set(int key, int value) &#123; Node node = null; if (keyNodeMap.containsKey(key)) &#123; node = keyNodeMap.get(key); node.value = value; &#125; else &#123; node = new Node(key, value); if (keyNodeMap.size() == capacity) &#123; keyNodeMap.remove(removeTail()); &#125; keyNodeMap.put(key, node); &#125; moveToHead(node); &#125; private void moveToHead(Node node) &#123; if (node.pre != null || node.next != null) &#123; node.next.pre = node.pre; node.pre.next = node.next; &#125; node.next = head.next; head.next.pre = node; node.pre = head; head.next = node; &#125; private int removeTail() &#123; int lastKey = -1; if (tail.pre != head) &#123; Node lastNode = tail.pre; lastKey = lastNode.key; lastNode.pre.next = tail; tail.pre = lastNode.pre; lastNode = null; &#125; return lastKey; &#125; class Node&#123; int key; int value; Node pre; Node next; public Node(int k, int v) &#123; key = k; value = v; &#125; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Binary Tree Preorder/Postorder Traversal","slug":"binary-tree-preorder-slash-postorder-traversal","date":"2015-04-27T01:28:00.000Z","updated":"2020-02-22T09:30:45.919Z","comments":true,"path":"2015/04/27/binary-tree-preorder-slash-postorder-traversal/","link":"","permalink":"http://findingsea.github.io/2015/04/27/binary-tree-preorder-slash-postorder-traversal/","excerpt":"树的前序和后序遍历是树相关算法的基本。就不多加解释了，直接上代码。","text":"树的前序和后序遍历是树相关算法的基本。就不多加解释了，直接上代码。 Binary Tree Preorder Traversal123456789101112131415public class Solution &#123; public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; result = new LinkedList&lt;Integer&gt;(); generate(result, root); return result; &#125; private void generate(List&lt;Integer&gt; sequence, TreeNode node) &#123; if (node == null) return; sequence.add(node.val); generate(sequence, node.left); generate(sequence, node.right); &#125;&#125; Binary Tree Postorder Traversal123456789101112131415public class Solution &#123; public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; result = new LinkedList&lt;Integer&gt;(); generate(result, root); return result; &#125; private void generate(List&lt;Integer&gt; result, TreeNode node) &#123; if (node == null) return; generate(result, node.left); generate(result, node.right); result.add(node.val); &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Word Break I II@LeetCode","slug":"word-break-i-ii-at-leetcode","date":"2015-04-26T01:32:00.000Z","updated":"2020-02-22T09:30:45.919Z","comments":true,"path":"2015/04/26/word-break-i-ii-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/26/word-break-i-ii-at-leetcode/","excerpt":"Word Break","text":"Word Break 递归，基本属于暴力求解。但是纯暴力应该是过不了的，参考网上的办法，增加了一个unmatch集合，类型是HashSet，用来存放那些已经被验证过无法匹配的字符串，这样可以剪掉很多分支。 实现代码： 1234567891011121314151617181920public class Solution &#123; private Set&lt;String&gt; unmatch = new HashSet&lt;String&gt;(); public boolean wordBreak(String s, Set&lt;String&gt; dict) &#123; for (String prefix : dict) &#123; if (s.equals(prefix)) return true; if (s.startsWith(prefix)) &#123; String suffix = s.substring(prefix.length(), s.length()); if (!unmatch.contains(suffix)) &#123; if (wordBreak(suffix, dict)) return true; else unmatch.add(suffix); &#125; &#125; &#125; return false; &#125;&#125; Word Break II解法基本差不多，无非是增加记录路径的要求。这里唯一需要注意的是，在前面我们只要一找到符合条件的组合即可返回了，在这题中，一定要遍历所有情况之后再返回。当然，还是用了一个mismatch来剪分支。 实现代码： 1234567891011121314151617181920212223242526272829303132333435public class Solution &#123; public List&lt;String&gt; wordBreak(String s, Set&lt;String&gt; dict) &#123; List&lt;String&gt; result = new LinkedList&lt;String&gt;(); if (s.length() == 0) return result; generate(s, dict, new HashSet&lt;String&gt;(), result, new StringBuilder()); return result; &#125; private boolean generate(String s, Set&lt;String&gt; dict, Set&lt;String&gt; mismatch, List&lt;String&gt; result, StringBuilder sentence) &#123; if (s.length() == 0) &#123; result.add(sentence.toString()); return true; &#125; boolean canBreak = false; for (String word : dict) &#123; if (s.startsWith(word)) &#123; String suffix = s.substring(word.length(), s.length()); if (!mismatch.contains(suffix)) &#123; StringBuilder newSentence = new StringBuilder(sentence); if (newSentence.length() != 0) newSentence.append(\" \"); newSentence.append(word); if (generate(suffix, dict, mismatch, result, newSentence)) &#123; canBreak = true; &#125; else &#123; mismatch.add(suffix); &#125; &#125; &#125; &#125; return canBreak; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Copy List with Random Pointer@LeetCode","slug":"copy-list-with-random-pointer-at-leetcode","date":"2015-04-25T05:03:00.000Z","updated":"2020-02-22T09:30:45.919Z","comments":true,"path":"2015/04/25/copy-list-with-random-pointer-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/25/copy-list-with-random-pointer-at-leetcode/","excerpt":"Copy List with Random Pointer","text":"Copy List with Random Pointer 节点中需要拷贝的两个引用是next和random。next引用比较好拷贝，相当直接复制普通列表。而对于random则需要目标节点已存在才比较容易些拷贝代码，采用的办法就是构造一个HashMap，其中key是原节点，value是拷贝节点，在拷贝random引用的过程中，直接用map.get(node.random)来获取相应的目标节点即可。 实现代码： 1234567891011121314151617181920212223242526272829303132/** * Definition for singly-linked list with a random pointer. * class RandomListNode &#123; * int label; * RandomListNode next, random; * RandomListNode(int x) &#123; this.label = x; &#125; * &#125;; */public class Solution &#123; public RandomListNode copyRandomList(RandomListNode head) &#123; if (head == null) return null; RandomListNode targetNode = head, copyPreHead = new RandomListNode(-1), copyNode = copyPreHead; HashMap&lt;RandomListNode, RandomListNode&gt; copiedMap = new HashMap&lt;RandomListNode, RandomListNode&gt;(); while (targetNode != null) &#123; copyNode.next = new RandomListNode(targetNode.label); copiedMap.put(targetNode, copyNode.next); targetNode = targetNode.next; copyNode = copyNode.next; &#125; targetNode = head; copyNode = copyPreHead.next; while (targetNode != null) &#123; if (targetNode.random != null) &#123; copyNode.random = copiedMap.get(targetNode.random); &#125; targetNode = targetNode.next; copyNode = copyNode.next; &#125; return copyPreHead.next; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Candy@LeetCode","slug":"candy-at-leetcode","date":"2015-04-24T01:47:00.000Z","updated":"2020-02-22T09:30:45.919Z","comments":true,"path":"2015/04/24/candy-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/24/candy-at-leetcode/","excerpt":"Candy","text":"Candy 双向爬坡。从左到右爬一边，再从右到左爬一边。再累加所有值即可。 1234567891011121314151617181920public class Solution &#123; public int candy(int[] ratings) &#123; int[] candies = new int[ratings.length]; int last = ratings.length - 1; int result = 0; for (int i = 1; i &lt;= last; i++) &#123; if (ratings[i - 1] &lt; ratings[i]) &#123; candies[i] = candies[i - 1] + 1; &#125; &#125; for (int i = last - 1; i &gt;= 0; i--) &#123; if (ratings[i] &gt; ratings[i + 1]) &#123; candies[i] = Math.max(candies[i], candies[i + 1] + 1); &#125; result += candies[i]; &#125; result += ratings.length + candies[last]; return result; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Palindrome Partitioning I II@LeetCode","slug":"palindrome-partitioning-i-ii-at-leetcode","date":"2015-04-24T01:01:00.000Z","updated":"2020-02-22T09:30:45.919Z","comments":true,"path":"2015/04/24/palindrome-partitioning-i-ii-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/24/palindrome-partitioning-i-ii-at-leetcode/","excerpt":"Palindrome Partitioning","text":"Palindrome Partitioning 递归解法。遍历每一种组合情况，其实这样的解法并不是很高效，但是还是是可以顺利AC。 实现代码： 12345678910111213141516171819202122232425262728293031323334public class Solution &#123; public List&lt;List&lt;String&gt;&gt; partition(String s) &#123; List&lt;List&lt;String&gt;&gt; result = new LinkedList&lt;List&lt;String&gt;&gt;(); generate(result, new LinkedList&lt;String&gt;(), s); return result; &#125; private void generate(List&lt;List&lt;String&gt;&gt; result, LinkedList&lt;String&gt; list, String s) &#123; if (s.length() == 0) &#123; List&lt;String&gt; res = new LinkedList&lt;String&gt;(list); result.add(res); return; &#125; int length = s.length(); for (int i = 1; i &lt;= length; i++) &#123; String sub = s.substring(0, i); if (isPalindrome(sub)) &#123; list.add(sub); generate(result, list, s.substring(i, length)); list.remove(list.size() - 1); &#125; &#125; &#125; private boolean isPalindrome(String s) &#123; int len = s.length(); for (int i = 0; i &lt; len / 2; i++) &#123; if (s.charAt(i) != s.charAt(len - 1 - i)) &#123; return false; &#125; &#125; return true; &#125;&#125; Palindrome Partitioning II动态规划。维护一个boolean[][] isPalindrome二维数组，isPalindrome[i][j]表示s.substring(i, j)是否为回文串。递推公式：检查s.charAt(begin)和s.charAt(end)是否相等，如果相等就检查isPalindrome[begin + 1][end - 1]的值，也就是对一个isPalindrome[begin][end]的赋值复杂度是O(1)。另外维护一个numOfCuts数组，numOfCuts[i]表示分割s.substring(1, i)最少需要几个cut，这个值需要在每次找到一个回文串的时候就相应的更新一遍。 简单来说，就是找出所有的回文串，找的方法就是先判断当前起点和终点字符串是否相等，如果相等就进一步检查起点和终点之间的字符串是否是回文的，找到了回文串之后表示从当前起点前的位置到当前终点只需切一刀即可分割，以此与已有的分割方案进行比较即可。 实现代码： 123456789101112131415161718192021public class Solution &#123; public int minCut(String s) &#123; int length = s.length(); boolean[][] isPalindrome = new boolean[length][length]; int[] numOfCuts = new int[length + 1]; numOfCuts[0] = -1; for (int i = 1; i &lt; length + 1; i++) &#123; numOfCuts[i] = numOfCuts[i - 1] + 1; &#125; for (int end = 0; end &lt; length; end++) &#123; for (int begin = end; begin &gt;= 0; begin--) &#123; if (s.charAt(begin) == s.charAt(end) &amp;&amp; (end - begin &lt; 2 || isPalindrome[begin + 1][end - 1])) &#123; isPalindrome[begin][end] = true; numOfCuts[end + 1] = Math.min(numOfCuts[end + 1], numOfCuts[begin] + 1); &#125; &#125; &#125; return numOfCuts[numOfCuts.length - 1]; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Longest Consecutive Sequence@LeetCode","slug":"longest-consecutive-sequence-at-leetcode","date":"2015-04-22T05:42:00.000Z","updated":"2020-02-22T09:30:45.919Z","comments":true,"path":"2015/04/22/longest-consecutive-sequence-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/22/longest-consecutive-sequence-at-leetcode/","excerpt":"Longest Consecutive Sequence","text":"Longest Consecutive Sequence 本题直观的解法就是排序之后遍历，但是题目要求只用O(n)的复杂度，那么先排序显然是无法满足要求的。 那么这种『显然要遍历所有元素，但是却只给了O(n)的复杂度』，这样就想到了HashMap。把数组中的每个元素都放入一个HashMap中为key，value为boolean类型，表示该元素有没有访问过。然后，对于数组中的每个元素，要是没有被访问过，就对其进行计数——往前遍历及往后遍历，直到下一个元素不存在于表中为止。那么这样就保证了在整个计数过程中，所有元素都只被访问了一次。 实现代码： 12345678910111213141516171819202122232425262728293031323334public class Solution &#123; public int longestConsecutive(int[] num) &#123; HashMap&lt;Integer, Boolean&gt; visited = new HashMap&lt;Integer, Boolean&gt;(); int length = num.length, max = 0; for (int n : num) &#123; visited.put(n, false); &#125; for (int i = 0; i &lt; num.length; i++) &#123; int n = num[i]; if (visited.get(n)) &#123; continue; &#125; int count = 1; for (int left = n - 1; left &gt;= n - length + 1; left--) &#123; if (visited.containsKey(left)) &#123; visited.put(left, true); count++; &#125; else &#123; break; &#125; &#125; for (int right = n + 1; right &lt;= n + length - 1; right++) &#123; if (visited.containsKey(right)) &#123; visited.put(right, true); count++; &#125; else &#123; break; &#125; &#125; max = Math.max(max, count); &#125; return max; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Binary Tree Maximum Path Sum@LeetCode","slug":"binary-tree-maximum-path-sum-at-leetcode","date":"2015-04-21T02:27:00.000Z","updated":"2020-02-22T09:30:45.919Z","comments":true,"path":"2015/04/21/binary-tree-maximum-path-sum-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/21/binary-tree-maximum-path-sum-at-leetcode/","excerpt":"Binary Tree Maximum Path Sum","text":"Binary Tree Maximum Path Sum 动态规划+深度优先搜索。把大问题（求整棵树的路径最大值）拆分成小问题（每颗子树的路径最大值），递推公式为：当前树的路径最大值=max(左子树的路径最大值, 右子树的路径最大值)+当前根节点的值。以此来推出最后全树的最大路径值。 实现代码： 12345678910111213141516171819202122public class Solution &#123; private int max; public int maxPathSum(TreeNode root) &#123; if (root == null) return 0; max = root.val; traversal(root); return max; &#125; private int traversal(TreeNode node) &#123; int left = node.left == null ? 0 : traversal(node.left); int right = node.right == null ? 0 : traversal(node.right); left = left &lt;= 0 ? 0 : left; right = right &lt;= 0 ? 0 : right; max = Math.max(max, left + node.val + right); node.val = node.val + Math.max(left, right); return node.val; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Populating Next Right Pointers in Each Node I II@LeetCode","slug":"populating-next-right-pointers-in-each-node-i-ii-at-leetcode","date":"2015-04-20T00:23:00.000Z","updated":"2020-02-22T09:30:45.918Z","comments":true,"path":"2015/04/20/populating-next-right-pointers-in-each-node-i-ii-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/20/populating-next-right-pointers-in-each-node-i-ii-at-leetcode/","excerpt":"Populating Next Right Pointers in Each Node I","text":"Populating Next Right Pointers in Each Node I 树的广度优先搜索题。记录下每一层的节点总个数，然后根据广度优先搜索的原则进行遍历，将非null节点都加入到队列中，对于同一层中的节点，将其next指向队列中的下一个节点即可。 实现代码： 123456789101112131415161718192021222324public class Solution &#123; public void connect(TreeLinkNode root) &#123; if (root == null) return; LinkedList&lt;TreeLinkNode&gt; nodes = new LinkedList&lt;TreeLinkNode&gt;(); nodes.add(root); int numOfLevelTotal = 1; while (!nodes.isEmpty()) &#123; TreeLinkNode treeLinkNode = nodes.poll(); numOfLevelTotal--; if (treeLinkNode.left != null) &#123; nodes.add(treeLinkNode.left); &#125; if (treeLinkNode.right != null) &#123; nodes.add(treeLinkNode.right); &#125; if (numOfLevelTotal &gt; 0) &#123; treeLinkNode.next = nodes.getFirst(); &#125; else &#123; numOfLevelTotal = nodes.size(); &#125; &#125; &#125;&#125; Populating Next Right Pointers in Each Node II根据题目来说，这一题和上一次的区别在于： What if the given tree could be any binary tree? Would your previous solution still work? 但是由于之前所采用的方法并没有这种局限，所以直接拷贝过来也可以AC。 不过这里存在一个问题，仔细看题目里的要求： You may only use constant extra space. 理论上，采用队列的话是肯定没办法只是用常数额外内存的，但是LeetCode好像在这件事上没有检测的这么严，起码我写的Java代码和我看到的用递归解决的C++代码都可以通过。 那么如果硬要纠结一下这一条呢？不使用队列怎么做？ 其实也不难，只是思路要转变一下，就不能是遍历这一层同时连接这一层，而是遍历这一层连接下一层。那么比较重要的就是要记录每一层的头节点，由于每一层在被遍历的时候是已经连接好了的，所以不必担心找不到节点的问题，如果挨个找寻next节点的子节点即可，子节点先内部（相同父节点）连接，然后再连接到总链表中即可。 实现代码： 123456789101112131415161718192021222324252627282930313233public class Solution &#123; public void connect(TreeLinkNode root) &#123; TreeLinkNode levelHead = root, nextLevelHead = null; while (levelHead != null) &#123; TreeLinkNode node = levelHead, tail = null; while (node != null) &#123; if (node.left != null &amp;&amp; node.right != null) &#123; node.left.next = node.right; &#125; TreeLinkNode sub; if (node.left != null) sub = node.left; else if (node.right != null) sub = node.right; else sub = null; if (sub != null) &#123; if (nextLevelHead == null) &#123; nextLevelHead = sub; tail = sub; &#125; else &#123; tail.next = sub; &#125; while (tail.next != null) tail = tail.next; &#125; node = node.next; &#125; levelHead = nextLevelHead; nextLevelHead = null; &#125; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Distinct Subsequences@LeetCode","slug":"distinct-subsequences-at-leetcode","date":"2015-04-19T06:46:00.000Z","updated":"2020-02-22T09:30:45.918Z","comments":true,"path":"2015/04/19/distinct-subsequences-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/19/distinct-subsequences-at-leetcode/","excerpt":"Distinct Subsequences","text":"Distinct Subsequences 动态规划题。先用二维动态规划的思路解释下：设match是动态规划表，其中match[i][j]表示S.substring(0, i)对T.substring(0, j)有几种组成方式，递推公式为： 若S.charAt(i - 1) == T.charAt(j - )，则match[[i][j] = match[i - 1][j - 1] + match[i - 1][j]。 若S.charAt(i - 1) != T.charAt(j - 1)，则match[i][j] = match[i - 1][j]。 二维动态规划数组的实现代码如下： 12345678910111213141516171819public class Solution &#123; public int numDistinct(String S, String T) &#123; if (T.length() == 0) return 1; int rows = S.length() + 1, cols = T.length() + 1; int[][] dp = new int[rows][cols]; dp[0][0] = 1; for (int i = 1; i &lt; rows; i++) &#123; dp[i][0] = 1; for (int j = 1; j &lt; cols; j++) &#123; if (S.charAt(i - 1) == T.charAt(j - 1)) &#123; dp[i][j] = dp[i - 1][j - 1] + dp[i - 1][j]; &#125; else &#123; dp[i][j] = dp[i - 1][j]; &#125; &#125; &#125; return dp[rows - 1][cols - 1]; &#125;&#125; 那么能不能改成一维数组？ 仔细看一下递推公式，计算dp[i][j]需要的额外信息只有左边一格的旧制，那么就直接用hold将其保存起来不就好了，于是就可以把二维的动态规划数组优化成了一维的，对空间复杂度进行了改进。同时，进一步改进在于如果对于T中的某一位，前一位的构造已经失败（也就是构造到前一位的方位数为0），那么也就不用计算当前位了，直接进入下一层循环即可。 一维动态规划数组实现代码： 12345678910111213141516171819202122public class Solution &#123; public int numDistinct(String S, String T) &#123; if (T.length() == 0) &#123; return 1; &#125; int[] dp = new int[T.length() + 1]; dp[0] = 1; for (int i = 0; i &lt; S.length(); i++) &#123; int hold = 1; for (int j = 1; j &lt; dp.length; j++) &#123; if (dp[j - 1] == 0) break; int h = dp[j]; if (S.charAt(i) == T.charAt(j - 1)) &#123; dp[j] = hold + dp[j]; &#125; hold = h; &#125; &#125; return dp[dp.length - 1]; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Recover Binary Search Tree@LeetCode","slug":"recover-binary-search-tree-at-leetcode","date":"2015-04-19T01:47:00.000Z","updated":"2020-02-22T09:30:45.918Z","comments":true,"path":"2015/04/19/recover-binary-search-tree-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/19/recover-binary-search-tree-at-leetcode/","excerpt":"Recover Binary Search Tree","text":"Recover Binary Search Tree 根据BST树的特性来，对BST的中序遍历，得到的是一个升序数列。所以在遍历过程中检测出两个异常的位置，对其进行交换即可。 一旦有两个位置的节点被交换了，那么中序遍历就会出现有两个：Node[i] &gt; Node[i + 1]其中i是错误位置，Node[j] &lt; Node[j - 1]其中j是错误位置，遵循这个规律，找到相应的Node[i]和Node[j]对其进行交换（只交换val值）即可。 实现代码如下： 123456789101112131415161718192021222324252627282930313233343536public class Solution &#123; private TreeNode wrongLessNode; private TreeNode wrongLargerNode; private TreeNode preNode; public void recoverTree(TreeNode root) &#123; recover(root); if (wrongLessNode != null &amp;&amp; wrongLargerNode != null) &#123; int temp = wrongLessNode.val; wrongLessNode.val = wrongLargerNode.val; wrongLargerNode.val = temp; &#125; &#125; private void recover(TreeNode root) &#123; if (root == null) return; if (preNode == null &amp;&amp; root.left == null) &#123; preNode = root; &#125; recover(root.left); if (preNode != null &amp;&amp; root.val &lt; preNode.val) &#123; if (wrongLessNode == null) &#123; wrongLessNode = preNode; wrongLargerNode = root; &#125; else &#123; wrongLargerNode = root; return; &#125; &#125; preNode = root; recover(root.right); &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Interleaving String@LeetCode","slug":"interleaving-string-at-leetcode","date":"2015-04-17T02:18:00.000Z","updated":"2020-02-22T09:30:45.918Z","comments":true,"path":"2015/04/17/interleaving-string-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/17/interleaving-string-at-leetcode/","excerpt":"Interleaving String","text":"Interleaving String 动态规划题。用一个二维（也可以简化成一维的）boolean数组match[i][j]来表示str3.substring(0, i + j)能不能由str1.substring(0, i)和str2.substring(0, j)组成，递推公式： 1match[i][j] = (match[i - 1][j] &amp;&amp; str1.charAt(i - 1) == str3.charAt(i + j)) || (match[i][j - 1] &amp;&amp; str2.charAt(j - 1) == str3.charAt(i + j)) 需要注意的是，这里的match中，第一行代表了用str1去组成str3的情况，而第一列代表了用str2去组成str3的情况，这是为了方便循环中的递推计算，所以要注意match中的索引和str1以及str2中的索引并不是直接对应的。 最后，怎么把这个二维的DP优化成一维的呢，其实只要记住一个简单的道理：在递推公式中，dp[i][j]的计算不依赖dp[i - 1][j - 1]，那么这个二维DP就可以优化成一维的。因为在计算dp[i][j]时，dp[i - 1][j]和dp[i][j - 1]本来就是已知的。那么如果计算需要依赖dp[i - 1][j - 1]，还能优化吗？形式上可以，那就是在循环内用两个数组，前一个数组记录dp中上一行的结果，后一个数组用来计算当前行的，但其实这个方法并没有对内存进行太多优化，因为Java对于垃圾回收并不是发生在对象引用计数归0的那一刻，而是会选取一个时间进行统一回收，所以这种优化，该分配的内容一样还是分配出去了，并且本身一维数组的直观程度不如二维来得好，所以这种优化并不提倡。 实现代码： 123456789101112131415161718192021public class Solution &#123; public boolean isInterleave(String s1, String s2, String s3) &#123; if (s1.length() + s2.length() != s3.length()) return false; if (s1.length() == 0 || s2.length() == 0) return s3.equals(s1) || s3.equals(s2); boolean[] match = new boolean[s1.length() + 1]; match[0] = false; for (int i = 1; i &lt;= s1.length(); i++) &#123; match[i] = s1.charAt(i - 1) == s3.charAt(i - 1); &#125; for (int i = 0; i &lt; s2.length(); i++) &#123; match[0] = s3.charAt(i) == s2.charAt(i); for (int j = 1;j &lt; match.length; j++) &#123; match[j] = (match[j - 1] &amp;&amp; s1.charAt(j - 1) == s3.charAt(i + j)) || (match[j] &amp;&amp; s2.charAt(i) == s3.charAt(i + j)); &#125; &#125; return match[match.length - 1]; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Scramble String@LeetCode","slug":"scramble-string-at-leetcode","date":"2015-04-16T02:09:00.000Z","updated":"2020-02-22T09:30:45.918Z","comments":true,"path":"2015/04/16/scramble-string-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/16/scramble-string-at-leetcode/","excerpt":"Scramble String","text":"Scramble String 这一题的解法其实很简单，就是递归遍历所有情况，那么需要增加的就是提前检验，然后排出以减少递归的次数，从而改进效率。 提前检验的内容就是检验两个字符串的内容是否相同，这个内容是否相同指的是：两个字符串所包含的字符种类和每种字符出现的个数是否相同，如果这个不同就可以直接返回，不需要执行接下来的代码。 实现代码如下： 123456789101112131415161718192021222324252627282930public class Solution &#123; public boolean isScramble(String s1, String s2) &#123; if (s1.equals(s2)) return true; char[] s1chars = s1.toCharArray(); char[] s2chars = s2.toCharArray(); Arrays.sort(s1chars); Arrays.sort(s2chars); for (int i = 0; i &lt; s1chars.length; i++) &#123; if (s1chars[i] != s2chars[i]) return false; &#125; int half = 1; boolean result = false; while (half &lt; s1.length()) &#123; result = (isScramble(s1.substring(0, half), s2.substring(0, half)) &amp;&amp; isScramble(s1.substring(half, s1.length()), s2.substring(half, s2.length()))) || (isScramble(s1.substring(0, half), s2.substring(s2.length() - half, s2.length())) &amp;&amp; isScramble(s1.substring(half, s1.length()), s2.substring(0, s2.length() - half))); if (result) break; half++; &#125; return result; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Maximal Rectangle@LeetCode","slug":"maximal-rectangle-at-leetcode","date":"2015-04-16T01:19:00.000Z","updated":"2020-02-22T09:30:45.918Z","comments":true,"path":"2015/04/16/maximal-rectangle-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/16/maximal-rectangle-at-leetcode/","excerpt":"Maximal Rectangle","text":"Maximal Rectangle 这一题的核心算法其实和Largest Rectangle in Histogram一样，对每一行都求出每个元素对应的高度，这个高度就是对应的连续1的长度，然后对每一行都更新一次最大矩形面积，那么这个问题就变成了Largest Rectangle in Histogram，用相同的方法求解就行了。总结来说就是对矩阵中的每一行，执行一遍Largest Rectangle in Histogram算法。 实现代码： 123456789101112131415161718192021222324252627282930313233343536public class Solution &#123; public int maximalRectangle(char[][] matrix) &#123; if (matrix == null || matrix.length == 0) return 0; int largestRectangle = 0; int[] height = new int[matrix[0].length]; for (int i = 0; i &lt; matrix.length; i++) &#123; for (int j = 0; j &lt; matrix[0].length; j++) &#123; int h = matrix[i][j] - '0'; height[j] = h == 0 ? 0 : height[j] + 1; &#125; largestRectangle = Math.max(largestRectangle, largestRectangleArea(height)); &#125; return largestRectangle; &#125; private int largestRectangleArea(int[] height) &#123; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); int index = 0, largestArea = 0; while (index &lt; height.length) &#123; if (stack.isEmpty() || height[stack.peek()] &lt; height[index]) &#123; stack.push(index++); &#125; else &#123; int h = height[stack.pop()]; int w = stack.isEmpty() ? index : index - stack.peek() - 1; largestArea = Math.max(largestArea, h * w); &#125; &#125; while (!stack.isEmpty()) &#123; int h = height[stack.pop()]; int w = stack.isEmpty() ? height.length : height.length - stack.peek() - 1; largestArea = Math.max(largestArea, h * w); &#125; return largestArea; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Largest Rectangle in Histogram@LeetCode","slug":"largest-rectangle-in-histogram-at-leetcode","date":"2015-04-14T02:50:00.000Z","updated":"2020-02-22T09:30:45.917Z","comments":true,"path":"2015/04/14/largest-rectangle-in-histogram-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/14/largest-rectangle-in-histogram-at-leetcode/","excerpt":"Largest Rectangle in Histogram","text":"Largest Rectangle in Histogram 这道题目有一个规则要掌握：当图形处在上升期时（height[i] &lt; height[i + 1]），其实是不用计算面积的，因为在这种情况下再往前移动一格（i -&gt; i + 1）所能得到的面积必然更大；当图形处在下降期时（height[i] &gt; height[i + 1]），就要开始计算当前矩形的面积了，但是这个时候只知道右端点，如何知道左端点在哪呢？这就需要在遍历的时候，维护一个栈，这个栈里面保存的是最有可能的右端点，那么压栈呢？当每次出现比栈顶元素大的块是，就将其索引压栈，反之就是要计算机一次当前的矩形面积并和当前最大面积进行比较。 再多解释一下这个左端点栈的维护，因为这是做这一题的关键。 入栈：入栈的情形很简单，就是遇到了比当前栈顶元素还大的元素，那就把它的索引入栈，这其实是一种贪心，相当于先不计算矩阵的大小，因为如果下一个元素还要大，那么所能得到的矩阵大小必然比现在计算要来的大。 出栈：遇到当前元素对栈顶元素要小，那就说明以栈顶元素为高度的矩阵边界到了，那么就要将栈顶元素出栈，然后计算以其为高度的矩形的大小。 那么这个栈中的元素有两个性质： 栈顶元素和当前索引之间的所有元素（前闭后开的区间）都大于等于栈顶元素：因为一旦中间遇到了比栈顶元素小的元素，那么栈需要连续弹出，直至当前栈顶元素小于当前元素。 栈顶元素和栈中的第二元素之间的所有元素（前开后闭的区间）都大于等于栈顶元素：因为如果这中间有一个元素既大于栈中的第二个元素又小于栈顶元素，那么它应该在这中间被入栈，继而成为栈中第二个元素。 其实这个做法就是把数组中的每个元素都作为矩形高度，计算了一遍该高度下矩形的最大面积。只是每次都贪心最大，避免了重复计算，所以效率高。 实现代码如下： 123456789101112131415161718192021public class Solution &#123; public int largestRectangleArea(int[] height) &#123; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); int index = 0, largestArea = 0; while (index &lt; height.length) &#123; if (stack.isEmpty() || height[stack.peek()] &lt; height[index]) &#123; stack.push(index++); &#125; else &#123; int h = height[stack.pop()]; int w = stack.isEmpty() ? index : index - stack.peek() - 1; largestArea = Math.max(largestArea, h * w); &#125; &#125; while (!stack.isEmpty()) &#123; int h = height[stack.pop()]; int w = stack.isEmpty() ? height.length : height.length - stack.peek() - 1; largestArea = Math.max(largestArea, h * w); &#125; return largestArea; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Minimum Window Substring@LeetCode","slug":"minimum-window-substring-at-leetcode","date":"2015-04-13T02:24:00.000Z","updated":"2020-02-22T09:30:45.917Z","comments":true,"path":"2015/04/13/minimum-window-substring-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/13/minimum-window-substring-at-leetcode/","excerpt":"Minimum Window Substring","text":"Minimum Window Substring 典型的窗口操作题，维护两个哈希表，stdMap标准表，map当前表，标准表用来保存T中的字符信息，当前表用来保存当前窗口的字符信息。 对窗口的操作包括以下两个： 扩充窗口：将窗口的右端点尽力向右扩展，直至到包含所有标准表中的字符（窗口中的每个有效字符的数量大于等于标准表中对应字符的数量），一旦窗口中的有效字符的总数达到字典字符串的长度，就停止扩充。 收缩窗口：当扩充窗口结束时，表明当前窗口已经至少包含了标准表中的所有字符（以及相应的数量），但这时窗口还不是最小的，因为在扩充窗口的时候，可能对某一个字符串包含了多于标准表中的次数，由于窗口是要连续的，所以只要对左端点进行收缩即可，即将位于最左端的那些出现次数过多的字符进行舍弃，知道舍弃到当前字符在窗口中的出现字数刚好等于该字符在标准表中的次数，则说明窗口左端点已经无法再右移了，收缩窗口完成。然后计算一下当前窗口的长度，与所记录的最短长度进行比较，再进入下一轮的窗口扩充。 实现代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Solution &#123; public String minWindow(String S, String T) &#123; int begin = 0, end = 0, minBegin = 0, minSize = S.length(), count = 0; HashMap&lt;Character, Integer&gt; stdMap = new HashMap&lt;Character, Integer&gt;(); HashMap&lt;Character, Integer&gt; map = new HashMap&lt;Character, Integer&gt;(); for (int i = 0; i &lt; T.length(); i++) &#123; char ch = T.charAt(i); if (stdMap.containsKey(ch)) &#123; stdMap.put(ch, stdMap.get(ch) + 1); &#125; else &#123; stdMap.put(ch, 1); &#125; map.put(ch, 0); &#125; for (end = 0; end &lt; S.length(); end++) &#123; char ch = S.charAt(end); if (!stdMap.containsKey(ch)) &#123; continue; &#125; if (map.get(ch) &lt; stdMap.get(ch)) &#123; count++; &#125; map.put(ch, map.get(ch) + 1); if (count == T.length()) &#123; while (true) &#123; char c = S.charAt(begin); if (stdMap.containsKey(c)) &#123; if (map.get(c) &gt; stdMap.get(c)) &#123; map.put(c, map.get(c) - 1); &#125; else &#123; break; &#125; &#125; begin++; &#125; if (end - begin + 1 &lt; minSize) &#123; minSize = end - begin + 1; minBegin = begin; &#125; &#125; &#125; return count == T.length() ? S.substring(minBegin, minBegin + minSize) : \"\"; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Edit Distance@LeetCode","slug":"edit-distance-at-leetcode","date":"2015-04-12T06:47:00.000Z","updated":"2020-02-22T09:30:45.917Z","comments":true,"path":"2015/04/12/edit-distance-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/12/edit-distance-at-leetcode/","excerpt":"Edit Distance","text":"Edit Distance 典型的动态规划题目。维护一个二维数组dis[][]，dis[i][j]表示：word1的前i个元素与word2的前j个元素的edit distance值。递推关系为： 当word1[i] == word2[j]，dis[i][j] = dis[i][j - 1]。 当word[i] != word2[j]，dis[i][j] = min(dis[i - 1][j - 1], dis[i] [j - 1], dis[i - 1][j]) + 1。 解释一下第二种情况下的递推公式： dis[i][j] = dis[i - 1][j - 1] + 1意味着替换字符 dis[i][j] = dis[i - 1][j] + 1意味着删除字符 dis[i][j] = dis[i][j - 1] + 1意味着插入字符 实现代码： 1234567891011121314151617181920public class Solution &#123; public int minDistance(String word1, String word2) &#123; int[] result = new int[word1.length() + 1]; for (int i = 0; i &lt; result.length; i++) result[i] = i; for (int i = 0; i &lt; word2.length(); i++) &#123; int[] newResult = new int[result.length]; newResult[0] = i + 1; for (int j = 0; j &lt; word1.length(); j++) &#123; if (word1.charAt(j) == word2.charAt(i)) &#123; newResult[j + 1] = result[j]; &#125; else &#123; newResult[j + 1] = Math.min(result[j], Math.min(result[j + 1], newResult[j])) + 1; &#125; &#125; result = newResult; &#125; return result[result.length - 1]; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Text Justification@LeetCode","slug":"text-justification-at-leetcode","date":"2015-04-11T02:47:00.000Z","updated":"2020-02-22T09:30:45.917Z","comments":true,"path":"2015/04/11/text-justification-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/11/text-justification-at-leetcode/","excerpt":"Text Justification这一题主要考察的还是对边界条件的控制，并没有太高深的算法，但是编写的难度不低，而且想一次通过非常难。","text":"Text Justification这一题主要考察的还是对边界条件的控制，并没有太高深的算法，但是编写的难度不低，而且想一次通过非常难。 我采用的办法： 首先，筛选出一行中应该包括的单词，这里要考虑空格还要占用掉的长度，也就是除了当前的总长度之外，还需要记录下纯单词的长度，这样方便之后生成相应的空格。 然后，当当前记录的长度大于等于额定长度之后，就需要对当前内容进行格式化。单词的索引很容易算出，难点在于空格，因为空格需要遵循以下两个规则： 每两个单词之间必须要有一个空格 单词实现左右对齐之后，空格应该尽量平均，并且有需要的话越往左空格应该越多基于这两条原则，我的办法是先计算平均空格长度，那么所有的空格要么是等于平均空格长度，要么是等于平均空格长度加1，在拼接空格的时候，计算当前剩余的空格总数以每个位置填入平均空格数是否可以填满，以此来判断具体当前位置需要填入的空格数。 实现代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class Solution &#123; public List&lt;String&gt; fullJustify(String[] words, int L) &#123; int index = 0, last = 0, count = 0, wordsLenCount = 0, wordsCount = 0; List&lt;String&gt; result = new ArrayList&lt;String&gt;(); if (L == 0) &#123; result.add(words[0]); return result; &#125; while (index &lt; words.length) &#123; if (count + words[index].length() &gt;= L) &#123; int spaceCount; int aveSlot = 0; if (count + words[index].length() &gt; L) &#123; spaceCount = L - wordsLenCount; if (wordsCount &gt; 1) aveSlot = spaceCount / (wordsCount - 1); index--; &#125; else &#123; wordsLenCount += words[index].length(); wordsCount++; spaceCount = L - wordsLenCount; if (wordsCount &gt; 1) aveSlot = spaceCount / (wordsCount - 1); &#125; StringBuffer buffer = new StringBuffer(\"\"); for (int i = index - wordsCount + 1; i &lt;= index; i++) &#123; buffer.append(words[i]); int sCount; if (wordsCount &gt; 1) &#123; if (spaceCount % aveSlot == 0 &amp;&amp; spaceCount / aveSlot == wordsCount - 1) &#123; sCount = aveSlot; &#125; else &#123; sCount = aveSlot + 1; &#125; spaceCount -= sCount; wordsCount--; &#125; else &#123; sCount = spaceCount; &#125; for (int j = 0; j &lt; sCount; j++) &#123; buffer.append(' '); &#125; &#125; result.add(buffer.toString()); count = 0; wordsLenCount = 0; wordsCount = 0; last = index + 1; &#125; else &#123; count += words[index].length() + 1; wordsLenCount += words[index].length(); wordsCount++; &#125; index++; &#125; if (last &lt; words.length) &#123; StringBuffer buffer = new StringBuffer(\"\"); for (int i = last; i &lt; words.length; i++) &#123; buffer.append(words[i]); if (words[i].length() &gt; 0) buffer.append(\" \"); &#125; for (int i = buffer.length(); i &lt; L; i++) &#123; buffer.append(\" \"); &#125; result.add(buffer.toString()); &#125; return result; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Valid Number@LeetCode","slug":"valid-number-at-leetcode","date":"2015-04-10T01:52:00.000Z","updated":"2020-02-22T09:30:45.917Z","comments":true,"path":"2015/04/10/valid-number-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/10/valid-number-at-leetcode/","excerpt":"Valid Number这一题主要的难点还是要考虑的边界条件太多，而且有些情况下，指数和底数需要考虑的还不一样，就更增加了难度。","text":"Valid Number这一题主要的难点还是要考虑的边界条件太多，而且有些情况下，指数和底数需要考虑的还不一样，就更增加了难度。 我的做法如下： 首先，对字符串左右去空格，然后根据字符e来进行划分，e之前的归为底数，e之后的归为指数。这个时候在使用Java的split()函数时要注意的时当分隔符是原字符串的首字母时，拆分之后的数组的第一个元素会是空字符串。所以，其实我们在去空格之后就可以对原字串做一些判断，直接筛选掉一些明显错误的情况。 然后，对指底数字符串和指数字符串分别进行遍历，那么遍历过程中最需要注意的就是对小数点.的检测。专门设置一个boolean变量还表示当前检测的字符串是不是小数，在第一次检测到小数点.且其后还有内容的时候，对这个值赋true，当再一次出现小数点的时候即可判断当前字符串不合法。还有一点就是遍历前先检测符号，这一点不需多说。 实现代码： 123456789101112131415161718192021222324252627282930313233343536373839public class Solution &#123; public boolean isNumber(String s) &#123; boolean result = true; s = s.trim(); if (s.length() == 0 || s.charAt(0) == 'e' || s.charAt(s.length() - 1) == 'e' || splitArr.length &gt; 2) return false; String[] splitArr = s.split(\"e\"); for (int k = 0; k &lt; splitArr.length; k++) &#123; String str = splitArr[k]; boolean isDecimal = false; if (str.charAt(0) == '-' || str.charAt(0) == '+') str = str.substring(1, str.length()); if (str.length() == 0) &#123; result = false; break; &#125; for (int i = 0; i &lt; str.length(); i++) &#123; if ('0' &lt;= str.charAt(i) &amp;&amp; str.charAt(i) &lt;= '9') continue; else if (str.charAt(i) == '.' &amp;&amp; !isDecimal) &#123; if (k != 1 &amp;&amp; str.length() &gt; 1) &#123; isDecimal = true; &#125; else &#123; result = false; break; &#125; &#125; else &#123; result = false; break; &#125; &#125; if (!result) break; &#125; return result; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Insert Interval@LeetCode","slug":"insert-interval-at-leetcode","date":"2015-04-08T04:04:00.000Z","updated":"2020-02-22T09:30:45.917Z","comments":true,"path":"2015/04/08/insert-interval-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/08/insert-interval-at-leetcode/","excerpt":"Insert Interval","text":"Insert Interval 这道题我今天重新看我以前提交的代码时，差点看吐了，巨复杂无比，先上代码，然后再分析为什么我当初会这样写。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class Solution &#123; public List&lt;Interval&gt; insert(List&lt;Interval&gt; intervals, Interval newInterval) &#123; Comparator&lt;Interval&gt; comparator = new Comparator&lt;Interval&gt;() &#123; @Override public int compare(Interval o1, Interval o2) &#123; if (o1.start == o2.start) return o1.end - o2.end; return o1.start - o2.start; &#125; &#125;; Collections.sort(intervals, comparator); boolean inserted = false; int index = 0; while (index &lt; intervals.size()) &#123; int re = cmpInterval(newInterval, intervals.get(index)); switch (cmpInterval(newInterval, intervals.get(index))) &#123; case -2: if ((0 &lt; index &amp;&amp; intervals.get(index - 1).end &lt; newInterval.start) || index == 0) intervals.add(index, newInterval); inserted = true; break; case -1: intervals.get(index).start = newInterval.start; if (0 &lt; index &amp;&amp; intervals.get(index - 1).end &gt;= intervals.get(index).start) &#123; intervals.get(index - 1).end = Math.max(intervals.get(index).end, intervals.get(index - 1).end); intervals.remove(intervals.get(index)); &#125; inserted = true; break; case 0: inserted = true; break; case 1: intervals.get(index).end = newInterval.end; index++; break; case 2: if (index == intervals.size() - 1) &#123; intervals.add(newInterval); inserted = true; &#125; else &#123; index++; &#125; break; case 3: intervals.remove(intervals.get(index)); break; default: continue; &#125; if (inserted) break; &#125; if (intervals.size() == 0 || intervals.get(intervals.size() - 1).end &lt; newInterval.start) &#123; intervals.add(newInterval); &#125; return intervals; &#125; public int cmpInterval(Interval toInsert, Interval interval) &#123; if (toInsert.start &lt; interval.start) &#123; if (toInsert.end &lt; interval.start) return -2; else if (interval.start &lt;= toInsert.end &amp;&amp; toInsert.end &lt;= interval.end) return -1; else return 3; &#125; else if (interval.start &lt;= toInsert.start &amp;&amp; toInsert.start &lt;= interval.end) &#123; if (interval.start &lt;= toInsert.end &amp;&amp; toInsert.end &lt;= interval.end) return 0; else return 1; &#125; else &#123; return 2; &#125; &#125;&#125; 我当时的想法非常朴素，就是用带插入的区间去原区间列表中一个个比较，问题就出在这个比较的结果会很多，可以看到我代码里面用了5个值来代表5中不同的比较结果（这里的前后是以数轴为坐标）： -2：待插入区间位于当前区间前方，且无重叠部分 -1：待插入区间位于当前区间前方，但有重叠部分 3： 待插入区间包含当前区间 0：待插入区间包含于当前区间 1：待插入区间位于当前区间后方，但有重叠部分 2：待插入区间位于当前区间后方，且无重叠部分 是不是看着都蛋疼，的确，重新看代码的时候，我也是花了好久才理清这所有情况，这样的代码可读性实在太差，而且是在太复杂。其实这题非常非常容易想到思路，尤其是当你已经做过前一题Merge Intervals，只要稍微细看就知道这题只是前一题的稍微变形，解决的方法只要把新区间插入到原区间数组中，然后重新合并下即可，具体的合并方法在Merge Intervals@LeetCode中给出。 本题的具体的实现代码如下： 123456789101112131415161718192021222324252627public class Solution &#123; public List&lt;Interval&gt; insert(List&lt;Interval&gt; intervals, Interval newInterval) &#123; List&lt;Interval&gt; result = new ArrayList&lt;Interval&gt;(); if (intervals == null) return result; intervals.add(newInterval); Comparator&lt;Interval&gt; comparator = new Comparator&lt;Interval&gt;() &#123; @Override public int compare(Interval o1, Interval o2) &#123; if (o1.start == o2.start) &#123; return o1.end - o2.end; &#125; return o1.start - o2.start; &#125; &#125;; Collections.sort(intervals, comparator); for (Interval interval : intervals) &#123; int last = result.size(); if (last == 0 || result.get(last - 1).end &lt; interval.start) &#123; Interval interval1 = new Interval(interval.start, interval.end); result.add(interval1); &#125; else &#123; result.get(last - 1).end = Math.max(interval.end, result.get(last - 1).end); &#125; &#125; return result; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Java 用自定义类型作为HashMap的键","slug":"java-custom-key-in-hashmap","date":"2015-04-07T09:53:00.000Z","updated":"2020-02-22T09:30:45.917Z","comments":true,"path":"2015/04/07/java-custom-key-in-hashmap/","link":"","permalink":"http://findingsea.github.io/2015/04/07/java-custom-key-in-hashmap/","excerpt":"这是Java中很经典的问题，在面试中也经常被问起。其实很多书或者文章都提到过要重载hashCode()和equals()两个方法才能实现自定义键在HashMap中的查找，但是为什么要这样以及如果不这样做会产生什么后果，好像很少有文章讲到，所以写这么一篇来说明下。","text":"这是Java中很经典的问题，在面试中也经常被问起。其实很多书或者文章都提到过要重载hashCode()和equals()两个方法才能实现自定义键在HashMap中的查找，但是为什么要这样以及如果不这样做会产生什么后果，好像很少有文章讲到，所以写这么一篇来说明下。 首先，如果我们直接用以下的Person类作为键，存入HashMap中，会发生发生什么情况呢？ 12345678public class Person &#123; private String id; public Person(String id) &#123; this.id = id; &#125;&#125; 12345678910111213141516171819import java.util.HashMap;public class Main &#123; public static void main(String[] args) &#123; HashMap&lt;Person, String&gt; map = new HashMap&lt;Person, String&gt;(); map.put(new Person(\"001\"), \"findingsea\"); map.put(new Person(\"002\"), \"linyin\"); map.put(new Person(\"003\"), \"henrylin\"); map.put(new Person(\"003\"), \"findingsealy\"); System.out.println(map.toString()); System.out.println(map.get(new Person(\"001\"))); System.out.println(map.get(new Person(\"002\"))); System.out.println(map.get(new Person(\"003\"))); &#125;&#125; 那么输出结果是什么呢？ 1234&#123;Person@6e4d4d5e=henrylin, Person@275cea3=findingsea, Person@15128ee5=findingsealy, Person@4513098=linyin&#125;nullnullnull 我们可以看到，这里出现了两个问题： 在添加的过程中，我们将key=new Person(&quot;003&quot;)的键值对添加了两次，那么在期望中，HashMap中应该只存在一对这样的键值对，因为key（期望中）是相同的，所以不应该重复添加，第二次添加的value=&quot;findingsealy&quot;应该替换掉原先的value=&quot;henrylin&quot;。但是在输入中，我们发现期望中的情况并没有出现，而是在HashMap同时存在了value=&quot;findingsealy&quot;和value=&quot;henrylin&quot;的两个键值对，并且它们的key值还是不相同的，这显然是错误的。 在获取value值时，我们分别用三个Person对象去查找，这三个对象和我们刚刚存入的三个key值（在期望中）是相同的，但是查找出的却是三个null值，这显然也是错误的。 那么，正确的方法其实在很多地方都是被描述过了，直接对Person类进行修改，重载equals和hashCode方法，修改过后的Person类如下： 12345678910111213141516171819202122232425public class Person &#123; private String id; public Person(String id) &#123; this.id = id; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Person person = (Person) o; if (id != null ? !id.equals(person.id) : person.id != null) return false; return true; &#125; @Override public int hashCode() &#123; return id != null ? id.hashCode() : 0; &#125;&#125; 那么，当我们重新执行上述的检验程序时，得到的结果如下： 1234&#123;Person@ba31=findingsea, Person@ba32=linyin, Person@ba33=findingsealy&#125;findingsealinyinfindingsealy 可以看到，之前指出的亮点错误都得到了改正。那么，为什么会这样呢？ 在HashMap中，查找key的比较顺序为： 计算对象的Hash Code，看在表中是否存在。 检查对应Hash Code位置中的对象和当前对象是否相等。 显然，第一步就是要用到hashCode()方法，而第二步就是要用到equals()方法。在没有进行重载时，在这两步会默认调用Object类的这两个方法，而在Object中，Hash Code的计算方法是根据对象的地址进行计算的，那两个Person(&quot;003&quot;)的对象地址是不同的，所以它们的Hash Code也不同，自然HashMap也不会把它们当成是同一个key了。同时，在Object默认的equals()中，也是根据对象的地址进行比较，自然一个Person(&quot;003&quot;)和另一个Person(&quot;003&quot;)是不相等的。 理解了这一点，就很容易搞清楚为什么需要同时重载hashCode()和equals两个方法了。 重载hashCode()是为了对同一个key，能得到相同的Hash Code，这样HashMap就可以定位到我们指定的key上。 重载equals()是为了向HashMap表明当前对象和key上所保存的对象是相等的，这样我们才真正地获得了这个key所对应的这个键值对。 还有一个细节，在Person类中对于hashCode()的重在方法为： 1234@Overridepublic int hashCode() &#123; return id != null ? id.hashCode() : 0;&#125; 这里可能有疑惑的点在于：为什么可以用String类型的变量的Hash Code作为Person类的Hash Code值呢？这样new Person(new String(&quot;003&quot;))和new Person(new String(&quot;003&quot;))的Hash Code是相等的吗？ 来看看以下代码的输出： 1234System.out.println(\"findingsea\".hashCode());System.out.println(\"findingsea\".hashCode());System.out.println(new String(\"findingsea\").hashCode());System.out.println(new String(\"findingsea\").hashCode()); 1234728795174728795174728795174728795174 可以看到四条语句的输出都是相等的，很直观的合理的猜测就是String类型也重载了hashCode()以根据字符串的内容来返回Hash Code值，所以相同内容的字符串具有相同的Hash Code。 同时，这也说明了一个问题：为什么在已知hashCode()相等的情况下，还需要用equals()进行比较呢？就是因为避免出现上述例子中的出现的情况，因为根据对Person类的hashCode()方法的重载实现，Person类会直接用id这个String类型成员的Hash Code值作为自己的Hash Code值，但是很显然的，一个Person(&quot;003&quot;)和一个String(&quot;003&quot;)是不相等的，所以在hashCode()相等的情况下，还需要用equals()进行比较。 以下例子可以作为上述说明的佐证： 1234System.out.println(new Person(\"003\").hashCode()); // 47667System.out.println(new String(\"003\").hashCode()); // 47667System.out.println(new Person(\"003\").equals(new String(\"003\"))); // false 以上即是全部。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://findingsea.github.io/tags/Java/"}]},{"title":"Merge Intervals@LeetCode","slug":"merge-intervals-at-leetcode","date":"2015-04-07T01:22:00.000Z","updated":"2020-02-22T09:30:45.917Z","comments":true,"path":"2015/04/07/merge-intervals-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/07/merge-intervals-at-leetcode/","excerpt":"Merge Intervals","text":"Merge Intervals 这也是一题我有点不太能理解为什么可以标为hard的题目。解法其实很直观，就是先对interval进行排序，然后遍历一遍。这里需要注意的点有两个： 对interval进行排序需要构造一个比较器。 在遍历过程中，如果结果集合为空或者当前interval与结果集合中的最后一个interval不重叠，那么就直接将当前interval直接加入到结果集合中；如果发生了重叠，那么将结果集合的最后一个interval的右端点改为当前interval的右端点。 实现代码： 12345678910111213141516171819202122232425public class Solution &#123; public List&lt;Interval&gt; merge(List&lt;Interval&gt; intervals) &#123; List&lt;Interval&gt; result = new ArrayList&lt;Interval&gt;(); Comparator&lt;Interval&gt; comparator = new Comparator&lt;Interval&gt;() &#123; @Override public int compare(Interval o1, Interval o2) &#123; if (o1.start == o2.start) &#123; return o1.end - o2.end; &#125; return o1.start - o2.start; &#125; &#125;; Collections.sort(intervals, comparator); for (Interval interval : intervals) &#123; int last = result.size(); if (last == 0 || result.get(last - 1).end &lt; interval.start) &#123; Interval newInterval = new Interval(interval.start, interval.end); result.add(newInterval); &#125; else &#123; result.get(last - 1).end = Math.max(interval.end, result.get(last - 1).end); &#125; &#125; return result; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"N-Queens I II@LeetCode","slug":"n-queens-at-leetcode","date":"2015-04-06T06:39:00.000Z","updated":"2020-02-22T09:30:45.916Z","comments":true,"path":"2015/04/06/n-queens-at-leetcode/","link":"","permalink":"http://findingsea.github.io/2015/04/06/n-queens-at-leetcode/","excerpt":"N-Queens","text":"N-Queens N皇后问题，非常经典。同时也是非常传统的递归方法解决。 递归的主体很简单：对于当前位置，分别尝试下放皇后和不放皇后两种情况。这里有两个需要注意的地方： 在递归函数中，在一次递归中，对整行进行遍历，这样相当于在检查的时候就不需要对当前行进行检查了，因为赋值的时候已经保证了当前行只有一个皇后。 定义一个检查函数，分别对之前已经赋值过的位置上同一列和斜列上是否有皇后存在，如果有就返回false；遍历全部位置之后都没有就返回true。 实现代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class Solution &#123; public List&lt;String[]&gt; solveNQueens(int n) &#123; List&lt;String[]&gt; result = new ArrayList&lt;String[]&gt;(); if (n == 0) return result; generate(new int[n][n], 0, result); return result; &#125; private void generate(int[][] board, int row, List&lt;String[]&gt; queens) &#123; int n = board.length; if (row == n) &#123; String[] strArr = new String[n]; for (int i = 0; i &lt; n; i++) &#123; StringBuffer sb = new StringBuffer(\"\"); for (int j = 0; j &lt; n; j++) &#123; if (board[i][j] == 0) sb.append(\".\"); else sb.append(\"Q\"); &#125; strArr[i] = sb.toString(); &#125; queens.add(strArr); return; &#125; for (int col = 0; col &lt; board.length; col++) &#123; board[row][col] = 1; if (!check(board, row, col)) &#123; board[row][col] = 0; continue; &#125; else &#123; generate(board, row + 1, queens); board[row][col] = 0; &#125; &#125; &#125; private boolean check(int[][] board, int row, int col) &#123; int i = row - 1, j = col; while (i &gt;= 0) &#123; if (board[i][j] == 1 || (j - row + i &gt;= 0 &amp;&amp; board[i][j - row + i] == 1) || (j + row - i &lt; board.length &amp;&amp; board[i][j + row - i] == 1)) &#123; return false; &#125; i--; &#125; return true; &#125;&#125; N-Queens II最后顺便提一句这题的进阶版——N-Queens II，在这个系列中，这个设置也是很奇怪，如果用如上方法解决了第一题，那么第二题只要改一下返回值就行了，即求一下集合的的size()。 详细代码如下： 123456789101112131415161718192021222324252627282930313233343536373839public class Solution &#123; public int totalNQueens(int n) &#123; List&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;(); if (n == 0) return 0; generate(new int[n][n], 0, result); return result.size(); &#125; private void generate(int[][] board, int row, List&lt;Integer&gt; queens) &#123; int n = board.length; if (row == n) &#123; queens.add(1); return; &#125; for (int col = 0; col &lt; board.length; col++) &#123; board[row][col] = 1; if (!check(board, row, col)) &#123; board[row][col] = 0; continue; &#125; else &#123; generate(board, row + 1, queens); board[row][col] = 0; &#125; &#125; &#125; private boolean check(int[][] board, int row, int col) &#123; int i = row - 1, j = col; while (i &gt;= 0) &#123; if (board[i][j] == 1 || (j - row + i &gt;= 0 &amp;&amp; board[i][j - row + i] == 1) || (j + row - i &lt; board.length &amp;&amp; board[i][j + row - i] == 1)) &#123; return false; &#125; i--; &#125; return true; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Jump Game II@LeetCode","slug":"jump-game-ii","date":"2015-04-06T03:05:00.000Z","updated":"2020-02-22T09:30:45.916Z","comments":true,"path":"2015/04/06/jump-game-ii/","link":"","permalink":"http://findingsea.github.io/2015/04/06/jump-game-ii/","excerpt":"Jump Game II","text":"Jump Game II 比较典型的贪心。维护一个区间，区间表示第i步所能到达的索引范围。递推的方法为：每次都遍历一遍当前区间内的所有元素，从一个元素出发的最远可达距离是index+array[index]，那么下一个区间的左端点就是当前区间的右端点+1，下一个区间的右端点就是当前区间的max(index+array[index])，以此类推，直到区间包含了终点，统计当前步数即可。 实现代码： 1234567891011121314151617public class Solution &#123; public int jump(int[] A) &#123; if (A.length == 1) return 0; int max = 0, count = 1, begin = 0, end = A[0]; while (end &lt; A.length - 1) &#123; count++; int index = begin; for (; index &lt;= end; index++) &#123; max = Math.max(max, index + A[index]); &#125; begin = index; end = max; &#125; return count; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Wildcard Matching@LeetCode","slug":"wildcard-matching","date":"2015-04-03T02:10:00.000Z","updated":"2020-02-22T09:30:45.916Z","comments":true,"path":"2015/04/03/wildcard-matching/","link":"","permalink":"http://findingsea.github.io/2015/04/03/wildcard-matching/","excerpt":"Wildcard Matching","text":"Wildcard Matching 一开始是非常想用递归的方法做的，因为前面已经有做正则表达式的经验了，所以认为这一题应该是同样的思路做。但是小数据集还好，大数据集根本过不去，分析了一下，主要是要回朔的地方太多了，或者是需要处理的分支实在太多。 参考了网上一个挺巧妙的方法，对目标字符串和通配符字符串分别设置索引，指向当前位置。在*和*之间自然是逐个匹配；当遇到*号时，在目标字符串和通配符字符串都记录下当前位置；如果遇到无法匹配的情况，先检查之前没有*号的位置记录，如果有则将目标字符串和通配符字符串的索引都回退到当时保存的位置，然后字符串索引自加之后继续开始匹配。 这个算法对*的处理就是，当第一次遇到时，默认不匹配目标字符串中的任何内容，当后面的内容遇到了无法匹配的情况时，再进行回退，每次回退相当于利用之前的*多匹配一个目标字符串中的字符，直到全部匹配完或是无法匹配退出。 实现代码： 12345678910111213141516171819202122232425public class Solution &#123; public boolean isMatch(String s, String p) &#123; int posS = 0, posP = 0; int posStar = -1, flagInS = -1; while (posS &lt; s.length()) &#123; if (posP &lt; p.length() &amp;&amp; (s.charAt(posS) == p.charAt(posP) || p.charAt(posP) == '?')) &#123; posS++; posP++; &#125; else if (posP &lt; p.length() &amp;&amp; (p.charAt(posP) == '*')) &#123; flagInS = posS; posStar = posP; posP++; &#125; else if (posStar != -1) &#123; posS = ++flagInS; posP = posStar + 1; &#125; else &#123; return false; &#125; &#125; while (posP &lt; p.length() &amp;&amp; p.charAt(posP) == '*') &#123; posP++; &#125; return posS == s.length() &amp;&amp; posP == p.length(); &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Java泛型 泛型类、泛型接口和泛型方法","slug":"java-generics-part1","date":"2015-04-03T02:01:00.000Z","updated":"2020-02-22T09:30:45.916Z","comments":true,"path":"2015/04/03/java-generics-part1/","link":"","permalink":"http://findingsea.github.io/2015/04/03/java-generics-part1/","excerpt":"根据《Java编程思想 （第4版）》中的描述，泛型出现的动机在于： 有许多原因促成了泛型的出现，而最引人注意的一个原因，就是为了创建容器类。","text":"根据《Java编程思想 （第4版）》中的描述，泛型出现的动机在于： 有许多原因促成了泛型的出现，而最引人注意的一个原因，就是为了创建容器类。 泛型类容器类应该算得上最具重用性的类库之一。先来看一个没有泛型的情况下的容器类如何定义： 12345678910111213141516171819202122232425public class Container &#123; private String key; private String value; public Container(String k, String v) &#123; key = k; value = v; &#125; public String getKey() &#123; return key; &#125; public void setKey(String key) &#123; this.key = key; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125;&#125; Container类保存了一对key-value键值对，但是类型是定死的，也就说如果我想要创建一个键值对是String-Integer类型的，当前这个Container是做不到的，必须再自定义。那么这明显重用性就非常低。 当然，我可以用Object来代替String，并且在Java SE5之前，我们也只能这么做，由于Object是所有类型的基类，所以可以直接转型。但是这样灵活性还是不够，因为还是指定类型了，只不过这次指定的类型层级更高而已，有没有可能不指定类型？有没有可能在运行时才知道具体的类型是什么？ 所以，就出现了泛型。 12345678910111213141516171819202122232425public class Container&lt;K, V&gt; &#123; private K key; private V value; public Container(K k, V v) &#123; key = k; value = v; &#125; public K getKey() &#123; return key; &#125; public void setKey(K key) &#123; this.key = key; &#125; public V getValue() &#123; return value; &#125; public void setValue(V value) &#123; this.value = value; &#125;&#125; 在编译期，是无法知道K和V具体是什么类型，只有在运行时才会真正根据类型来构造和分配内存。可以看一下现在Container类对于不同类型的支持情况： 1234567891011public class Main &#123; public static void main(String[] args) &#123; Container&lt;String, String&gt; c1 = new Container&lt;String, String&gt;(\"name\", \"findingsea\"); Container&lt;String, Integer&gt; c2 = new Container&lt;String, Integer&gt;(\"age\", 24); Container&lt;Double, Double&gt; c3 = new Container&lt;Double, Double&gt;(1.1, 2.2); System.out.println(c1.getKey() + \" : \" + c1.getValue()); System.out.println(c2.getKey() + \" : \" + c2.getValue()); System.out.println(c3.getKey() + \" : \" + c3.getValue()); &#125;&#125; 输出： 123name : findingseaage : 241.1 : 2.2 泛型接口在泛型接口中，生成器是一个很好的理解，看如下的生成器接口定义： 123public interface Generator&lt;T&gt; &#123; public T next();&#125; 然后定义一个生成器类来实现这个接口： 12345678910public class FruitGenerator implements Generator&lt;String&gt; &#123; private String[] fruits = new String[]&#123;\"Apple\", \"Banana\", \"Pear\"&#125;; @Override public String next() &#123; Random rand = new Random(); return fruits[rand.nextInt(3)]; &#125;&#125; 调用： 12345678910public class Main &#123; public static void main(String[] args) &#123; FruitGenerator generator = new FruitGenerator(); System.out.println(generator.next()); System.out.println(generator.next()); System.out.println(generator.next()); System.out.println(generator.next()); &#125;&#125; 输出： 1234BananaBananaPearBanana 泛型方法一个基本的原则是：无论何时，只要你能做到，你就应该尽量使用泛型方法。也就是说，如果使用泛型方法可以取代将整个类泛化，那么应该有限采用泛型方法。下面来看一个简单的泛型方法的定义： 12345678910111213public class Main &#123; public static &lt;T&gt; void out(T t) &#123; System.out.println(t); &#125; public static void main(String[] args) &#123; out(\"findingsea\"); out(123); out(11.11); out(true); &#125;&#125; 可以看到方法的参数彻底泛化了，这个过程涉及到编译器的类型推导和自动打包，也就说原来需要我们自己对类型进行的判断和处理，现在编译器帮我们做了。这样在定义方法的时候不必考虑以后到底需要处理哪些类型的参数，大大增加了编程的灵活性。 再看一个泛型方法和可变参数的例子： 123456789101112public class Main &#123; public static &lt;T&gt; void out(T... args) &#123; for (T t : args) &#123; System.out.println(t); &#125; &#125; public static void main(String[] args) &#123; out(\"findingsea\", 123, 11.11, true); &#125;&#125; 输出和前一段代码相同，可以看到泛型可以和可变参数非常完美的结合。 以上，泛型的第一部分的结束。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://findingsea.github.io/tags/Java/"}]},{"title":"Trapping Rain Water@LeetCode","slug":"trapping-rain-water","date":"2015-04-02T02:59:00.000Z","updated":"2020-02-22T09:30:45.916Z","comments":true,"path":"2015/04/02/trapping-rain-water/","link":"","permalink":"http://findingsea.github.io/2015/04/02/trapping-rain-water/","excerpt":"Trapping Rain Water","text":"Trapping Rain Water 这道题当时也是花了我不少脑力呀，总感觉方法就在边上了，但是总是差一点点。 这一题的主要问题就在于：如何找到『坑』。 其一，理论上来讲，如果当前处在上升阶段（y在增大），那么就应该正在形成一个『坑』。 其二，知道现在处在『坑』了，就该算坑有多大，但是这里的难点在于如果以当前点为『坑』的右边缘，那么会遇到下一个位置可能更高，那么下一个位置才应该是『坑』的右边缘，同时还要注意左右边缘高度的比较，如果右边缘已经高于左边缘了，那么当前这个『坑』的大小就无法再增加了，反之则还有继续增大的可能。那么这里就要执行一个动作来方便之后的计算和判断：『填坑』。如果当前位置的高度低于左边缘，那么就先把已知的『坑』填平，也就是把『坑』中的每个位置就填到和右边缘一样高，并记录下来填坑的大小，再继续下一个位置；如果当前位置的高度高于左边缘，那么当前『坑』的大小不会再变了，直接用左边缘的高度高度为标尺扫一遍『坑』，把不平的地方填平即可，当然也要记录下填坑的大小。这个方法的好处在于，『坑』的每一个位置都不会被重复填，可以使代码简化并且不容易出错。 实现代码： 123456789101112131415161718192021222324252627282930313233public class Solution &#123; public int trap(int[] A) &#123; if (A == null || A.length == 0) return 0; int leftHeight = 0, left, cap = 0, index = 0; while (index &lt; A.length &amp;&amp; A[index] == 0) &#123; index++; &#125; if (index == A.length) return cap; left = index; leftHeight = A[index++]; for (; index &lt; A.length; index++) &#123; int height = A[index]; if (A[index - 1] &lt; A[index]) &#123; if (leftHeight &gt; height) &#123; int i = index - 1, min = 0; for (; A[i] &lt; A[index]; i--) &#123; cap += A[index] - A[i]; A[i] = A[index]; &#125; &#125; else &#123; for (int i = index - 1; i &gt; left; i--) &#123; cap += leftHeight - A[i]; &#125; leftHeight = height; left = index; &#125; &#125; &#125; return cap; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"First Missing Positive@LeetCode","slug":"first-missing-positive","date":"2015-04-01T01:21:00.000Z","updated":"2020-02-22T09:30:45.916Z","comments":true,"path":"2015/04/01/first-missing-positive/","link":"","permalink":"http://findingsea.github.io/2015/04/01/first-missing-positive/","excerpt":"First Missing Positive","text":"First Missing Positive 同样是一道我不太能理解为什么能标为hard的题目。 我的解法是将所有正数都先放到map里面，然后就从小正数——也就是1——开始检查map，遇到的第一个不包含在map中的正数便是答案。最坏情况下的复杂度是O(n)。 123456789101112131415161718public class Solution &#123; public int firstMissingPositive(int[] A) &#123; HashMap&lt;Integer, Boolean&gt; map = new HashMap&lt;Integer, Boolean&gt;(); for (int a : A) &#123; if (a &gt; 0) &#123; map.put(a, true); &#125; &#125; int v = 1; while (true) &#123; if (!map.containsKey(v)) &#123; break; &#125; v++; &#125; return v; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Sudoku Solver@LeetCode","slug":"sudoku-solver","date":"2015-03-31T01:08:00.000Z","updated":"2020-02-22T09:30:45.916Z","comments":true,"path":"2015/03/31/sudoku-solver/","link":"","permalink":"http://findingsea.github.io/2015/03/31/sudoku-solver/","excerpt":"Sudoku Solver","text":"Sudoku Solver 题目看起来有些难，但是其实解法很通俗，就是每一步就尝试一遍所有9个数字，然后看哪个数字是可以当前合理的。 主体还是一个递归函数，找出当前适合的数后再递归调用。找出合适的数的方法就是遍历9个数字填充到当前位置，然后用验证函数进行验证，然后验证通过就继续调用递归函数解出下一个位置，如果验证不通过就再尝试下一个数字。如果遍历了一遍都没有发现合适的数字，那么就返回false。当发现所有空位都填充满了之后，就可以返回true了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Solution &#123; public void solveSudoku(char[][] board) &#123; if (board == null || board.length != 9 || board[0].length != 9) return; solve(board, 0, 0); &#125; private boolean solve(char[][] board, int i, int j) &#123; if (j &gt;= 9) return solve(board, i + 1, 0); if (i == 9) return true; if (board[i][j] == '.') &#123; for (int k = 1; k &lt;= 9; k++) &#123; board[i][j] = (char) (k + '0'); if (isValid(board, i, j)) &#123; if (solve(board, i, j + 1)) return true; &#125; board[i][j] = '.'; &#125; &#125; else &#123; return solve(board, i, j + 1); &#125; return false; &#125; private boolean isValid(char[][] board, int i, int j) &#123; for (int k = 0; k &lt; 9; k++) &#123; if (k != i &amp;&amp; board[k][j] == board[i][j]) return false; &#125; for (int k = 0; k &lt; 9; k++) &#123; if (k != j &amp;&amp; board[i][k] == board[i][j]) return false; &#125; for (int row = i / 3 * 3; row &lt; i / 3 * 3 + 3; row++) &#123; for (int col = j / 3 * 3; col &lt; j / 3 * 3 + 3; col++) &#123; if (row != i &amp;&amp; col != j &amp;&amp; board[i][j] == board[row][col]) return false; &#125; &#125; return true; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Search in Rotated Sorted Array@LeetCode","slug":"search-in-rotated-sorted-array","date":"2015-03-30T02:34:00.000Z","updated":"2020-02-22T09:30:45.915Z","comments":true,"path":"2015/03/30/search-in-rotated-sorted-array/","link":"","permalink":"http://findingsea.github.io/2015/03/30/search-in-rotated-sorted-array/","excerpt":"Search in Rotated Sorted Array","text":"Search in Rotated Sorted Array 其实不太能理解为什么这题能标成hard，因为用很直观的算法便可以解出来。由于数组是被翻转过的，所以被分成两个部分，每个部分又都是有序的。所以先判断先判断一下要查找的数是在前半段还是后半段，然后依次查找即可。 1234567891011121314151617181920212223242526272829303132333435363738public class Solution &#123; public int search(int[] A, int target) &#123; int index = -1; if (A == null || A.length == 0) return index; if (A[0] == target) return 0; if (A[A.length - 1] == target) return A.length - 1; int ALen = A.length; boolean hit = false; if (A[0] &lt; target) &#123; index = 1; while (index &lt; ALen &amp;&amp; A[index - 1] &lt; A[index]) &#123; if (A[index] == target) &#123; hit = true; break; &#125; index++; &#125; if (!hit) &#123; index = -1; &#125; &#125; else if (target &lt; A[ALen - 1])&#123; index = ALen - 2; while (0 &lt;= index &amp;&amp; A[index] &lt; A[index + 1]) &#123; if (A[index] == target) &#123; hit = true; break; &#125; index--; &#125; if (!hit) &#123; index = -1; &#125; &#125; else &#123; index = -1; &#125; return index; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Permutations I II@LeetCode","slug":"permutations-i-ii","date":"2015-03-29T03:37:00.000Z","updated":"2020-02-22T09:30:45.915Z","comments":true,"path":"2015/03/29/permutations-i-ii/","link":"","permalink":"http://findingsea.github.io/2015/03/29/permutations-i-ii/","excerpt":"Permutations","text":"Permutations 递归的方法，设置一个used数组，用来记录相应位置是否已经使用过了，然后设置一个permutation数组，用来保存当前的序列，如果当前序列长度到达额定长度后，将该序列加入最后结果集合中。 实现代码： 1234567891011121314151617181920212223public class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; permute(int[] num) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;List&lt;Integer&gt;&gt;(); generate(num, new boolean[num.length], result, new ArrayList&lt;Integer&gt;()); return result; &#125; private void generate(int[] num, boolean[] used, List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; permutation) &#123; if (permutation.size() == num.length) &#123; result.add(new ArrayList&lt;Integer&gt;(permutation)); &#125; else &#123; for (int i = 0; i &lt; num.length; i++) &#123; if (!used[i]) &#123; permutation.add(num[i]); used[i] = true; generate(num, used, result, permutation); permutation.remove(permutation.size() - 1); used[i] = false; &#125; &#125; &#125; &#125;&#125; Permutations II 难度的提升在于：有数字是重复的。 针对这一点，可以先对原始数据集合进行排序，这样保证了如果有重复元素，那么他们也是相邻的。同时，在递归函数中，同一层递归中，除了判断该位有没有使用过，还要判断当前位之后的元素是否与当前位相同，如果相同则要一直往前找到第一个不相同的且没有使用过的元素，作为下一个当前位插入permutation数组中。 实现代码： 1234567891011121314151617181920212223242526272829public class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] num) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;List&lt;Integer&gt;&gt;(); Arrays.sort(num); generate(num, new boolean[num.length], result, new ArrayList&lt;Integer&gt;()); return result; &#125; private void generate(int[] num, boolean[] used, List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; permutation) &#123; if (permutation.size() == num.length) &#123; result.add(new ArrayList&lt;Integer&gt;(permutation)); &#125; else &#123; int i = 0; while (i &lt; used.length) &#123; if (!used[i]) &#123; permutation.add(num[i]); used[i] = true; generate(num, used, result, permutation); permutation.remove(permutation.size() - 1); used[i] = false; while (i &lt; used.length - 1 &amp;&amp; num[i] == num[i + 1]) &#123; i++; &#125; &#125; i++; &#125; &#125; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Longest Valid Parentheses@LeetCode","slug":"longest-valid-parentheses","date":"2015-03-29T03:10:00.000Z","updated":"2020-02-22T09:30:45.915Z","comments":true,"path":"2015/03/29/longest-valid-parentheses/","link":"","permalink":"http://findingsea.github.io/2015/03/29/longest-valid-parentheses/","excerpt":"Longest Valid Parentheses","text":"Longest Valid Parentheses 这也是不知道方法前很纠结，知道方法之后很简单就能搞定的题目。解题的核心就是维护一个左括号栈和站内元素起点索引，之所以要维护一个匹配起始索引，是因为在匹配过程中先前已经匹配的元素可能已经出栈了，其索引无法获取所以要提前记录下来，在维护的过程中可能遇到两种情况： 当前字符是(，那么就直接压栈。 当前字符是)，那么如果栈内为空，就说明当前匹配失效且不是起始索引移动起始索引；如果栈内不为空，则先弹出栈顶元素，如果此时栈内为空了，说明当前已经匹配到了起始索引出，则从起始索引开始计算长度，反之，说明当前还在连续匹配串内，那么只要从当前栈顶元素索引开始计算长度即可。 具体实现代码： public class Solution { public int longestValidParentheses(String s) { Stack&lt;Integer&gt; left = new Stack&lt;Integer&gt;(); int max = 0, matchBegin = 0; for (int i = 0; i &lt; s.length(); i++) { char ch = s.charAt(i); if (ch == '(') { left.push(i); } else { if (left.isEmpty()) { matchBegin = i + 1; } else { left.pop(); if (left.isEmpty()) { max = Math.max(max, i - matchBegin + 1); } else { max = Math.max(max, i - left.peek()); } } } } return max; } }","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Substring with Concatenation of All Words@LeetCode","slug":"substring-with-concatenation-of-all-words","date":"2015-03-27T01:24:00.000Z","updated":"2020-02-22T09:30:45.915Z","comments":true,"path":"2015/03/27/substring-with-concatenation-of-all-words/","link":"","permalink":"http://findingsea.github.io/2015/03/27/substring-with-concatenation-of-all-words/","excerpt":"Substring with Concatenation of All Words","text":"Substring with Concatenation of All Words 比较复杂的一题，首先是要明确用滑块的概念来解决，始终保持L集合中的字符串在滑块中都只出现了一次，当然设置一个总计数count，当cout等于L集合长度时，即使找了一段符合要求的字符串。 需要用到的内存空间： 两张哈希表，一张保存L集合中的单词，一张用来保存当前滑块中的单词，key为单词，value为出现次数 cout计数，保存当前滑块中的单词总数 left标记，记录滑块左起点 实现的步骤： 遍历一遍单词数组L集合，构造总单词表 以单词长度为步长，遍历目标字符串，如果当前单词在总单词表内，则进入步骤3；反之，则清空当前滑块单词表，将cout置零，将left移动到下一位置 当前滑块档次表中的相应单词计数加1，检查该单词的计数是否小于等于总单词表中该单词的总数，如果是，则将count计数加1，进入步骤5；反之，进入步骤4 根据左起点left收缩滑块，直到收缩到与当前单词相同的字符串片段，将其剔除之后，滑块的收缩工作完成 如果当前count计数等于单词集合长度，记录下left左起点的位置后，将left右移，当前滑块中相应单词计数减1，总计数减1，继续循环 这里解释下步骤4中的收缩滑块，这是因为当前滑块中有单词的出现次数超过了额定的出现次数，那么就是需要收缩滑块来剔除这个单词，相当于是从滑块的左起点开始寻找该单词，找到之后，将该单词的右端点作为滑块新的左起点，这样就保证了滑块中所有单词都是小于等于额定出现次数，这样也保证了count计数的有效性。 遇到总单词表中不存在的单词的情况，在步骤2中已经说明，清空当前数据之后继续循环，也就是保证了滑块中是不会出现不存在单词表中的单词的。 最后，考虑最外圈循环，如果是从0开始作为滑块的初始起点，那么其实并没有遍历字符串中的所有可能子串，因为步长是单词长度，所以移动滑块的时候会跨过很多可能子串，所以要在外圈再加一层循环，这个循环的作用就是移动滑块的初始起点，所以循环次数就是单词的长度。 实现代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class Solution &#123; public List&lt;Integer&gt; findSubstring(String S, String[] L) &#123; ArrayList&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;(); if (S == null || S.length() == 0 || L == null || L.length == 0) return result; int strLen = S.length(); int wordLen = L[0].length(); HashMap&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;(); for (int i = 0; i &lt; L.length; i++) &#123; if (map.containsKey(L[i])) &#123; map.put(L[i], map.get(L[i]) + 1); &#125; else &#123; map.put(L[i], 1); &#125; &#125; for (int i = 0; i &lt; wordLen; i++) &#123; HashMap&lt;String, Integer&gt; curMap = new HashMap&lt;String, Integer&gt;(); int count = 0, left = i; for (int j = i; j &lt;= strLen - wordLen; j += wordLen) &#123; String curStr = S.substring(j, j + wordLen); if (map.containsKey(curStr)) &#123; if (curMap.containsKey(curStr)) &#123; curMap.put(curStr, curMap.get(curStr) + 1); &#125; else &#123; curMap.put(curStr, 1); &#125; if (curMap.get(curStr) &lt;= map.get(curStr)) &#123; count++; &#125; else &#123; while (true) &#123; String tmp = S.substring(left, left + wordLen); curMap.put(tmp, curMap.get(tmp) - 1); left += wordLen; if (curStr.equals(tmp)) &#123; break; &#125; else &#123; count--; &#125; &#125; &#125; if (count == L.length) &#123; result.add(left); String tmp = S.substring(left, left + wordLen); curMap.put(tmp, curMap.get(tmp) - 1); left += wordLen; count--; &#125; &#125; else &#123; curMap.clear(); count = 0; left = j + wordLen; &#125; &#125; &#125; return result; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Reverse Nodes in k-Group@LeetCode","slug":"reverse-nodes-in-k-group","date":"2015-03-26T12:44:00.000Z","updated":"2020-02-22T09:30:45.915Z","comments":true,"path":"2015/03/26/reverse-nodes-in-k-group/","link":"","permalink":"http://findingsea.github.io/2015/03/26/reverse-nodes-in-k-group/","excerpt":"Reverse Nodes in k-Group","text":"Reverse Nodes in k-Group 翻转链表的升级版，由于在以前阿里的面试中遇到过，所以特别在意，这次写题解之前又重新把原来通过的代码优化了一下。 其实这题很简单，知道了翻转链表的通用写法之后，解这一题其实就是循环翻转的过程（知道最后一个group长度不足）。 先介绍下翻转链表的写法： 首先设置一个前置节点，将前置节点的next设置为头节点，以头节点为当前节点，开始循环 将当前节点的next赋给一个临时节点，然后将当前节点的next指向前置节点，随后依次位移前置节点指针和当前节点指针：前置节点指针指向当前节点，当前节点指针指向临时节点，这样就完成了一次循环 当前置节点指针指向尾节点时，循环结束 有个这个翻转函数之后，只要对链表进行循环，当计数长度不k时，指针继续前进；当计数长度到达k时，将头尾节点作为参数传入翻转函数进行翻转，然后重新拼接到原链表中。直至到达链表末尾。 实现代码： 1234567891011121314151617181920212223242526272829303132333435363738public class Solution &#123; public ListNode reverseKGroup(ListNode head, int k) &#123; if (k == 1 || head == null || head.next == null) return head; ListNode first = head, last = head; ListNode preHead = new ListNode(-1); preHead.next = head; ListNode preGroup = preHead, nextGroup = preHead; int count = 1; while (last != null) &#123; if (count == k) &#123; nextGroup = last.next; reverseList(first, last); preGroup.next = last; preGroup = first; first.next = nextGroup; first = nextGroup; last = nextGroup; count = 1; continue; &#125; last = last.next; count++; &#125; return preHead.next; &#125; private void reverseList(ListNode head, ListNode tail) &#123; ListNode pre = new ListNode(-1), node = head; pre.next = head; while (pre != tail) &#123; ListNode temp = node.next; node.next = pre; pre = node; node = temp; &#125; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Merge k Sorted Lists@LeetCode","slug":"merge-k-sorted-lists","date":"2015-03-26T01:36:00.000Z","updated":"2020-02-22T09:30:45.915Z","comments":true,"path":"2015/03/26/merge-k-sorted-lists/","link":"","permalink":"http://findingsea.github.io/2015/03/26/merge-k-sorted-lists/","excerpt":"Merge k Sorted Lists","text":"Merge k Sorted Lists 当初看到这题的第一反应是每次都遍历一遍所有头节点，然后选出最小的连接到已排序链表的末尾。这个想法当然能够解决问题，但是性能上肯定是过不去的。因为这样相当于没排序一个元素就是需要比较m次（m为链表条数），那么最后的复杂度就是O(nm)（n为元素总数）。 那么更加高效的办法就是对链表进行两两合并，两条链表的合并复杂度为O(l + k)，l和k分别代表了两条链表的元素个数，那么最终的复杂度为O(n)（n为元素总数）。 实现代码： 123456789101112131415161718192021222324252627282930313233343536public class Solution &#123; public ListNode mergeKLists(List&lt;ListNode&gt; lists) &#123; if (lists.isEmpty()) return null; return merge(lists, 0, lists.size() - 1); &#125; public ListNode merge(List&lt;ListNode&gt; lists, int start, int end) &#123; if (start == end) return lists.get(start); int mid = (start + end) / 2; ListNode one = merge(lists, start, mid); ListNode two = merge(lists, mid + 1, end); return mergeTwoLists(one, two); &#125; public ListNode mergeTwoLists(ListNode node1, ListNode node2) &#123; ListNode head = new ListNode(-1), node = head; while (node1 != null &amp;&amp; node2 != null) &#123; if (node1.val &lt; node2.val) &#123; node.next = node1; node1 = node1.next; &#125; else &#123; node.next = node2; node2 = node2.next; &#125; node = node.next; &#125; if (node1 == null &amp;&amp; node2 != null) &#123; node.next = node2; &#125; else if (node1 != null &amp;&amp; node2 == null) &#123; node.next = node1; &#125; return head.next; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Regular Expression Matching@LeetCode","slug":"regular-expression-matching","date":"2015-03-24T05:31:00.000Z","updated":"2020-02-22T09:30:45.915Z","comments":true,"path":"2015/03/24/regular-expression-matching/","link":"","permalink":"http://findingsea.github.io/2015/03/24/regular-expression-matching/","excerpt":"Regular Expression Matching 比较典型的动态规划题，重点就在于*号的匹配上。","text":"Regular Expression Matching 比较典型的动态规划题，重点就在于*号的匹配上。 分三步走： 当模式串为空时。检查内容串是否为空（为空则返回true，反之返回false）。注意这里反过来是不成立的，也就是不能检查当内容穿为空时，模式串是否为空，因为如果模式串最后一个字符是*，那么即便此时模式串不为空，总结结果也有可能是true。 当模式串长度为1或者模式串的第二个字符不为*时。这种情况比较简单，只要比较这个字符串的第一个字符即可，两个字符串的第一个字符相等或者模式串的第一个字符为.则返回true，反之就是false。 最后，就是要处理模式串第二个字符是*的情况了，这种情况下，模式串的第一个字符可以匹配内容串中任意多个连续的相同字符（包括0个），那么就从『一个都匹配』到『匹配所有符合要求的字符』进行一遍循环，那么在循环中，问题就变为两个字符串的字串是否匹配的问题了，对函数进行递归调用即可，判断返回结果以决定是否返回true。最后如果循环结束之后仍没有返回，就证明无论如何匹配，*都无法合理匹配，那就证明两个字符串无法匹配，所以返回false。 实现代码： 1234567891011121314151617181920212223public class Solution &#123; public boolean isMatch(String s, String p) &#123; if (p.length() == 0) return s.length() == 0; if (p.length() == 1 || p.charAt(1) != '*') &#123; if (s.length() &gt; 0 &amp;&amp; (p.charAt(0) == s.charAt(0) || p.charAt(0) == '.')) &#123; return isMatch(s.substring(1, s.length()), p.substring(1, p.length())); &#125; else &#123; return false; &#125; &#125; else &#123; int i = 0; do &#123; if (isMatch(s.substring(i, s.length()), p.substring(2, p.length()))) &#123; return true; &#125; i++; &#125; while (i &lt;= s.length() &amp;&amp; (p.charAt(0) == s.charAt(i - 1) || p.charAt(0) == '.')); return false; &#125; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"一月份阅读报告","slug":"january-reading-report","date":"2015-03-23T13:04:00.000Z","updated":"2020-02-22T09:30:45.914Z","comments":true,"path":"2015/03/23/january-reading-report/","link":"","permalink":"http://findingsea.github.io/2015/03/23/january-reading-report/","excerpt":"一月份总共读了四本书，刚好达到要求：《解忧杂货店》，《枪炮、病菌与钢铁 : 人类社会的命运》，《看不见的城市》和《刀锋》。都是赶在放寒假回家之前抓紧时间看完的，然后之后就过年，然后就忙实习，然后阅读报告就一直拖，今天总算是有时间和心情把阅读报告补完。","text":"一月份总共读了四本书，刚好达到要求：《解忧杂货店》，《枪炮、病菌与钢铁 : 人类社会的命运》，《看不见的城市》和《刀锋》。都是赶在放寒假回家之前抓紧时间看完的，然后之后就过年，然后就忙实习，然后阅读报告就一直拖，今天总算是有时间和心情把阅读报告补完。 解忧杂货店 这本书被认为是东野圭吾第一本非悬疑类小说，在网上的评价也非常好。我读过之后的最大感觉就是：虽然不是悬疑小说，但是仍然紧紧地吸引着我读下去，直至最后一页我才恋恋不舍地合上了书。 我在豆瓣上做的书评： 没有悬疑，没有推理，没有阴谋论，一本完全不像东野的东野的数。整本书就讲了一件事：何以解忧，唯有倾听。可能东野已经意识到了，如果有人倾听，唐泽雪惠和桐原亮的悲剧是可以避免的；如果有人倾听，石神哲哉的悲剧也是可以避免的。可以让世界变得更好的，不是汤川那样的神探，而是更多像浪矢这样的倾听者。 枪炮、病菌与钢铁 : 人类社会的命运 又是一本声名在外的书，整体书的风格非常严谨，几乎每一个论点都有相应的大量数据作为佐证。 我当时在朋友圈推荐时的评价： 非常严肃的学术作品，地理决定论的代表性著作。作者用多年的研究和详尽的数据，力求回答一些终极问题：为什么世界是今天这样的世界？为什么是欧洲征服了美洲，而不是反过来？为什么欧洲中国美国都作为世界的中心，而澳大利亚没有？等等。 看不见的城市 这是我看的第一本卡尔维诺的书，说真的，即便是现在，我对超现实主义的作品的理解还是非常困难，只能看一个大概，无法完全看出文字背后的寓意。 卡尔维诺自己的介绍也许是对这本书最好的诠释。 对我们来说，今天的城市是什么？我认为我写了一种东西，它就像越来越难以把城市当做城市来生活，献给城市的最后一首爱情诗。 刀锋 毛姆貌似在中国很流行，喜欢看书的朋友也有推荐他的书，所以我就拿起了刀锋。说实话，刀锋对我的冲击力不如想象大，也可能是我对其期望太高了。刀锋的确讲了一个很好的故事，毛姆的叙事手法也非常巧妙，有一种温文儒雅又略带诙谐的感觉，读起来是非常舒服的。但是，看完故事之后，总会觉得少了点什么，总是有一种感觉：嗯，一个不错的故事，那然后呢？好像故事结束了，书也就结束了。对于这种大师级的作品，我总希望能从在故事里读出点什么，毫无疑问，奥威尔可以，狄更斯可以，茨威格也可以，但是毛姆，总是差了那一层纸。不知道是毛姆有意为之不愿意再往前一步，还是其他原因，让我对刀锋留下了点遗憾。","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"Median of Two Sorted Arrays@LeetCode","slug":"median-of-two-sorted-arrays","date":"2015-03-23T01:18:00.000Z","updated":"2020-02-22T09:30:45.914Z","comments":true,"path":"2015/03/23/median-of-two-sorted-arrays/","link":"","permalink":"http://findingsea.github.io/2015/03/23/median-of-two-sorted-arrays/","excerpt":"Median of Two Sorted Arrays","text":"Median of Two Sorted Arrays 这题记得当时也是查了网上的资料才做出来的，而且采用的是一个通用算法findKth。 其实思想很简单：要寻找第k小的元素，那么总是保持数组A的当前元素（即A[a]）为当前最小元素（如果不是，则交换A和B数组，使这一条成立），然后弹出该元素（即++a），然后再递归调用寻找第k-1小的元素。 这需要注意的地方在于： A.length + B.length为偶数的时候，中位数有两个，要取平均。 A.length + B.length为奇数的时候，中位数只有一个。 实现代码如下： 123456789101112131415161718192021222324252627/** * Created by findingsea on 14/11/16. */public class Solution &#123; public double findKth(int A[], int a, int B[], int b, int k) &#123; if (A.length == a || (b &lt; B.length &amp;&amp; A[a] &gt; B[b])) &#123; int tmp[] = A; A = B; B = tmp; int t = a; a = b; b = t; &#125; if (k == 1) return A[a]; return findKth(A, ++a, B, b, --k); &#125; public double findMedianSortedArrays(int A[], int B[]) &#123; int len = A.length + B.length; if (len == 1) return A.length == 0 ? B[0] : A[0]; if (len % 2 == 0) &#123; return (findKth(A, 0, B, 0, len / 2) + findKth(A, 0, B, 0, len / 2 + 1)) / 2; &#125; else &#123; return findKth(A, 0, B, 0, len / 2 + 1); &#125; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"当你访问淘宝的时候，发生了什么？","slug":"what-will-happen-when-you-visit-taobao","date":"2015-03-20T07:56:00.000Z","updated":"2020-02-22T09:30:45.914Z","comments":true,"path":"2015/03/20/what-will-happen-when-you-visit-taobao/","link":"","permalink":"http://findingsea.github.io/2015/03/20/what-will-happen-when-you-visit-taobao/","excerpt":"原文地址：当你访问淘宝的时候，发生了什么？ 因为准备阿里的面试（这个问题以前在阿里的笔面试中出现过），所以把这个问题还翻出来复习了一下。太细节的地方背起来当然没什么意义，这里我就整理每一步大概做了哪些事情以及涉及到阿里相关的那些技术。","text":"原文地址：当你访问淘宝的时候，发生了什么？ 因为准备阿里的面试（这个问题以前在阿里的笔面试中出现过），所以把这个问题还翻出来复习了一下。太细节的地方背起来当然没什么意义，这里我就整理每一步大概做了哪些事情以及涉及到阿里相关的那些技术。 1. 浏览器查询DNS服务器在浏览器中键入的只是网址，那么浏览器要知道具体的服务器就要查询DNS服务器，将www.taobao.com转换成相应的IP地址。阿里旗下网站的每日访问量巨大，不可能将所有访问都解析到一个IP地址上，那么这一步就涉及到阿里的负载均衡系统。 2. 产生PV，同时如果是独立用户那么将产生UVPV指的是Page View，页面被刷新一次就记一次数。 UV指的是User View，一个用户访问一次就记一次数，无论这个用户访问了多少个页面或者刷新了多少遍，都只记一次UV。 3. 从CDN中获取素材阿里旗下的网站——尤其是淘宝和天猫——富文本素材众多，那么如果都从服务器上读取的话，一来速度慢，二来对服务器的压力也大。所以这一步就涉及到阿里的CDN与分布式文件系统。阿里在全国建立了上百个CDN节点，CDN指的是内容分发网络。 4. 搜索这是很多上淘宝天猫要做的第一件事情，那么阿里的后台系统将搜索行为分为以下四个类型： 浏览型 查询型 对比型 确定型 针对不同的搜索类型，会出现不同的结果。这里涉及到阿里的搜索引擎和日志系统。搜索引擎中包含了自然语言处理和中文分词以及其他技术。日志系统是记载了用户做出的各类行为，比如查询、交易、取消交易等等，这些都会被保存下来。 5. 交易快照只要是进行过的交易都会记录下来，无论商品的信息是否发生了改变。那么保存这些信息是需要非常巨大的存储代价的，那么这一步就涉及到阿里的分布式存储系统，同时注意这些数据保存之前都是会进行压缩的。 6. 数据传输无论是日志还是交易信息，乘以阿里每日的交易量都是一个很大的数据，所以阿里还开发了自己的数据传输系统。 7. 云梯最后，你在阿里旗下的所有网站的所有行为，都会被大规模数据挖掘系统云梯进行分析，以求最大程度地还原和定位你这个人。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"http://findingsea.github.io/tags/Interview/"}]},{"title":"Dungeon Game@LeetCode","slug":"dungeon-game","date":"2015-03-19T01:56:00.000Z","updated":"2020-02-22T09:30:45.914Z","comments":true,"path":"2015/03/19/dungeon-game/","link":"","permalink":"http://findingsea.github.io/2015/03/19/dungeon-game/","excerpt":"Dungeon Game 这是我的在LeetCode上的最后一题，一道很典型的动态规划题。","text":"Dungeon Game 这是我的在LeetCode上的最后一题，一道很典型的动态规划题。 创建一个二维数组来保存记录。 首先从重点开始，这里需要注意的是，终点的血量求负之后是需要加1的，例如重点值是-5，那么进入终点时的血量就应该是6，不然到终点血量变为0了也是失败。然后需要注意的是如果进入终点前所需的血量小于1，那么就应该以1记，因为如果是血量小于1就直接失败了。 然后循环运算二维数组中的每个点的最低血量，例如，对于dungeon[i][j]点来说，通过dungeon[i][j]本身需要的血量是-dungeon[i][j]，通过dungeon[i][j]点之后到达终点所需的最小血量为Math.min(dungeon[i + 1][j], dungeon[i][j + 1])，对两者求和，同样的，如果这求和值小于1那么应该以1记，完整递推公式为dungeon[i][j] = Math.max(1, -dungeon[i][j] + Math.min(dungeon[i + 1][j], dungeon[i][j + 1]))。 最后返回dungeon[0][0]的值即可。 实现代码： 12345678910111213141516171819public class Solution &#123; public int calculateMinimumHP(int[][] dungeon) &#123; int rows = dungeon.length, cols = dungeon[0].length; dungeon[rows - 1][cols - 1] = Math.max(1, -dungeon[rows - 1][cols - 1] + 1); for (int j = cols - 2; j &gt;= 0; j--) &#123; dungeon[rows - 1][j] = Math.max(1, -(dungeon[rows - 1][j]) + dungeon[rows - 1][j + 1]); &#125; for (int i = rows - 2; i &gt;= 0; i--) &#123; for (int j = cols - 1; j &gt;= 0; j--) &#123; if (j == cols - 1) &#123; dungeon[i][j] = Math.max(1, -(dungeon[i][j]) + dungeon[i + 1][j]); &#125; else &#123; dungeon[i][j] = Math.max(1, -dungeon[i][j] + Math.min(dungeon[i + 1][j], dungeon[i][j + 1])); &#125; &#125; &#125; return dungeon[0][0]; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"堆和堆排序","slug":"heap-and-heap-sort","date":"2015-03-18T04:47:00.000Z","updated":"2020-02-22T09:30:45.914Z","comments":true,"path":"2015/03/18/heap-and-heap-sort/","link":"","permalink":"http://findingsea.github.io/2015/03/18/heap-and-heap-sort/","excerpt":"堆的定义堆是一种常见的数据结构，具体定义可以见维基百科。","text":"堆的定义堆是一种常见的数据结构，具体定义可以见维基百科。 程序设计中实用的数据结构中对于堆的定义如下： 二叉堆是一棵满足下列性质的完全二叉树。 如果某节点有孩子，且根节点的值都小于孩子节点的值，我们称之为小根堆。 如果某节点有孩子，且根节点的值都大于孩子节点的值，我们称之为大根堆。 二叉堆的树结构同其他完全二叉树一样，所有叶子都在同一层或两个连续层上，最后一层的节点占据尽量左的位置。 利用堆的特性（最大堆和最小堆）可以对数列进行排序，堆排序的性能如下： | 平均时间 | 最差情形 | 稳定度 | 额外空间| —————– |:———————:| ———-:|| O(nlogn) | O(nlogn) | 不稳定 | O(1) 堆排序的步骤如下： 建堆 弹出堆顶元素 调整堆 重复2和3步骤 建堆建堆有两种方法： 先填数后调整 边插入边调整 这里介绍前一种方法，也就是先填数后调整。由于堆满足完全二叉树的性质，所以可以用一个一维数组来保存堆中的数据。其中的性质如下： 在一维数组heap[1…n]中，其中heap[i]节点的父节点是heap[i div 2]，左子节点是heap[2i]，右子节点是heap[2i+1]，若2i&gt;n，则节点i为叶节点。 这里需要注意的是，定义中数组的编号是从1开始的，并且在算法描述中都将采用从1开始编号的方式，而我的代码中，为了统一操作，编号是从0开始的。 由于我们已知2i&gt;n的点都是叶节点，也就是无法向下调整的节点，所以我们的自下而上的调整节点从n div 2节点开始，到根节点为止。 建堆的代码如下： 1234567891011121314151617181920212223242526272829public MinHeap(int[] array) &#123; length = array.length; num = array.clone(); int index = length / 2 - 1; while (index &gt;= 0) &#123; int toSwapIndex = num[index * 2 + 1] &lt; num[index * 2 + 2] ? index * 2 + 1 : index * 2 + 2; if (num[toSwapIndex] &lt; num[index]) &#123; int temp = num[index]; num[index] = num[toSwapIndex]; num[toSwapIndex] = temp; topDownBuild(toSwapIndex); &#125; index--; &#125;&#125;private void topDownBuild(int top) &#123; while (top &lt; length / 2) &#123; int toSwapIndex = num[top * 2 + 1] &lt; num[top * 2 + 2] ? top * 2 + 1 : top * 2 + 2; if (num[toSwapIndex] &lt; num[top]) &#123; int temp = num[top]; num[top] = num[toSwapIndex]; num[toSwapIndex] = temp; &#125; else &#123; break; &#125; top = toSwapIndex; &#125;&#125; 弹出堆顶元素堆顶元素就是当前数据集中的最小（或者最大）元素，弹出的操作很简单，就是获取num[0]的值，然后将num[0]重新赋值为num[length - 1]，并且length--即可。 调整堆弹出堆顶元素之后，显而易见当前堆的状态被破坏了，那么就需要调整堆，其实也就是直接的调用build(int top)方法。这一步中的调整堆算法其实和建堆时的很像，但是有如下区别： 建堆时，采用的是自下而上的调整策略；调整堆时，采用的自下而上的调整策略。因为如果刨去当前的堆顶元素，整个堆其他位置的元素其实是处在合理的位置。 调整堆时，只要当前位置已经是合理的了，那就不需要继续调整，可以马上跳出循环。 重复重复弹出堆顶元素和调整堆两步骤，直到堆空了为止（成员变量length等于0）。 完整代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * Created by findingsea on 3/12/15. * 对于一个包含了n个节点的二叉堆来说，叶子的数量为n为奇数：(n / 2 + 1)或者n为偶数：(n / 2) */public class HeapSort &#123; public int[] sort(int[] num) &#123; int[] result = new int[num.length]; MinHeap minHeap = new MinHeap(num); for (int i = 0; i &lt; result.length; i++) &#123; result[i] = minHeap.pop(); &#125; return result; &#125; class MinHeap &#123; int[] num; int length; public MinHeap(int[] array) &#123; length = array.length; num = array.clone(); int index = length / 2 - 1; while (index &gt;= 0) &#123; int toSwapIndex = num[index * 2 + 1] &lt; num[index * 2 + 2] ? index * 2 + 1 : index * 2 + 2; if (num[toSwapIndex] &lt; num[index]) &#123; int temp = num[index]; num[index] = num[toSwapIndex]; num[toSwapIndex] = temp; topDownBuild(toSwapIndex); &#125; index--; &#125; &#125; // 边插入边调整 public void add(int n) &#123; &#125; public int pop() &#123; int top = num[0]; num[0] = num[length - 1]; length--; topDownBuild(0); return top; &#125; private void topDownBuild(int top) &#123; while (top &lt; length / 2) &#123; int toSwapIndex = num[top * 2 + 1] &lt; num[top * 2 + 2] ? top * 2 + 1 : top * 2 + 2; if (num[toSwapIndex] &lt; num[top]) &#123; int temp = num[top]; num[top] = num[toSwapIndex]; num[toSwapIndex] = temp; &#125; else &#123; break; &#125; top = toSwapIndex; &#125; &#125; &#125;&#125;","categories":[],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://findingsea.github.io/tags/Algorithm/"}]},{"title":"Largest Number@LeetCode","slug":"largest-number","date":"2015-03-18T02:39:00.000Z","updated":"2020-02-22T09:30:45.914Z","comments":true,"path":"2015/03/18/largest-number/","link":"","permalink":"http://findingsea.github.io/2015/03/18/largest-number/","excerpt":"Largest Number","text":"Largest Number 典型的窍门题，就是知道了诀窍之后很简单就能搞定。不像有些题目，比如动态规划，即便知道了是用什么方法，但求递推公式还是要花很大的力气。 这题最大的难点就在于：当一个数是另一个数的前缀时，如何排列它们顺序。（其他情况很简单，就按照字符串默认的排序规则就行） 解决方法是：比较两个数o1和o2时，不要直接比较他们自身的大小，而是比较o1+o2和o2+o1的大小。 实现方法就是要自己写一个比较器，那么这里也有一个技巧，网上的实现代码有些是这样写的： 1return (int) (Long.parseLong(o1 + o2) - Long.parseLong(o2 + o1)); 虽然这样的实现在编写上非常简单，但是其实这样需要完整地转换两个字符串，这在大多数情况是不需要的，大多数情况下只要比较前几个数字就可以判断出大小了，所以我采用的比较器写法如下： 1234567891011String str1 = o1 + o2;String str2 = o2 + o1;int length = str1.length();for (int i = 0; i &lt; length; i++) &#123; if (str1.charAt(i) &gt; str2.charAt(i)) &#123; return 1; &#125; else if (str1.charAt(i) &lt; str2.charAt(i)) &#123; return -1; &#125;&#125;return 0; 实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637public class Solution &#123; public String largestNumber(int[] num) &#123; int length = num.length; String[] numStr = new String[length]; for (int i = 0; i &lt; length; i++) &#123; numStr[i] = String.valueOf(num[i]); &#125; Arrays.sort(numStr, new StringComparator()); StringBuilder stringBuilder = new StringBuilder(); for (int i = length - 1; i &gt;= 0; i--) &#123; stringBuilder.append(numStr[i]); &#125; int index = 0; while (index &lt; stringBuilder.length() - 1 &amp;&amp; stringBuilder.charAt(index) == '0') &#123; index++; &#125; return stringBuilder.substring(index, stringBuilder.length()).toString(); &#125; class StringComparator implements Comparator&lt;String&gt; &#123; @Override public int compare(String o1, String o2) &#123; String str1 = o1 + o2; String str2 = o2 + o1; int length = str1.length(); for (int i = 0; i &lt; length; i++) &#123; if (str1.charAt(i) &gt; str2.charAt(i)) &#123; return 1; &#125; else if (str1.charAt(i) &lt; str2.charAt(i)) &#123; return -1; &#125; &#125; return 0; &#125; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"String, StringBuffer和StringBuilder","slug":"string-stringbuffer-stringbuilder","date":"2015-03-17T06:59:00.000Z","updated":"2020-02-22T09:30:45.914Z","comments":true,"path":"2015/03/17/string-stringbuffer-stringbuilder/","link":"","permalink":"http://findingsea.github.io/2015/03/17/string-stringbuffer-stringbuilder/","excerpt":"在Java中，String是不可变类型，所以对于字符串的操作提供了两个辅助类：StringBuffer和StringBuilder。","text":"在Java中，String是不可变类型，所以对于字符串的操作提供了两个辅助类：StringBuffer和StringBuilder。 这个两个类的主要区别在于： StringBuilder的效率更高 StringBuffer是线程安全的，而StringBuilder不是 不过，需要注意的是，在利用+对String对象直接进行拼接的时候，Java内部其实还是用StringBuilder来实现的，但是和显式地调用StringBuilder略有区别。 考虑如下代码： 123456789String[] strings = new String[]&#123;\"one\", \"two\", \"three\", \"four\", \"five\"&#125;;String resultStr = \"\";StringBuilder resultBuilder = new StringBuilder();for (int i = 0; i &lt; strings.length; i++) &#123; resultStr += strings[i];&#125;for (int i = 0; i &lt; strings.length; i++) &#123; resultBuilder.append(strings[i]);&#125; 在利用+直接进行拼接时，每次循环都会生成一个新的StringBuilder对象，也就是说等同： 123StringBuilder stringBuilder = new StringBuilder(resultStr);stringBuilder.append(strings[i]);resultStr = stringBuilder.toString(); 这样运行的效率明显是低于显式调用StringBuilder的。 但是在有一种情况下，利用+拼接的速度会远远快于用StringBuilder或者StringBuffer，考虑如下代码： 12String str = \"one\" + \"two\" + \"three\";StringBuilder strBuilder = new StringBuilder().append(\"one\").append(\"two\").append(\"three\"); 在这种情况下，JVM会直接把String str = &quot;one&quot; + &quot;two&quot; + &quot;three&quot;;理解为String str = &quot;onetwothree”;，也就说不需要像通常情况下生成StringBuilder对象然后再拼接，速度自然快很多。不过需要强调的一点是，当然字符串来自其他对象的时候，JVM不会做这种特殊处理，也就说如下代码： 1234String one = \"one\";String two = \"two\";String three = \"three\";String str = one + two + three; 效率仍然是非常低的。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://findingsea.github.io/tags/Java/"}]},{"title":"Rotate Array@LeetCode","slug":"rotate-array","date":"2015-03-17T05:31:00.000Z","updated":"2020-02-22T09:30:45.914Z","comments":true,"path":"2015/03/17/rotate-array/","link":"","permalink":"http://findingsea.github.io/2015/03/17/rotate-array/","excerpt":"Rotate Array 这题当然有很朴素的解法，例如利用k%nums.length次循环每次循环都将原字符串向右推移1位，或者直接计算出每个字符最终所应该在的位置直接进行赋值。","text":"Rotate Array 这题当然有很朴素的解法，例如利用k%nums.length次循环每次循环都将原字符串向右推移1位，或者直接计算出每个字符最终所应该在的位置直接进行赋值。 那么这两种方法，前者复杂度太高，或者不够清晰简单。 我选用的是在编程珠玑中提到的翻转方法，比如我们的输入是[1,2,3,4,5,6,7]和k = 3，那么翻转需要如下三部： 翻转[1,2,3,4]部分，得到[4,3,2,1,5,6,7] 翻转[5,6,7]部分，得到[4,3,2,1,7,6,5] 翻转整个数组，得到[5,6,7,1,2,3,4]，也就是最终答案 可以看到这种方法，只要写一个翻转数组的函数，然后调用三次即可。 实现代码如下： 12345678910111213141516171819public class Solution &#123; public void rotate(int[] nums, int k) &#123; if (nums.length == 0 || nums.length == 1 || k % nums.length == 0) return; k %= nums.length; int length = nums.length; reverse(nums, 0, length - k - 1); reverse(nums, length - k, length - 1); reverse(nums, 0, length - 1); &#125; private void reverse(int[] nums, int begin, int end) &#123; for (int i = 0; i &lt; (end - begin + 1) / 2; i++) &#123; int temp = nums[begin + i]; nums[begin + i] = nums[end - i]; nums[end - i] = temp; &#125; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Repeated DNA Sequences@LeetCode","slug":"repeated-dna-sequences","date":"2015-03-17T03:57:00.000Z","updated":"2020-02-22T09:30:45.913Z","comments":true,"path":"2015/03/17/repeated-dna-sequences/","link":"","permalink":"http://findingsea.github.io/2015/03/17/repeated-dna-sequences/","excerpt":"Repeated DNA Sequences 这一题经典的用二进制序列表示字符串序列，以减少内存消耗的例子。","text":"Repeated DNA Sequences 这一题经典的用二进制序列表示字符串序列，以减少内存消耗的例子。 题目中提到DNA序列只包含四种碱基对，分别用A，C，G和T表示，那么就可以用二进制数来分别代表它们： A：00 C：01 G：10 T：11 那么形如ACGT的DNA序列就可以表示为00011011，也就是27。而且这个值对于所有DNA序列都是唯一的，那么就可以把它作为key，出现的次数作为value，将已出现过的key都放入哈希表中即可。 代码如下： 1234567891011121314151617181920212223242526public class Solution &#123; public List&lt;String&gt; findRepeatedDnaSequences(String s) &#123; List&lt;String&gt; result = new LinkedList&lt;String&gt;(); HashMap&lt;Character, Integer&gt; tokenValueMap = new HashMap&lt;Character, Integer&gt;(); tokenValueMap.put('A', 0); tokenValueMap.put('C', 1); tokenValueMap.put('G', 2); tokenValueMap.put('T', 3); HashMap&lt;Integer, Integer&gt; sequenceCountMap = new HashMap&lt;Integer, Integer&gt;(); int length = s.length(); for (int index = 0; index &lt;= length - 10; index++) &#123; int value = 0; for (int i = 0; i &lt; 10; i++) &#123; value &lt;&lt;= 2; value += tokenValueMap.get(s.charAt(index + i)); &#125; if (!sequenceCountMap.containsKey(value)) &#123; sequenceCountMap.put(value, 1); &#125; else if (sequenceCountMap.get(value) == 1) &#123; sequenceCountMap.put(value, 2); result.add(s.substring(index, index + 10)); &#125; &#125; return result; &#125;&#125;","categories":[],"tags":[]},{"title":"面试查漏补缺——阿里","slug":"alibaba-phone-interview","date":"2015-03-17T02:05:00.000Z","updated":"2020-02-22T09:30:45.913Z","comments":true,"path":"2015/03/17/alibaba-phone-interview/","link":"","permalink":"http://findingsea.github.io/2015/03/17/alibaba-phone-interview/","excerpt":"阿里电话面试面试时间：2015-03-16","text":"阿里电话面试面试时间：2015-03-16 Java StringBuffer和StringBuilder的区别的问题。String,StringBuffer与StringBuilder的区别?? StringBuilder and StringBuffer 简单来说：StringBuilder的效率更高；StringBuffer是线程安全的，而StringBuilder不是线程安全的。 快排性能 平均时间：O(nlogn) 最差情况：O(n ^ 2) 稳定度：不稳定 额外空间：O(logn)或者O(n) 解释为什么最坏情况是O(n ^ 2)：考虑类似5 4 3 2 1的输入，那么每个数都会被选为基准，因此每个数都会和其他数进行比较，所以比较的次数就是n ^ 2。 查看Linux负载情况top命令 Thread vs RunnableThread和Runnable的区别 Thread是类，Runnable是接口。在实际使用中，更多地使用Runnable，因为接口的性质，值得实现接口可以给类提供更多的灵活性。 TCP vs UDP TCP：传输控制协议，面向链接，可靠，提供了超时重发、丢弃重复数据、检验数据、流量控制等，保证数据从一端传到另一端。 UDP：用户数据报协议，面向数据包，不可靠，只管发送，不保证送达，也没有超时重传机制，故而速度很快。 创建索引create index index_name on table_name 2015-03-18 Upate 阿里视频面试 堆和栈的区别堆和栈的区别（转过无数次的文章） 简单来讲，形如int a = 1的基本类型，都分配在栈上，且栈上的对象可以共享；形如Object obj = new Object()的对象，都分配在堆上，不可共享。 栈的速度要比堆快，在C++中，分配在栈上的空间由系统回收，分配在堆上的空间由程序员回收，也就是del。但是由于Java有JVM的存在，所以基本不用自己回收任何资源。 TCP/IP协议断开时需要几次图解TCP-IP协议 TCP\\IP三次握手连接，四次握手断开分析 简单形容的话，建立连接时的三次握手： 客户端 —&gt; 服务器，客户端请求连接 服务器 —&gt; 客户端，服务器确认连接信息 客户端 —&gt; 服务器，客户端确认连接信息，开始连接 断开连接时的四次握手： A —&gt; B，A请求断开连接 B —&gt; A，B确认请求并准备断开连接 B —&gt; A，B关闭连接并通知A A —&gt; B，A确认关闭","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"http://findingsea.github.io/tags/Interview/"}]},{"title":"Min Stack@LeetCode","slug":"min-stack","date":"2015-03-12T05:12:00.000Z","updated":"2020-02-22T09:30:45.913Z","comments":true,"path":"2015/03/12/min-stack/","link":"","permalink":"http://findingsea.github.io/2015/03/12/min-stack/","excerpt":"Min Stack","text":"Min Stack 这一题我一开始的实现方法是：维护一个栈用来保存数据，然后用一个整型（min）保存当前最小值。这样针对每一个操作： push(x)输入入栈，然后更新最小值 pop()出栈，然后更新最小值 top()直接返回栈顶元素 getMin()直接返回最小值 这样的实现方法，除pop()外，其实方法都是O(1)的，符合题目要求的constant time。但是pop()操作，在最坏情况下是O(n)的复杂度（最小值出栈了）。虽然从理论上并不能完全保证constant time，但是在测试数据分布比较均匀的情况下，AC是没问题的，而且相比于正确方法可能还效率高一点，毕竟出栈入栈都是需要时间的。 代码如下： 12345678910111213141516171819202122232425262728293031323334class MinStack &#123; private Stack&lt;Integer&gt; stack; private int min; public MinStack() &#123; stack = new Stack&lt;Integer&gt;(); min = Integer.MAX_VALUE; &#125; public void push(int x) &#123; stack.push(x); min = Math.min(min, x); &#125; public void pop() &#123; int top = stack.pop(); if (top == min) &#123; min = Integer.MAX_VALUE; Iterator iterator = stack.iterator(); while (iterator.hasNext()) &#123; min = Math.min(min, (Integer) iterator.next()); &#125; &#125; &#125; public int top() &#123; return stack.peek(); &#125; public int getMin() &#123; return min; &#125;&#125; 完整正确的方法是：维护两个栈。一个数据栈，一个最小值栈。 数据栈的维护和前一种方法相同，也就是一般栈的维护方法。 最小栈的维护，包括： 有数据输入时，检查是否小于等于最小栈的栈顶元素，如果是则将新元素压入最小栈 有输入弹出时，检查是否等于最小栈的栈顶元素，如果是则将最小栈栈顶元素弹出 调用getMin()方法时，直接返回最小栈的栈顶元素 之前我怀疑这种方法有问题的时候，考虑到的是：如果当前弹出的元素第二或者第三小的元素，那么如果维护最小栈。后来发现这样的担心是多余的，由于栈的特性，如果要弹出第二或者第三小的元素，那么最小元素必然在此前已经被弹出，而不需要考虑多余的维护策略。 具体代码如下： 1234567891011121314151617181920212223242526272829303132class MinStack &#123; private Stack&lt;Integer&gt; stack; private Stack&lt;Integer&gt; minStack; public MinStack() &#123; stack = new Stack&lt;Integer&gt;(); minStack = new Stack&lt;Integer&gt;(); &#125; public void push(int x) &#123; stack.push(x); if (minStack.isEmpty() || x &lt;= minStack.peek()) &#123; minStack.push(x); &#125; &#125; public void pop() &#123; int top = stack.pop(); if (top == minStack.peek()) &#123; minStack.pop(); &#125; &#125; public int top() &#123; return stack.peek(); &#125; public int getMin() &#123; return minStack.peek(); &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Maximum Product Subarray@LeetCode","slug":"maximum-product-subarray","date":"2015-03-12T03:18:00.000Z","updated":"2020-02-22T09:30:45.913Z","comments":true,"path":"2015/03/12/maximum-product-subarray/","link":"","permalink":"http://findingsea.github.io/2015/03/12/maximum-product-subarray/","excerpt":"Maximum Product Subarray","text":"Maximum Product Subarray 一开始题目没有看清楚，以为还是求和，但是这一题其实是求乘积，那么相对于求和的题目，求乘积需要注意的有两点： 元素为0的点，只要包含了元素为0的点，那么整段的乘积必为0 正负数，不能简单地依靠动态规划的方法做，因为之后的信息对之前的信息是有影响的：i点之前的乘积为负数，但如果之后还有负数，则乘积会变成正数且将大于之前的乘积 解题的思想如下： 以0为界，分割数组，计算每个0之间（以及0和短点之间）的乘积 针对每一段乘积，如果乘积为正数，则直接返回与当前最大值比较；如果乘积为负数，则取最短负数前缀和最短负数后缀（连续的乘积为负的数字段），分别用整段乘积去除之后就能得到该段最大乘积 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Solution &#123; public int maxProduct(int[] A) &#123; int max = A[0], length = A.length; int begin = 0, end, product; while (begin &lt; length &amp;&amp; A[begin] == 0) &#123; begin++; &#125; if (begin == length) return 0; end = begin + 1; product = A[begin]; while (end &lt; length) &#123; if (A[end] == 0) &#123; max = Math.max(max, Math.max(0, countMax(begin, end, A, product))); begin = end + 1; while (begin &lt; length &amp;&amp; A[begin] == 0) &#123; begin++; &#125; if (begin == length) break; product = A[begin]; end = begin + 1; &#125; else &#123; product *= A[end++]; &#125; &#125; if (begin != length) max = Math.max(max, countMax(begin, length, A, product)); return max; &#125; private int countMax(int begin, int end, int[] A, int product) &#123; if (product &gt; 0 || end - begin == 1) &#123; return product; &#125; int index = begin; int preProduct = 1, sufProduct = 1; while (index &lt; end - 1 &amp;&amp; A[index] &gt; 0) &#123; preProduct *= A[index]; index++; &#125; preProduct *= A[index]; index = end - 1; while (begin &lt; index &amp;&amp; A[index] &gt; 0) &#123; sufProduct *= A[index]; index--; &#125; sufProduct *= A[index]; return Math.max(product / preProduct, product / sufProduct); &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Java Callback","slug":"java-callback","date":"2015-03-11T08:51:00.000Z","updated":"2020-02-22T09:30:45.913Z","comments":true,"path":"2015/03/11/java-callback/","link":"","permalink":"http://findingsea.github.io/2015/03/11/java-callback/","excerpt":"如何编写回调函数？ 回调函数其实就是将某个特定接口的实现作为参数传入目标对象，让目标对象在适当的时候对齐进行调用。","text":"如何编写回调函数？ 回调函数其实就是将某个特定接口的实现作为参数传入目标对象，让目标对象在适当的时候对齐进行调用。 Response接口包含了两个方法：success和fail，分别需要在请求成功和失败时调用，但是具体这两个方法需要做写什么事情，这在接口的定义中是无从知道的，因为这是根据每个发送请求的主体的具体情况而确定的。 Request是发送请求类，是执行人物的主体，在其send(Response response)方法中，会接受一个Response接口的实现，并在请求完成后，根据请求的结果调用Response中相应的方法。 CallbackSample是测试的主体，在main函数中，产生一个Request对象，然后调用其send方法，同时传入一个匿名类实现了Response接口。 123456789/** * Created by findingsea on 3/11/15. */public interface Response &#123; void success(); void fail();&#125; 1234567891011/** * Created by findingsea on 3/11/15. */public class Request &#123; public void send(Response response) &#123; System.out.println(\"Send Request\"); response.fail(); &#125;&#125; 1234567891011121314151617181920/** * Created by findingsea on 3/11/15. */public class CallbackSample &#123; public static void main(String[] args) &#123; Request request = new Request(); request.send(new Response() &#123; @Override public void success() &#123; System.out.println(\"Request Success\"); &#125; @Override public void fail() &#123; System.out.println(\"Request Fail\"); &#125; &#125;); &#125;&#125; 以下是输出： 12Send RequestRequest Fail","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://findingsea.github.io/tags/Java/"}]},{"title":"Word Ladder I II@LeetCode","slug":"word-ladder-i-ii","date":"2015-02-27T10:41:00.000Z","updated":"2020-02-22T09:30:45.913Z","comments":true,"path":"2015/02/27/word-ladder-i-ii/","link":"","permalink":"http://findingsea.github.io/2015/02/27/word-ladder-i-ii/","excerpt":"Word Ladder这个系列的两题都是靠了看别人的解法才做出来的，很有必要好好总结下。","text":"Word Ladder这个系列的两题都是靠了看别人的解法才做出来的，很有必要好好总结下。 看到这题的时候我其实就没什么想法，对这种类型题的经验太少。上网查完之后，确定要用图的思想解决，思路就是从起点出发对字典中可达的字符串进行BFS（广度优先搜索）并记录当前节点与起点的距离，一旦找到了目标字符串即返回。 1234567891011121314151617181920212223242526public class Solution &#123; public int ladderLength(String start, String end, Set&lt;String&gt; dict) &#123; HashMap&lt;String, Integer&gt; disMap = new HashMap&lt;String, Integer&gt;(); LinkedList&lt;String&gt; queue = new LinkedList&lt;String&gt;(); queue.add(start); disMap.put(start, 1); while (!queue.isEmpty()) &#123; String word = queue.poll(); for (int i = 0; i &lt; word.length(); i++) &#123; for (char ch = 'a'; ch &lt;= 'z'; ch++) &#123; StringBuffer buffer = new StringBuffer(word); buffer.setCharAt(i, ch); String nextWord = buffer.toString(); if (end.equals(nextWord)) &#123; return disMap.get(word) + 1; &#125; if (dict.contains(nextWord) &amp;&amp; !disMap.containsKey(nextWord)) &#123; disMap.put(nextWord, disMap.get(word) + 1); queue.add(nextWord); &#125; &#125; &#125; &#125; return 0; &#125;&#125; Word Ladder II一开始以为做了I之后，用一样的思路解决II应该会容易很多。但做了才发现，II对效率的要求更高，而且这使得这一题成为了LeetCode上通过率最低的题之一。 先讲一下自己做的时候的思路，和I相似，用图的思想，只不过是该用DFS（深度优先搜索），从起点出发，对字典中的每一个可达字符串进行DFS并记录路径，到达目标之后在当前路径和之间的最短路径中取较短者。代码如下，大数据集合超时。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Solution &#123; public List&lt;List&lt;String&gt;&gt; findLadders(String start, String end, Set&lt;String&gt; dict) &#123; List&lt;List&lt;String&gt;&gt; result = new LinkedList&lt;List&lt;String&gt;&gt;(); LinkedList&lt;String&gt; sequence = new LinkedList&lt;String&gt;(); HashMap&lt;String, Boolean&gt; usedMap = new HashMap&lt;String, Boolean&gt;(); sequence.add(start); usedMap.put(start, true); find(result, sequence, start, end, dict, usedMap); return result; &#125; private void find(List&lt;List&lt;String&gt;&gt; result, LinkedList&lt;String&gt; sequence, String word, String end, Set&lt;String&gt; dict, HashMap&lt;String, Boolean&gt; usedMap) &#123; for (int i = 0; i &lt; word.length(); i++) &#123; for (char ch = 'a'; ch &lt;= 'z'; ch++) &#123; if (word.charAt(i) == ch) continue; StringBuffer buffer = new StringBuffer(word); buffer.setCharAt(i, ch); String nextWord = buffer.toString(); if (end.equals(nextWord)) &#123; int minLength = result.size() == 0 ? 0 : result.get(result.size() - 1).size(); if (minLength == 0 || sequence.size() + 1 &lt;= minLength) &#123; if (sequence.size() + 1 &lt; minLength) &#123; result.clear(); &#125; List&lt;String&gt; res = new LinkedList&lt;String&gt;(); for (String str : sequence) &#123; res.add(str); &#125; res.add(nextWord); result.add(res); &#125; return; &#125; if (dict.contains(nextWord) &amp;&amp; (!usedMap.containsKey(nextWord) || !usedMap.get(nextWord))) &#123; sequence.add(nextWord); usedMap.put(nextWord, true); find(result, sequence, nextWord, end, dict, usedMap); sequence.pollLast(); usedMap.put(nextWord, false); &#125; &#125; &#125; &#125;&#125; 仔细分析最初的代码，发现耗时的地方在于：对于每一个可达的点都要尝试一下，相当于遍历了所以从起点可达终点的线路（也导致了很多点其实多次重复遍历），但是这其中很多线路本身的遍历是没有价值的，如果当前线路已经比最短可达路径长度长了，那接着往下遍历是没有意义的。所以改进的算法也是针对这一点来减少需要遍历的点和线路。 参考了网上的做法之后，确定了基本的解决方案： 从起点出发，对字典中的所有字符串都遍历一遍，并记录它们到起点的距离，相当于先做BFS，由于是深度优先搜索，所以保证保存下来的距离都是起点到每个节点的最短距离。 在从起点出发，根据可达性和与起点的距离进行深度优先搜索，并记录路径，在搜索时，要根据层来搜索，也就说确定下一个搜索节点，不光是根据从当前节点是否可达，还要根据下一节点和当前节点是否处在相邻的两层，这样能够避免对节点的重复遍历包含同时也时刻保持当前路径是最短的。 下面是代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class Solution &#123; public List&lt;List&lt;String&gt;&gt; findLadders(String start, String end, Set&lt;String&gt; dict) &#123; LinkedList&lt;String&gt; queue = new LinkedList&lt;String&gt;(); HashMap&lt;String, Integer&gt; disMap = new HashMap&lt;String, Integer&gt;(); queue.add(start); disMap.put(start, 1); while (!queue.isEmpty()) &#123; String word = queue.poll(); for (int i = 0; i &lt; word.length(); i++) &#123; for (char ch = 'a'; ch &lt;= 'z'; ch++) &#123; if (word.charAt(i) == ch) continue; StringBuffer buffer = new StringBuffer(word); buffer.setCharAt(i, ch); String nextWord = new String(buffer); if (end.equals(nextWord)) &#123; disMap.put(end, disMap.get(word) + 1); i = word.length(); ch = 'z'; queue.clear(); &#125; if (dict.contains(nextWord) &amp;&amp; !disMap.containsKey(nextWord)) &#123; queue.add(nextWord); disMap.put(nextWord, disMap.get(word) + 1); &#125; &#125; &#125; &#125; List&lt;List&lt;String&gt;&gt; result = new LinkedList&lt;List&lt;String&gt;&gt;(); find(result, new LinkedList&lt;String&gt;(), end, start, dict, disMap); return result; &#125; private void find(List&lt;List&lt;String&gt;&gt; result, LinkedList&lt;String&gt; sequence, String word, String end, Set&lt;String&gt; dict, HashMap&lt;String, Integer&gt; disMap) &#123; if (disMap.get(word) == disMap.get(end) &amp;&amp; !end.equals(word)) &#123; return; &#125; else if (end.equals(word)) &#123; List&lt;String&gt; res = new LinkedList&lt;String&gt;(sequence); res.add(word); Collections.reverse(res); result.add(res); return; &#125; sequence.add(word); for (int i = 0; i &lt; word.length(); i++) &#123; for (char ch = 'a'; ch &lt;= 'z'; ch++) &#123; if (word.charAt(i) == ch) continue; StringBuffer buffer = new StringBuffer(word); buffer.setCharAt(i, ch); String nextWord = buffer.toString(); if (dict.contains(nextWord) &amp;&amp; disMap.containsKey(nextWord) &amp;&amp; disMap.get(nextWord) == disMap.get(word) - 1) &#123; find(result, sequence, nextWord, end, dict, disMap); &#125; &#125; &#125; sequence.remove(sequence.size() - 1); &#125;&#125; 这个代码仍然超时，仔细对照了我自己写的代码和参考的代码之后，唯一做法上的不同在于：在DFS时，我的做法是从起点开始去找终点；而在参考代码的做法则是从终点开始找起点。我对这部分进行修改之后就能顺利AC了，关于这个问题，我猜测LeetCode的测试数据很可能都是前密后疏的类型，也就是从越靠近起点，线路越多，越靠近终点，线路越少。如果是这种数据的话，从终点出发的确是可以节省很多时间的。 虽然对DFS部分的代码进行修改之后能够AC了，但是我还是发现我写的代码的运行耗时（900ms左右）比参考的代码的运行耗时要长（700ms左右），虽说这点差距都是在允许范围内的，但是在考虑到总体代码结构都一致的情况下，这个差距还是不小的，所以我又仔细比较了两份代码，发现了一处处理方式的不同。 在参考代码中，对当前字符串进行变换采用的是如下形式： 123456789101112131415161718for (int i = 0; i &lt; current.length(); i++) &#123; char[] strCharArr = current.toCharArray(); for (char ch = 'a'; ch &lt;= 'z'; ch++) &#123; if (strCharArr[i] == ch) &#123; continue; &#125; strCharArr[i] = ch; String newWord = new String(strCharArr); if (newWord.equals(end) == true || dict.contains(newWord)) &#123; //每个单词在path中只能出现一次，也就是每个单词只能出现在一层中，这样就很巧妙的解决了环的问题。 if (path.get(newWord) == null) &#123; int depth = (int) path.get(current); path.put(newWord, depth + 1); queue.add(newWord); &#125; &#125; &#125;&#125; 而我的代码采用是如下形式 1234567891011121314151617181920for (int i = 0; i &lt; word.length(); i++) &#123; for (char ch = 'a'; ch &lt;= 'z'; ch++) &#123; if (word.charAt(i) == ch) continue; StringBuffer buffer = new StringBuffer(word); buffer.setCharAt(i, ch); String nextWord = buffer.toString(); if (end.equals(nextWord)) &#123; disMap.put(end, disMap.get(word) + 1); i = word.length(); ch = 'z'; queue.clear(); &#125; if (dict.contains(nextWord) &amp;&amp; !disMap.containsKey(nextWord)) &#123; queue.add(nextWord); disMap.put(nextWord, disMap.get(word) + 1); &#125; &#125;&#125; 也就说，差别主要在于是把字符串转换成字符数组来进行修改还是还是创建一个StringBuffer来进行修改。于是我对自己的代码的这一部分也进行了修改，果然耗时减少了，这也说明字符数组的操作还是要比StringBuffer的操作省时很多。 最后，在参考代码基础上，我又做出了一点小改进。 提前结束层序图的构建。在构建每个节点到七点距离时（也就是构建图结构时），一旦遇到end点（终点）就终止遍历。这是因为使用BFS，每个点第一次出现时的距离，即为该点到起点的最短距离。也就是说，一旦出现了end点，那么当前所记录的end点所在的层位置，即为end点到start点的最短距离，同时之后出现的所有点（同样考虑BFS），它们到start点的距离是大于等于end点的，那么遍历那些点是没有意义的。 当考虑如下输入集合： 12345start = \"hit\"end = \"hoo\"dict = [\"hot\", \"mit\", \"mot\", \"moo\", \"aoo\", \"boo\", \"coo\"] 我改进之后的代码运行效率要比参考的代码高，因为构建层序图（BFS）时遍历的点更少（提到end点就结束了），构建出来的层序图点更少（去除了一些无用点），那么在DFS中遍历的点也更少，所以结合两方面的省时来提高了程序整体的运行效率。 如下是最后的完整代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class Solution &#123; private HashMap&lt;String, Integer&gt; disMap; public List&lt;List&lt;String&gt;&gt; findLadders(String start, String end, Set&lt;String&gt; dict) &#123; LinkedList&lt;String&gt; queue = new LinkedList&lt;String&gt;(); disMap = new HashMap&lt;String, Integer&gt;(); queue.add(start); disMap.put(start, 1); while (!queue.isEmpty()) &#123; String word = queue.poll(); for (int i = 0; i &lt; word.length(); i++) &#123; char[] chars = word.toCharArray(); for (char ch = 'a'; ch &lt;= 'z'; ch++) &#123; if (chars[i] == ch) continue; chars[i] = ch; String nextWord = new String(chars); if (end.equals(nextWord)) &#123; disMap.put(end, disMap.get(word) + 1); i = word.length(); ch = 'z'; queue.clear(); &#125; if (dict.contains(nextWord) &amp;&amp; !disMap.containsKey(nextWord)) &#123; queue.add(nextWord); disMap.put(nextWord, disMap.get(word) + 1); &#125; &#125; &#125; &#125; List&lt;List&lt;String&gt;&gt; result = new LinkedList&lt;List&lt;String&gt;&gt;(); find(result, new LinkedList&lt;String&gt;(), end, start); return result; &#125; private void find(List&lt;List&lt;String&gt;&gt; result, LinkedList&lt;String&gt; sequence, String word, String end) &#123; if (disMap.get(word) == disMap.get(end) &amp;&amp; !end.equals(word)) &#123; return; &#125; else if (end.equals(word)) &#123; List&lt;String&gt; res = new LinkedList&lt;String&gt;(sequence); res.add(word); Collections.reverse(res); result.add(res); return; &#125; sequence.add(word); for (int i = 0; i &lt; word.length(); i++) &#123; char[] chars = word.toCharArray(); for (char ch = 'a'; ch &lt;= 'z'; ch++) &#123; if (chars[i] == ch) continue; chars[i] = ch; String nextWord = new String(chars); if (disMap.containsKey(nextWord) &amp;&amp; disMap.get(nextWord) == disMap.get(word) - 1) &#123; find(result, sequence, nextWord, end); &#125; &#125; &#125; sequence.remove(sequence.size() - 1); &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"Best Time to Buy and Sell Stock I II III IV@LeetCode","slug":"best-time-to-buy-and-sell-stock-i-ii-iii","date":"2015-02-26T02:12:00.000Z","updated":"2020-02-22T09:30:45.912Z","comments":true,"path":"2015/02/26/best-time-to-buy-and-sell-stock-i-ii-iii/","link":"","permalink":"http://findingsea.github.io/2015/02/26/best-time-to-buy-and-sell-stock-i-ii-iii/","excerpt":"Best Time to Buy and Sell Stock相对比较简单的方法是用DP，思路是对于每个i都求出从0到i区间内的最大获益，而对于i+1只需要比较第i+1天的价格和前i天最低价的关系，就可以直接求出0到i+1天区间内的最大获益。也就是说对0到i天的最大获益的计算复杂度是O(1)，总体复杂度是O(n)。","text":"Best Time to Buy and Sell Stock相对比较简单的方法是用DP，思路是对于每个i都求出从0到i区间内的最大获益，而对于i+1只需要比较第i+1天的价格和前i天最低价的关系，就可以直接求出0到i+1天区间内的最大获益。也就是说对0到i天的最大获益的计算复杂度是O(1)，总体复杂度是O(n)。 详细解释下从第i天的最大获益如何推出第i+1天的最大获益，已知是的是前i天的最大获益以及前i天的最低价，那么对于第i+1天的价格而言： 第i+1天的价格大于minPrice（已遍历数据的最低价），此时只要对max(i)（前i天的最大获益）和prices[i + 1] - minPrice（第i+1天卖出所能得到的获益）取大值就能得出max(i + 1) 第i+1天的价格小于等于minPrice，那么在第i+1天卖出所得到的获益必然是小于max(i)（这里哪怕考虑极端情况：给出的数据是整体递减的，那么最佳的卖出时机也是当天买当天卖，获益为0，所以不会存在获益是负值的情况），所以max(i + 1) = max(i)。而且，对于之后的数据而言，minPrice需要更新了，因为对于之后的数据，在第i+1天买进必然比在0到i天之间的任何时候买进的获益都要多（因为第i+1天是0到i+1区间内的最低价）。 相较于网上一般的DP做法，我的小改进在于没有维护整个max数组，而是指用了一个max整型值来保存当前的最大获益，空间复杂度是O(1)。这个技巧其实在很多DP解法中都可以用到，只要之前的数据不需要回朔（或者是只需要回朔某几个位置的数据），很多情况下都可以把DP的数组从O(n^2)降到O(n)，从O(n)降到O(1)。 123456789101112131415public class Solution &#123; public int maxProfit(int[] prices) &#123; if (prices == null || prices.length == 0) return 0; int max = 0, minPrice = prices[0]; for (int i = 1; i &lt; prices.length; i++) &#123; if (prices[i] &lt;= minPrice) &#123; minPrice = prices[i]; &#125; else &#123; max = Math.max(max, prices[i] - minPrice); &#125; &#125; return max; &#125;&#125; Best Time to Buy and Sell Stock II这个进阶版和基础版的不同在于可以进行任意多次交易，这样其实限制更少，只要把所有递增区间的获益求和就行了。 12345678910111213141516171819202122public class Solution &#123; public int maxProfit(int[] prices) &#123; int max = 0; int i = 0; while (i &lt; prices.length - 1) &#123; if (prices[i] &gt;= prices[i + 1]) &#123; i++; continue; &#125; int j = i + 1; for (; j &lt; prices.length; j++) &#123; if (j &lt; prices.length - 1 &amp;&amp; prices[j] &lt;= prices[j + 1]) &#123; continue; &#125; max += prices[j] - prices[i]; break; &#125; i = j + 1; &#125; return max; &#125;&#125; Best Time to Buy and Sell Stock III高级版的难度一下子就提升了，刚一开始我的错误想法是：将两个获益最大区间的获益相加，后来很快就证明了这个解法是错误的。 借助网络之后，确定了正确解法：构造两个数组，left和right，left[i]表示从0到i天的最大获益，right[i]表示从i到最后一天的最大获益。 求left的方法其实就解题I的方法，不再赘述。 求right的方法其实是求left的对称解法： 求left时，记录前i天的最低价minPrice与最大获益max，求left[i]：考虑要在第i天卖出，那么买进的时间必然是在0到i之间（闭区间），这个时候只需要比较prices[i]-minPrice和max就可以求出截止到第i天的最大获益，然后根据需要更新minPrice。 求right时，记录从第i天往后的最高价maxPrice与最大获益max，求right[i]：考虑要再第i天买进，那么卖出时间必然是在i到最后一天之间（闭区间），这个时候只需要比较maxPrice-prices[i]和max就可以求出从第i天开始的最大获益，然后根据需要更新maxPrice。 对于left和right的构造算法复杂度都是O(n)。 构造完left和right之后，只要求left[i]+right[i]的最大值就行了。 12345678910111213141516171819202122232425262728293031public class Solution &#123; public int maxProfit(int[] prices) &#123; if (prices == null || prices.length == 0) return 0; int max = 0; int[] left = new int[prices.length]; int[] right = new int[prices.length]; int minPrice = prices[0]; for (int i = 1; i &lt; prices.length; i++) &#123; if (minPrice &lt; prices[i]) &#123; left[i] = Math.max(left[i - 1], prices[i] - minPrice); &#125; else &#123; left[i] = left[i - 1]; minPrice = prices[i]; &#125; &#125; int maxPrice = prices[prices.length - 1]; for (int i = prices.length - 2; i &gt;= 0; i--) &#123; if (prices[i] &lt; maxPrice) &#123; right[i] = Math.max(right[i + 1], maxPrice - prices[i]); &#125; else &#123; right[i] = right[i + 1]; maxPrice = prices[i]; &#125; &#125; for (int i = 0; i &lt; prices.length; i++) &#123; max = Math.max(max, left[i] + right[i]); &#125; return max; &#125;&#125; Best Time to Buy and Sell Stock IV这一题的难度要远高于前面几题，需要用到动态规划，但是需要额外的辅助。 先按照之前的方法对数组进行统计，计算出无限制条件下的最少交易次数tradeCount和最大获益profitCount。如果这个最少交易次数已经小于k了，那么直接返回最大获益即可。同时也因为在k &lt; tradeCount的情况下，进行动态规划的效率很低，所以要先进行处理来避免。 在动态规划的部分，维护两个数组：local和global。其中local[i][j]表示总交易次数为i截止到第j天并且在最后一天要做交易的情况下的最大获益，global[i][j]表示总交易次数为i截止到第j天的最大获益。 之所以在global之外还要维护一个local数组，是因为在计算global[i][j]时，面临两种情况： 最后一天不做交易，那么直接等于global[i][j - 1] 最后一天要做交易，那么又需要分别考虑罪有一天是否有收益的问题，所以要增加一个local数组进行辅助 递推公式： 123int diff = prices[j] - prices[j - 1];local[i][j] = Math.max(global[i - 1][j - 1], local[i][j - 1] + diff);global[i][j] = Math.max(global[i][j - 1], local[i][j]); 解释一下local[i][j] = Math.max(global[i - 1][j - 1], local[i][j - 1] + diff);这一条，当diff &lt; 0时，在最后一条做交易必然是亏的，所以其实此时local[i][j]直接等于global[i - 1][j - 1]；当diff &gt; 0时，本来应该比较两种情况的，global[i - 1][j - 1] + diff和local[i][j - 1] + diff，但是通过以下推断我们可以知道local[i][j - 1] &gt; global[i - 1][j - 1]，所以无须比较。 推断： 123456789因为global[i - 1][j - 1] = Math.max(global[i - 1][j - 2], local[i - 1][j - 1])所以global[i - 1][j - 1] = global[i - 1][j - 2]或者global[i - 1][j - 1] = local[i - 1][j - 1])由题意可知：local[i][j - 1] &gt; local[i - 1][j - 1])又因为local[i][j - 1] = Math.max(global[i - 1][j - 2], local[i][j - 2] + diff)所以local[i][j - 1] &gt;= global[i - 1][j - 2]综上local[i][j - 1] &gt; local[i - 1][j - 1])并且local[i][j - 1] &gt;= global[i - 1][j - 2]，即local[i][j - 1] &gt; global[i - 1][j - 1] 这里还有一个性质，就是当i大于最大收益所需的交易次数时，其实local[i][j] == global[i][j]，多出来的交易都是当天买卖，不会产生收益。 实现代码： 12345678910111213141516171819202122232425262728293031public class Solution &#123; public int maxProfit(int k, int[] prices) &#123; int days = prices.length; int tradeCount = 0, profitCount = 0, rangeProfitCount = 0; for (int i = 1; i &lt; days; i++) &#123; if (prices[i - 1] &lt; prices[i]) &#123; rangeProfitCount += prices[i] - prices[i - 1]; if (i == days - 1) &#123; profitCount += rangeProfitCount; tradeCount += 1; &#125; &#125; else if (rangeProfitCount &gt; 0) &#123; profitCount += rangeProfitCount; tradeCount += 1; rangeProfitCount = 0; &#125; &#125; if (tradeCount &lt;= k) return profitCount; int[][] global = new int[k + 1][days]; int[][] local = new int[k + 1][days]; for (int i = 1; i &lt;= k; i++) &#123; for (int j = 1; j &lt; days; j++) &#123; int diff = prices[j] - prices[j - 1]; local[i][j] = Math.max(global[i - 1][j - 1], local[i][j - 1] + diff); global[i][j] = Math.max(global[i][j - 1], local[i][j]); &#125; &#125; return global[global.length - 1][global[0].length - 1]; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://findingsea.github.io/tags/LeetCode/"}]},{"title":"JavaScript闭包和this绑定","slug":"javascript-closure","date":"2014-06-07T03:22:00.000Z","updated":"2020-02-22T09:30:45.912Z","comments":true,"path":"2014/06/07/javascript-closure/","link":"","permalink":"http://findingsea.github.io/2014/06/07/javascript-closure/","excerpt":"本文最主要讲讲JavaScript闭包和this绑定相关的我的小发现，鉴于这方面的基础知识已经有很多很好的文章讲过了，所以基本的就不讲了，推荐看看酷壳上的理解Javascript的闭包和阮一峰的学习Javascript闭包（Closure），写的都非常好。","text":"本文最主要讲讲JavaScript闭包和this绑定相关的我的小发现，鉴于这方面的基础知识已经有很多很好的文章讲过了，所以基本的就不讲了，推荐看看酷壳上的理解Javascript的闭包和阮一峰的学习Javascript闭包（Closure），写的都非常好。 首先来讲讲阮一峰的文章中的两道思考题。 代码片段一 12345678910var name = \"The Window\";var object = &#123; name : \"My Object\", getNameFunc : function()&#123; return function()&#123; return this.name; &#125;; &#125;&#125;;alert(object.getNameFunc()()); 这段代码最后输出的是 1The Window 原因在同一片文章的评论中已经有人指出了 George Wing 说： 上面本人说得不太正确。this的指向是由它所在函数调用的上下文决定的，而不是由它所在函数定义的上下文决定的。 对于最后返回的这个匿名函数 123function()&#123; return this.name;&#125;; 它是作为一个独立的函数返回的，它的调用域是在全局上，所以会输出全局变量name。 代码片段二 1234567891011var name = \"The Window\";var object = &#123; name : \"My Object\", getNameFunc : function()&#123; var that = this; return function()&#123; return that.name; &#125;; &#125;&#125;;alert(object.getNameFunc()()); 代码片段二最后输出的是 1My Object 这里就要考虑var that = this;这句的作用了，由于getNameFunc是object内部的函数，所以它调用的上下文this保存的是object的信息，将其保存到that变量，这样作为内部函数的匿名函数就可以直接访问了。 可以注意到的是，阮一峰文章中的代码，都是将通过一个JSON对象来访问内部的函数，这样其实有些地方还不够清晰，毕竟不怎么严格地说，闭包就是函数内部的函数，所以我借用CoolShell上的文章中的例子来进一步说明。 代码片段三 1234567function greeting(name) &#123; var text = 'Hello ' + name; // local variable // 每次调用时，产生闭包，并返回内部函数对象给调用者 return function() &#123; alert(text); &#125;&#125;var sayHello=greeting(\"Closure\");sayHello() // 通过闭包访问到了局部变量text 这段代码输出 1Hello Closure 看上去好像很好理解，接下来看代码片段四： 代码片段四 12345678var text = 'findingsea';function greeting(name) &#123; var text = 'Hello ' + name; // local variable // 每次调用时，产生闭包，并返回内部函数对象给调用者 return function() &#123; alert(this.text); &#125;&#125;var sayHello=greeting(\"Closure\");sayHello() // 通过闭包访问到了局部变量text 这段代码输出 1findingsea 这是为什么呢？ 针对代码片段三，CoolShell上的原文有解释： 文法环境中用于解析函数执行过程使用到的变量标识符。我们可以将文法环境想象成一个对象，该对象包含了两个重要组件，环境记录(Enviroment Recode)，和外部引用(指针)。环境记录包含包含了函数内部声明的局部变量和参数变量，外部引用指向了外部函数对象的上下文执行场景。全局的上下文场景中此引用值为NULL。这样的数据结构就构成了一个单向的链表，每个引用都指向外层的上下文场景。 针对代码片段四，就是我们之前讲过的，this保存是调用环境下的上下文内容，所以会输出全局的text。 ####总结本文想说明的是以下两点： 在函数闭包中，不使用this对变量进行访问时，函数会通过文法环境中的外部引用（指针），一级级地往上找（单向链表），直到找到（或者最终找不到）对应的变量。这个结构是在函数定义的时候就决定了的。 在函数闭包中，使用this对变量进行访问时，和绝大多数语言不同，JavaScript的this保存的是调用环境的上下文，也就是说this中的内容是在调用的时候决定的，所以访问到的是当前环境下的对应变量，并不会像前一种情况一样进行逐级查找。","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://findingsea.github.io/tags/JavaScript/"}]},{"title":"HD-OJ-1005","slug":"hd-oj-1005","date":"2014-04-22T08:36:00.000Z","updated":"2020-02-22T09:30:45.912Z","comments":true,"path":"2014/04/22/hd-oj-1005/","link":"","permalink":"http://findingsea.github.io/2014/04/22/hd-oj-1005/","excerpt":"杭电OJ 1005：","text":"杭电OJ 1005： #####Problem Description A number sequence is defined as follows: f(1) = 1, f(2) = 1, f(n) = (A * f(n - 1) + B * f(n - 2)) mod 7. Given A, B, and n, you are to calculate the value of f(n). #####Input The input consists of multiple test cases. Each test case contains 3 integers A, B and n on a single line (1 &lt;= A, B &lt;= 1000, 1 &lt;= n &lt;= 100,000,000). Three zeros signal the end of input and this test case is not to be processed. #####Output For each test case, print the value of f(n) on a single line. #####Sample Input 1 1 3 1 2 10 0 0 0 #####Sample Output 2 5 题目对于那些ACM选手来说，肯定不是什么大问题，不过对于我们这种只能刷刷水题的人来说，还是有点困难的。 我看到题目之后的第一反应是对于每一个特定的A和B，每次的计算结果都存到数组里，这样不用每个输入都重新计算，可以节省一定量的时间，当时觉得这个想法已经不错了，但是还是TLE了。最后上网找了答案，发现很多答案里都提到f(n)的值其实是循环的，而且最大的循环长度不会超过49（即起码在n=49之前，f(n)的值就开始循环了，f(k)=f(1)，f(k+1)=f(2)，f(k+2)=f(3)，…，k&lt;=49）。但是网上很多文章并没有指出怎么才能发现，或者说推导出这个规律。最后我花了点时间，自己推了下才终于知道了发现规律的方法。 首先，观察到递推式里有mod 7，就知道f(n)的所有值都在[0, 6]之间，有7个取值。 然后，观察递推式，f(n) = (A * f(n - 1) + B * f(n - 2)) mod 7，A和B是定常数，而f(n - 1)和f(n - 2)的取值都分别有7种可能，也就是说f(n)的取值最多有49种组合（这49种组合中，和可能相同，但是代表的意义不同，例如1+4和2+3是不同的，2+3和3+2也是不同的）。当n &gt; 51时（因为这种组合是从n=3开始算的），f(n)的取值组合必然是之前出现过了的，也就是必存在 123f(n) = f(k), f(n - 1) + f(n - 2) = f(k - 1) + f(k - 2)f(n - 1) = f(k - 1)f(n - 2) = f(k - 2) 但是其实我们可以知道，f(n) = 0 + 0，这种情况是不可能的（因为这样话很容易证明对于所有的n，f(n)都是为0），所以其实最多只有48种情况，即从n = 50开始，组合就必然出现重复了。其次，我们知道了f(n)和f(k)的取值组合完全相同后，只要证明f(n + 1) = f(k + 1)的即可证明f(n)的取值在n &gt; 49后必然存在循环。 123f(n + 1) = f(n) + f(n - 1)f(n) = f(k)f(n - 1) = f(k - 1) 由以上条件可知，f(n + 1) = f(k + 1)，同理可以推导出f(n + 2) = f(k + 2)，…，等等。并最终证明f(n)的值是循环的。 最后，我们已经证明了f(n)是存在循环的，最后要证明的是f(n)是整循环的，也就是说循环起始点应该是f(n) = f(n - 1) + f(n - 2) = f(1) + f(2)。先假设f(n + 2) = f(5) = f(n + 1) + f(n) = f(4) + f(3)，n是循环开始点，由假设可以推导出f(n + 1) = f(n) + f(n - 1) = f(4) + f(3)，f(n - 1)和f(3)之前存在两种可能： 1. f(n - 1) = f(3) 2. |f(n - 1) - f(3)| = 7由f(n)的取值范围[0, 6]知，第二种情况是不可能的，所以f(n - 1) = f(3)，所以n - 1是循环开始点，依次可以类推n - 2是循环开始点，…，直到f(n - k) = f(3) = f(n - k - 1) + f(n - k - 2) = f(2) + f(1)，n - k - 2是循环开始点。所以由证明可知，如果n是循环开始点，则f(n) = f(1)，f(n + 1) = f(2)，…。 知道了f(n)的值是循环的之后，这道题目就很容易做了，只要求出循环开始点就行了，即f(i - 1) = 1， f(i) = 1。 具体实现代码如下： 123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;int f[50] = &#123;0, 1, 1&#125;;int a, b, n;int main() &#123; while (cin &gt;&gt; a &gt;&gt; b &gt;&gt; n) &#123; if (a == 0 &amp;&amp; b == 0 &amp;&amp; n == 0) &#123; break; &#125; if (n &gt; 2) &#123; int i; for (i = 3; i &lt;= 49; i++) &#123; f[i] = (a * f[i - 1] + b * f[i - 2]) % 7; if (f[i] == f[2] &amp;&amp; f[i - 1] == f[1]) &#123; break; &#125; &#125; i -= 2; n = n % i == 0 ? i : n % i; &#125; cout &lt;&lt; f[n] &lt;&lt; endl; &#125;&#125;","categories":[],"tags":[{"name":"ACM","slug":"ACM","permalink":"http://findingsea.github.io/tags/ACM/"}]},{"title":"项目总结：PHP在线词典","slug":"php-dictionary-online","date":"2014-04-03T06:12:00.000Z","updated":"2020-02-22T09:30:45.912Z","comments":true,"path":"2014/04/03/php-dictionary-online/","link":"","permalink":"http://findingsea.github.io/2014/04/03/php-dictionary-online/","excerpt":"前段时间接了小项目，用PHP做一个在线词典。大概花了两个星期不到的时候做完，整理一份项目总结，方便以后回看。","text":"前段时间接了小项目，用PHP做一个在线词典。大概花了两个星期不到的时候做完，整理一份项目总结，方便以后回看。 ##需求整个在线词典算个Web应用吧，包含两类使用者：用户和管理员。用户需要查单词、整句翻译、背单词三大功能模块，具体如下： 查单词 如果用户所查询的单词数据库里有，就直接从数据库中读取 如果用户所查询的单词数据库里没有，就从网上爬，然后把爬回来的数据存进数据库 用户查询查询过的单词，可以选择将其加入生词本 整句翻译 采用谷歌翻译API 提供中翻英、英翻中两种模式 背单词 背诵的单词主要来自用户添加到生词本的单词 对当前正在背诵的单词，提供提示功能 管理员需要添加单词、例句，查看所有用户两个功能模块。 ##语言和工具采用的服务端语言是PHP，工具用了PHPStorm，因为PHPStorm很好的继承了WebStorm在编写Web应用方面的超强性能，对PHP的支持也十分到位，是个非常彪悍的IDE。 前端框架用的是Bootstrap+Flat UI，以前用过比较顺手。 服务端持久化框架用的是Medoo，这个第一次用，功能很强大，编写也很方便，最主要是整个框架也才几K，非常轻量级。 数据库用的是MySQL。 ##项目笔记####jQuery插件用Bootstrap的alert样式写了个jQuery插件，简单实现在用户操作之后，在页面中部顶端slideDown出现提示框，停留一秒钟再slideUp消失。这里主要是用到jQuery DOM操作和CSS绝对居中的技术。不过这个提示框到现在也不是很完美，因为没有办法根据提示内容自适应调整提示框宽度，由于我对CSS只是半吊子，所以基本也都是在网站找代码，为了快点完成项目也就没有在这个问题上继续纠结下去了。 jQuery代码： 1234567891011121314151617181920212223242526272829(function($) &#123; $.alert = function(type, text) &#123; var info_alert = $('&lt;div id=\"info-alert\" class=\"alert absolute-center\"&gt;&lt;/div&gt;'); switch (type) &#123; case 'success': info_alert.addClass('alert-success'); break; case 'info': info_alert.addClass('alert-info'); break; case 'warning': info_alert.addClass('alert-warning'); break; case 'danger': info_alert.addClass('alert-danger'); break; default : info_alert.addClass('alert-info'); &#125; info_alert.text(text); info_alert.prependTo('body'); info_alert.slideDown('slow'); setTimeout(function() &#123; info_alert.slideUp('slow', function() &#123; $(this).remove(); &#125;); &#125;, 1000); &#125;;&#125;)(jQuery); absolute-center类代码： 1234567891011.absolute-center &#123; position: absolute; margin-left: auto; margin-right: auto; min-width:40px; max-width:400px; left: 0; right: 0; text-align: center; overflow: auto;&#125; ####Cookie操作Cookie操作应该是写任何Web应用都避不开的，这次写的时候我就很后悔以前为什么没有整理出一套Cookie操作的代码方便以后重用。这次主要写了setCookie、getCookie、delCookie三个基本操作。虽然说Cookie的操作有很现成的jQuery插件，但是我觉得这种基本的和原理性的东西还是要自己多写写，频繁使用各种插件的结果往往是没了插件之后连最简单的东西也写不出来，毕竟面试笔试的时候你不能就告诉考官我知道有个插件能实现这个功能，具体怎么写我不清楚。 123456789101112131415161718192021222324252627282930313233function setCookie(info, expiredays) &#123; var exdate = new Date(); exdate.setDate(exdate.getDate() + expiredays); for (key in info) &#123; document.cookie = key + '=' + info[key] + ((expiredays==null) ? \"\" : \";expires=\" + exdate.toGMTString()); &#125;&#125;function getCookie(key) &#123; if (document.cookie.length&gt;0) &#123; var start = document.cookie.indexOf(key + \"=\"); if (start != -1) &#123; start = start + key.length + 1; var end = document.cookie.indexOf(\";\",start); if (end == -1) end = document.cookie.length; return document.cookie.substring(start,end); &#125; &#125; return '';&#125;function delCookie() &#123; var exdate = new Date(); exdate.setDate(exdate.getDate() - 1); var username = getCookie('username'), password = getCookie('password'); if (username &amp;&amp; password) &#123; document.cookie = 'username=;expires=Thu, 01-Jan-70 00:00:01 GMT'; document.cookie = 'password=;expires=Thu, 01-Jan-70 00:00:01 GMT'; &#125;&#125; ####32位随机ID生成数据库数据32位ID的随机生成函数： 1234&lt;?phpfunction Random_string($len = 32) &#123; return substr(md5(time()), rand(1,( 32 - $len)), $len);&#125; ##问题和遗憾####项目管理和代码管理这一直是我心中的痛呀，每次做项目之前总是想这次一定定要好好地注重模块化、注重代码重用等等，刚开始的时候还能坚持一下，到后面项目快要完结的时候就开始撒欢地写了。虽然这次项目的管理已经比以前好多了，不过我还是有很多不满意的地方，不过也只能在下次项目里再改进了。 ####面向对象因为刚开始用PHP的时候，就当成脚本语言一直这样写，所以没有太注重PHP的面向对象式编程。本来这次是想在这方面下点功夫的，可惜最后还是为了赶进度没有研究地太深。感觉面向对象这点一直是我的软肋，是应该有个时间好好学习梳理下。 ####随时总结项目中总是会遇到很多问题，也解决很多问题，这次项目也不例外。但是很多时候我都在纠结先继续写代码呢，还是先停一停总结当前的问题和解决方法，可惜的是大多数时候我都选择了前者，所以导致了这次项目做的过程中我其实有很多收获，但是现在真的要我一下子全都写下来我又觉得没太多可写的。","categories":[],"tags":[{"name":"项目总结","slug":"项目总结","permalink":"http://findingsea.github.io/tags/项目总结/"}]},{"title":"Python异号除法需要注意的问题","slug":"python-divison-tips","date":"2014-03-12T04:32:00.000Z","updated":"2020-02-22T09:30:45.912Z","comments":true,"path":"2014/03/12/python-divison-tips/","link":"","permalink":"http://findingsea.github.io/2014/03/12/python-divison-tips/","excerpt":"Python在整型除法上的运算规则和别的语言不同，对于被除数和除数同号的情况下，大部分语言的处理方法都是相似的：计算结果向下取整。但对于被除数和除数异号的情况下，像Java，C++等语言采用向上取整，而Python仍然采用向下取整。这在有些应用场景上会产生和我们预期不同的结果。","text":"Python在整型除法上的运算规则和别的语言不同，对于被除数和除数同号的情况下，大部分语言的处理方法都是相似的：计算结果向下取整。但对于被除数和除数异号的情况下，像Java，C++等语言采用向上取整，而Python仍然采用向下取整。这在有些应用场景上会产生和我们预期不同的结果。 对于同号的情况，大部分语言的处理方法都相似： 12345In [1]: 10 / 3Out[1]: 3In [2]: 1 / 100Out[2]: 0 对于异号的情况，Python仍然采用向下取整： 12345In [3]: -10 / 3Out[3]: -4In [4]: -1 / 100Out[4]: -1 而其他语言（Java，C++）的计算结果为-3和0。 这一点区别在LeetCode OJ的Evaluate Reverse Polish Notation体现地尤其明显。对于该题可采用如下策略： 12if num1 * num2 &lt;0: result.append(-(-num1 / num2)) Evaluate Reverse Polish Notation完整的Python代码如下： 123456789101112131415161718192021222324class Solution: # @param tokens, a list of string # @return an integer def evalRPN(self, tokens): result = [] for i in range(len(tokens)): tk = tokens[i] if tk not in ['+', '-', '*', '/']: result.append(int(tk)) else: num2 = result.pop() num1 = result.pop() if tk == '+': result.append(num1 + num2) elif tk == '-': result.append(num1 - num2) elif tk == '*': result.append(num1 * num2) elif tk == '/': if num1 * num2 &lt;0: result.append(-(-num1 / num2)) else: result.append(num1 / num2) return result[0]","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://findingsea.github.io/tags/Python/"}]},{"title":"系统日志","slug":"system-memo","date":"2014-02-20T12:54:00.000Z","updated":"2020-02-22T09:30:45.912Z","comments":true,"path":"2014/02/20/system-memo/","link":"","permalink":"http://findingsea.github.io/2014/02/20/system-memo/","excerpt":"整理Evernote的时候发现有一篇很零散的系统日志，所以整理一下放上来。","text":"整理Evernote的时候发现有一篇很零散的系统日志，所以整理一下放上来。 ###[2013-12-4]程序运行的时候，需要内存空间存放数据。一般来说，系统会划分出两种不同的内存空间：一种叫做stack（栈），另一种叫做heap（堆）。它们的主要区别是：stack是有结构的，每个区块按照一定次序存放，可以明确知道每个区块的大小；heap是没有结构的，数据可以任意存放。因此，stack的寻址速度要快于heap。其他的区别还有，一般来说，每个线程分配一个stack，每个进程分配一个heap，也就是说，stack是线程独占的，heap是线程共用的。此外，stack创建的时候，大小是确定的，数据超过这个大小，就发生stack overflow错误，而heap的大小是不确定的，需要的话可以不断增加。根据上面这些区别，数据存放的规则是：只要是局部的、占用空间确定的数据，一般都存放在stack里面，否则就放在heap里面。 12345public void Method1()&#123; int i=4; int y=2; class1 cls1 = new class1(); &#125; 上面代码的Method1方法，共包含了三个变量：i, y 和 cls1。其中，i和y的值是整数，内存占用空间是确定的，而且是局部变量，只用在Method1区块之内，不会用于区块之外。cls1也是局部变量，但是类型为指针变量，指向一个对象的实例。指针变量占用的大小是确定的，但是对象实例以目前的信息无法确知所占用的内存空间大小。这三个变量和一个对象实例在内存中的存放方式如下。 从上图可以看到，i、y和cls1都存放在stack，因为它们占用内存空间都是确定的，而且本身也属于局部变量。但是，cls1指向的对象实例存放在heap，因为它的大小不确定。作为一条规则可以记住，所有的对象都存放在heap。接下来的问题是，当Method1方法运行结束，会发生什么事？回答是整个stack被清空，i、y和cls1这三个变量消失，因为它们是局部变量，区块一旦运行结束，就没必要再存在了。而heap之中的那个对象实例继续存在，直到系统的垃圾清理机制（garbage collector）将这块内存回收。因此，一般来说，内存泄漏都发生在heap，即某些内存空间不再被使用了，却因为种种原因，没有被系统回收。 ###[2013-09-18]今天想配置一下在终端中启动MacVim，按网上的教程配置了在$PATH中设置了路径之后，在终端中用命令mvim中启动MacVim总是出现很诡异的情况，MacVim的确是启动起来了，但是没有新建窗口，而终端也进入vim但是无法做任何操作（按任何键都会在插入字符）。并且由于原来就存在的两个问题：终端中的vim无法识别transparency属性和用Homebrew安装的vim于YouCompleteMe存在冲突，而MacVim在这两方面都没问题，所以决定干脆直接把终端中的vim替换成MacVim，替换的方法十分简单：1.找到MacVim.app所在目录，在此目录下启动终端，运行：cp mvim /usr/local/bin/2.在.zshrc中写入alias vim=&#39;mvim -v&#39;配置完之后，当在终端中输入vim test.txt，终端讲会用MacVim打开文件（但还是显示在终端中，不过读取的配置文件都是MacVim的，并且不会出现上述的两个错误） ###[2013-09-19]昨天晚上和今天上，给Mac和台式机上的Vim都装了ConqueTerm，一个用来在Vim中启动终端的插件。这主要是因为在tmux下，Vim在插入模式下，按方向键会输出字母，具体原因还没有弄清楚。（问题，相关文章1，相关文章2）虽然设置了:set term=cons25之后能解决tmux下Vim的方向键问题，但是又引入了新问题：在终端中正常启动Vim进行编辑时，任何按键都输出乱码，加之我对于tmux这种模式不是很有好感（需要先进入tmux模式才能进行多窗口，感觉总是比直接在终端操作多了一层），所以转换思路，在Vim中使用终端。我的最终目的无非是为了能在编写代码时不退出Vim而直接运行调试，ConqueTerm很好的满足了我的需求。ConqueTerm的安装方法：在这里中下载.vba或.vmb，直接用Vim打开然后运行:so %即可。","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://findingsea.github.io/tags/日志/"}]},{"title":"我为什么阅读","slug":"why-i-read","date":"2013-11-17T04:56:00.000Z","updated":"2020-02-22T09:30:45.911Z","comments":true,"path":"2013/11/17/why-i-read/","link":"","permalink":"http://findingsea.github.io/2013/11/17/why-i-read/","excerpt":"写这篇文章的起因是看了《知乎周刊 - 读书这件小事》中的一个精选，问题在这里，周刊中收录的回答在这里。 摘录其中一段： 信息的半衰期用来衡量信息的价值和效用随着时间衰减的速度。以微博为代表的网络信息，通常半衰期就一两天，这就意味着今天令你非常亢奋的信息到了第二天、第三天就可能屁都不是。于是乎，循环往复，你每天生活在会立即失效的信息里，就像记忆力只有24小时的失忆患者，重复着一日复一日的无聊生活。","text":"写这篇文章的起因是看了《知乎周刊 - 读书这件小事》中的一个精选，问题在这里，周刊中收录的回答在这里。 摘录其中一段： 信息的半衰期用来衡量信息的价值和效用随着时间衰减的速度。以微博为代表的网络信息，通常半衰期就一两天，这就意味着今天令你非常亢奋的信息到了第二天、第三天就可能屁都不是。于是乎，循环往复，你每天生活在会立即失效的信息里，就像记忆力只有24小时的失忆患者，重复着一日复一日的无聊生活。 我相信很多『微博微信控』都会有这样的体会——刷了一天微博，各种评论、转发，看了娱乐科技新闻，看上去一天繁忙的很，做了很多事情，但是真的关了微博回想看看，又觉得这一天好像什么事情都没干，越是刷微博刷微信刷得热闹越是觉得生活无聊空虚，越是无聊越是想在微博微信上找点乐子，一不小心就踏进了恶性循环。 上面的回答中提到的『信息半衰期』的概念，很好的解释了这种现象出现的原因。由于微博微信上的信息都是『热信息』，来的快去的也快，搏完人们的眼球之后，就没剩下什么有价值的东西了。把过多时间浪费在吸取这类信息上，在当下可能会得到一定的心理满足和愉悦，并成为你和周围人的热点谈资，但随着信息价值的快速衰弱，一两天后，这些信息就在你的生活中失效了。 同样的，大部分的电视剧、娱乐节目、网络小说，以及很多现在的电影等等，它们所包含的信息的半衰期也很短。那真正有价值的，长盛不衰的信息都上哪里去了？ ###成本人类拥有互联网不过是这二三十年的事情，甚至电视出现也不过百年，那之前的信息如何储存和传播？答案就是出版成书。很显然，比起微博，书的成本高出太多，这里的成本体体现在两个方面： 1.发微博的成本和出书的成本 显然，出书的成本高处太多太多，不管是作家的时间成本，还是出版社的出版印刷销售成本。除非你的书是强制购买的——例如教科书，不然你就要担心销售的问题，而促使一个人买书的最强动机就是他觉得这本书对他有价值。也就是说如果你出版了一本价值不足（不能说毫无价值）的书，那就只有亏本。而发微博——不管有否有价值——成本总是可以忽略不计。 出书还有一个成本在于对名声的影响，你在微博上说错了话，或是散步了虚假的信息，点下『删除』就能销声匿迹。但是书一旦出版了，就永远有据可查。 所以，出书的经济时间成本，使得作者在写书的时候总要深思熟路，努力写出更有价值的东西，而书相比微博的持久性，使得作者在写书时不敢信口开河（当然有还是也有，但是基本发生过一次后，以后再也没人看他的书了）。正因为有这个门槛在，过滤掉了很多毫无价值（或者半衰期很短）的信息，使得书籍承载的信息普遍更有价值，半衰期更长，有些公元前写成的书到现在还在被无数人阅读，便可见其中的价值了。 2.看微博的成本和看书的成本 看书是一件极费体力和脑力的事情，一本稍微有点分量和价值的书，怎么着也得小一个星期才能看的完。而微博呢，估计一分钟看个十条也不成问题。很显然，看书的成本要高得多。正因为有这个高成本在，看书的人他们的心智往往要比那些成天只知道刷微博的人要更成熟，更健全。当一个读书人向你推荐一本书的时候，他必然是花了比看微博多得多的时间和精力去阅读和思考，然后才向人推荐，这样的信息传播往往价值很高。而微博呢，只要点一下『转发』就完成了，有时候你甚至没弄清楚这条微博在讲什么，或者讲的是不是真的，就点了『转发』，这样造成的信息传播，必然存在很多垃圾信息。 太容易的事情，就没有人会去认真对待，这是人趋利避害的天性，微博生产和传播的低成本，造成了现在微博上到处充斥着毫无价值的信息。而书往往包含了更多有价值的半衰期更长信息，它们会在很长的一段时间内都得到人类社会的认可，它们会对我们的生活体现出长时间的价值（有时候甚至是一生）。 ###主动和被动和菜头关于同一个问题的回答中提到： 1、信息的碎片程度加剧，人们倾向于消费越来越短的文字。2、对于富媒体的消费需求增加，尤其是对图片、音频、视频的需求增长惊人。3、信息达到用户的方式，Push和通知机制已经占据主流。 从电视媒体，微博等途径获得信息，很多都属于被动获取。被动获取的弊端就在于我们经常不得不接收一些我们毫不感兴趣的信息，比如凤姐，我对她和她的事毫无兴趣，但是我还是『被迫』认识了她。这一点在微博上尤其严重，因为微博上的社交信息网络，使得这类『炒作信息』几乎是无孔不入的，毕竟你不能保证你的朋友都是摆脱了低级趣味的人。 相较之下，阅读行为要更为主动。你可以自主选择阅读的对象，你可以自主选择何时进入或者抽离阅读环境（想象一下，在微博上你对一条信息已经心生厌倦了，结果它还是反复出现在你的timeline上，想象一下这种痛苦吧），最重要的，阅读的过程时刻伴随着思考，一本书好书或者一片好文章，作者必定不会写个惊悚的标题或者写个140字的爆炸性信息就结束了，作者肯定会从一个或多个角度论证自己的观点，会提供论据，会提供实例，这些东西在丰富作者观点的同时，也给你提供了思考的空间，如果他提供的论据或实例不符合你已有的知识，你很容易就提出质疑，当然你的质疑可能对，也可能错，但这个过程会让你把问题看的更清楚，因为你主动的思考了。（这里主要以阅读论述性的作品举例） ###碎片和整体『信息碎片化』的概念已经被越来越多的人所接受，以至于很多人都不关心信息的整体是什么模样了。对于那些专以消费信息碎片为乐的人来说，这当然不是什么问题。但是如果你想弄清楚事情的来龙去秒，以求获取事情的全貌，但就会非常困难。你不得不自己去收集碎片来拼凑，而且很多事情你无法相信碎片的真实性，因为他们可能互相矛盾。 这是我很讨厌现在一些媒体的原因，他们常常为了贪图爆点，或者为了主旋律，只给出片面的报道和评价，常常造成误导，使得个人或者几个人承担了所有的责任和痛苦。 一本书可能也不能覆盖事实的全貌，但是一本书不能控制舆论，一本书不能阻止你去看另一个观点的书。而且图书的系统和分类，都已经相对成熟，除了书本身，我们还有很多前辈阅读人的指导。这些都能为你勾勒出大概的轮廓，剩下的就要靠你根据自己的阅读和理解，去填充内容和形象。 ###多和少很多人都认为，现在读书的年代已经过去了，除却微博微信，我们这个年代还有电视，报纸，互联网等等，我们有各种各样的途径获得信息，而且通过这些途径可以在更短的时候内获得更多的信息，那我为什么还要读书呢？ 其实这个问题已经不需要我来回答了，莫提默·J. 艾德勒在《如何读一本书》中提到： 太多的资讯就如同太少的资讯一样，都是一种对理解力的阻碍。换句话说，现代的媒体正以压倒性的泛滥资讯阻碍我们的理解力。 电视观众、收音机观众、杂志读者所面对的是一种复杂的组成——从独创的华丽辞藻到经过审慎挑选的资料与统计——目的都在让个人不需要面对困难和努力，很容易就整理出『自己』的思绪。但是这些精美包装的资讯效率实在太高了，让观众、听众或者读者根本用不着自己做结论。相反的，他们直接将包装过后的观点装进自己的脑海中，就想录影带一样自然。他只要按一个『倒带』的钮，就能找到他所需要的适当言论。他根本不用思考就能表现得宜。 ###快和慢现代媒体的发展，的确使得信息的传播更加快速，但有的时候这种快，往往会带来很多副作用。有很多人——包括媒体记者，公众人物——为了追求快，追求爆点，对于信息不加任何求证地传播，常常造成虚假消息的大面积传播，以致谣言四起。对于此，我们能做的也就是在你下次点击廉价的『转发』之前，先求证下信息的真实性，哪怕只是用常识判断一下。 信息的快速传播的确有很多好的方面，但是过份的快，不会产生任何附加的好处，还会大大挤压了我们思考的空间，使我们变得更容易『人云亦云』。而且很多越是快的信息，半衰期越是短，等热潮过后，便毫无价值。更多的时候，我们需要的是慢下来，冷静地思考。而思考并不是一种人与生俱来的能力，思考是需要锻炼的，而最能锻炼人思考能力的行为，就是看书。阅读（或者说看书）的过程是纯粹和持久的，在这个过程中，没有其他嘈杂的信息干扰，你通过对文字的咀嚼和玩味，从一个模糊的概念到有了深刻的理解。这个过程，是对自己理解力不断锻炼和提高的过程。这是一个慢过程，你可能需要长时间的锻炼，才能真正拥有一个合格的理解力，但这是一个真正有价值的过程，这也是我们成为一个合格职业人，乃至合格公民的必经过程。 在这个浮躁的年代，我们更需要的是一杯茶、一本书、一个下午的宁静时光。 这些能让微博失色的东西，通常具有两个特质：纯粹和永恒。《知乎周刊 - 读书这件小事》","categories":[],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://findingsea.github.io/tags/Reading/"}]},{"title":"Django Tips - 2","slug":"django-tips-2","date":"2013-11-09T06:40:00.000Z","updated":"2020-02-22T09:30:45.911Z","comments":true,"path":"2013/11/09/django-tips-2/","link":"","permalink":"http://findingsea.github.io/2013/11/09/django-tips-2/","excerpt":"###在Django中引用静态文件由于Django对于所有链接的请求都需要经过url.py的配置，这虽然可以使得浏览器url非常美观，也方便了开发了，但是在HTML中引入JavaScript和CSS文件时就会发生404错误，因为求情了在url.py中不存在的地址。 Django当然也考虑到了这个问题，所以提供了静态文件的配置方法。","text":"###在Django中引用静态文件由于Django对于所有链接的请求都需要经过url.py的配置，这虽然可以使得浏览器url非常美观，也方便了开发了，但是在HTML中引入JavaScript和CSS文件时就会发生404错误，因为求情了在url.py中不存在的地址。 Django当然也考虑到了这个问题，所以提供了静态文件的配置方法。 1.首先在你的工程中新建一个文件夹static（名字随意）来存放静态文件，文件路径如图： ![static folder](/images/2013/11/9/project catalog.png)在setting.py文件中找到STATIC_URL选项，将其设置为刚才新建的static文件夹相对路径，例如： 1STATIC_URL = './static/' 2.在url.py文件中加入如下配置： 1(r'^static/(?P&lt;path&gt;.*)$', 'django.views.static.serve', &#123;'document_root': settings.STATIC_URL&#125;), ##Django模板对日期类型的转换 Django Template会对日期类型进行转换，按’F j, Y’格式显示，比较如下代码： 代码1： 123456def current_time(request): now = datetime.datetime.now() # print '%s' % now t = get_template('test/current_date.html') html = t.render(Context(&#123;'current_date': now&#125;)) return HttpResponse(html) 输出： 1It's now Oct. 14, 2013, 7:18 p.m. 代码2： 1234def current_time1(request): now = datetime.datetime.now() html = 'It\\'s now %s.' % now return HttpResponse(html) 输出： 1It's now 2013-10-14 19:17:18.361020.","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://findingsea.github.io/tags/Django/"}]},{"title":"从前同事的离职说起","slug":"former-company","date":"2013-11-03T07:14:00.000Z","updated":"2020-02-22T09:30:45.911Z","comments":true,"path":"2013/11/03/former-company/","link":"","permalink":"http://findingsea.github.io/2013/11/03/former-company/","excerpt":"就前几天，在微信『朋友圈』里，看到原来公司的前同事发了张公司所在大楼的照片，文字备注：『非官方娱乐活动叫我 各位保重 再见』，估计是离职了，留言一问，果然是。这个同事还是我当初在公司时非常欣赏的，而且他是我们其中一位Boss的学生，浙大毕业，留学意大利，原来是做工业设计，回国之后做产品设计，能力没的说，最主要人很豪爽。他是进来做产品经理的，上手很快，对于工作的处理和态度都非常专业，后来他负责的这个产品成为公司的主打产品，对于这么个小公司来说，他也算是核心人物了，所以，对他的离职我还是感到了几分惊讶。 惊讶过后，我就问他为什么离职，他给我的回复简洁明了：『带不动』。","text":"就前几天，在微信『朋友圈』里，看到原来公司的前同事发了张公司所在大楼的照片，文字备注：『非官方娱乐活动叫我 各位保重 再见』，估计是离职了，留言一问，果然是。这个同事还是我当初在公司时非常欣赏的，而且他是我们其中一位Boss的学生，浙大毕业，留学意大利，原来是做工业设计，回国之后做产品设计，能力没的说，最主要人很豪爽。他是进来做产品经理的，上手很快，对于工作的处理和态度都非常专业，后来他负责的这个产品成为公司的主打产品，对于这么个小公司来说，他也算是核心人物了，所以，对他的离职我还是感到了几分惊讶。 惊讶过后，我就问他为什么离职，他给我的回复简洁明了：『带不动』。 我离开公司的时候，已经对公司的方方面面心生厌恶，虽然有着还算不错的实习工资，但是在那里工作丝毫不能令人开心而且充斥着令我讨厌的人。当然，这种厌恶来自各方面的累积，我猜想这位『前同事』也是对公司各方面失望了很多次之后，才发出了『带不动』的感慨，并最终选择了离职。 ##老板是xx真是想不出比『xx』更文明的词来形容我的前老板——同时也是我的毕业设计导师。 ###拉自己学生当劳动力我在公司实习期间（十个月左右），公司人数最多的时候也是16、7个，其中绝大部分都是实习生，有本科实习的，也有研究生实习的，当然这么多实习生大部分都是他和另外一位浙大老师的学生，都是被他拉倒公司实习的，并准备在公司完成毕业设计的。这其中我知道绝大多数人都实习了很长时间，其中就包括我。一直到我走的时候，研发部的正式员工也不过4个半（那半个是他已经和公司签了三方协议的，而且这位老兄的能力确实比较强），拿大量实习生当廉价劳动力的公司，在杭州比比皆是，但是这样的公司肯定都走不远。 后来离开公司之后，和上一届的学姐聊起来，才发现我都已经算是幸福的了。上一届的一个学姐，也是这个『xx』的学生，被他强行拉到当时他在做的一家公司里实习，还要在那里做毕业设计，而且，没有工资。（当然我实习有工资的很大一部分原因是由于我所在的这家公司有『土豪』投资，花的不是『xx』自己的钱） ###加班对于IT公司来说，加班很常见，但是像『xx』这样，没事情也不让你走的，我就不知道常不常见了。我们公司规定是5点半下班，由于我只是实习，所以工作量相对来说不是太大，可能偶尔某段时间工作量大一点，我也会自觉加一下班。在大部分时间里，我不需要加班就能完成我负责的任务。只要有一段时间，你连续走的比较早，『xx』就会找你谈话，就算你跟他解释你的工作你都已经完成了，他还是会抛出『你的组长都没走，你怎么能走』、『我都没走，你怎么能走』之类的『终极理论』，然后就是各种教育你要多承担任务，他最喜欢说的一句话就是『哭着喊着求进步』，总之一句话，『要你加班』。当时我就和经常一起回去的同学说，既然到了下班时间又不能下班的，那干嘛规定5点半下班，干脆直接规定11点下班好了。 关于加班这事，据说有一次他从义乌回来，都九点了，到公司发现就几个人，竟然直接打电话给一个已经回家的开发人员，劈头就问『现在是什么情况呀！』，然后那个苦逼的老兄就这样被叫了回来。 ###没有信用画大饼这种事情当然是个老板都会干，而老板的好坏就在于他能把这个大饼给你兑现多少，从我能回忆的起时间来看，『xx』从来就没兑现过。 我们公司比较大的一个大饼就是，绩效奖励。公司的业务和复杂的关系就不说了，简单的就是曾经有一个从『xx』嘴里亲口说出来的承诺，如果到某个时间点，我们系统内的客户达到一个什么数量，全公司有10W的绩效奖励（当然，这钱也不是他出的，相当于是投资人给的奖励），安装每个人的工资比例进行分成。当时公司上下对于这个大饼还是比较憧憬的，毕竟是第一个『大饼』。但是当真到了这个时间点上，虽然我们的业绩磕磕绊绊，但是在我们看来好歹也算是达到要求了，但是他又开始没动静了，只字不提绩效奖金的事情，最后就这样不了了之，对我们没有任何交代。 由于公司成立才一年不到，所以2013年的年会是公司第一次年会，在年会之前，『大饼』又出现了，据说有iPhone和iPad之类的『大奖』供员工抽奖，之前的一段时间，大家对此都非常期待，公司的气氛也不错。由于我中间突然被查出来『腰椎间盘突出』，趴家里养病，后来春节回来问同事才知道，所谓的『大奖』，最大也就是一台iPod touch，之后就是些小本子了，抛出iPod touch剩下的奖品质量就只有大学生搞联谊的奖品水品了。而这还不是最让人厌恶的，公司年会本来是大家乐呵乐呵的活动，但同事跟我说『xx』把年会完全办成了报告会，开了整整两天的会，开会的时间还超出了正常下班的时间，连晚饭也是让员工自行解决的，自己吃完了接着开会。除了『xx』自己讲之后，还让每个员工都上去反思自己这一年哪里做的不好（貌似反思的结论就是：平时要多加班）。###观念有问题『xx』一直喜欢跟我们吹自己以前有多牛逼多牛逼，但是在开会的时候却总提一些很白痴的问题。不过他顶着一个『浙大计算机博士』的头衔，我也不清楚他真是水平到底如何，但是有一点可以肯定的是他在web开发这方面的观念太陈旧了。他给我们看了一个他在浙大时做的项目，可能由于那个年代的技术限制，页面只能用『土的掉渣』来形容。而重点在于，他除了做了那个『土的掉渣』的项目之后，貌似就在没有可以拿的出手的项目了，在经过这么些年技术高速发展和变革之后，他对现在的web开发几乎是毫无概念的。虽然说做老板的不一定要懂技术，但是比起完全不懂技术的老板，『xx』这种自以为自己懂的老板更为可怕。 『xx』曾经很自豪地跟我们说他找人，专科学校出来的人的简历他看都不看的，说干我们这行要有理论基础，不是只会写代码就可以了的。这话我听了就无语，都什么年代了，其实二三流甚至是很多人眼中不入流的学校出来的高级软件工程师比比皆是，他顶着『浙大计算机博士』就看不起这些学校毕业的人，而本身小公司这个阶段就很难招到好学校的毕业生，但是又急缺生产力，很多『差』一点的学校的技术过硬的毕业生其实是很好的选择，一个小公司却硬要把自己的姿态摆的这么高，真是无语。 还有一点就是他对于前端的态度，但凡是说出『前端的工作难度比较低』的人，我就认为他根本不懂现在的web开发。『xx』的思维局限在于，他好像觉得我么是一个互联网公司，那就一定要招个前端，在基本功能都完善不好的情况下，就大谈什么『用户体验』。其实就我看来，好的『用户体验』这种东西对于普通用户来说是有吸引力，但吸引力的大小还因人而异。企业更看重的是功能和可靠性。而我们本身服务的对象是淘宝的卖家，他们在我们的系统内，其实就是这么几个功能翻来覆去的用，在你还没把这么几个功能做的完全可靠的时候，就要什么『用户体验』，要什么『界面改版』，这不是本末倒置嘛。这一点的直接结果就是另一组的同事被坑惨了，他们的项目由于界面改版等等问题，导致功能开发进度一拖再拖，界面大范围改版引发的bug又给项目雪上加霜。###自以为是他自以为是的点实在太多了，其中最令人无语的就是我刚到公司的时候，那个时候公司连人都没几个，他竟然就对我们（我和另外一个被拉倒当劳力的同学）说：公司两年内要上市。在这个互联网公司三年内不倒就算是成功的大环境下，真不知道他盲目的自信来自哪里。现在呢，一年已经过去了，上市的机会我是没看到，倒是有不少员工选择了离职。 后来他又不知道哪来的idea，要我们每天下午1点半左右集体做广播体操，做完广播体操之后每天轮流一个人做分享（扯淡的内容居多）。前几天看『小道消息』的《奇葩公司文化巡礼》，里面就有人提到他们公司也要做广播体操，当时我就笑了。这些时候在我们所有员工看到都是浪费时间，如果你真的关心员工身体和心理的健康，多发点福利，少加点班，这是最简单有效的方法。我估计是他不知道看了什么乱七八糟的管理类的书，想出这么一个idea。每天占用开发人员效率值最高时段（因为刚午休睡醒）的一小时时间，来做这些东西，然后晚上又要你加班，这不是xx是什么。 他还有自以为是的点在于对自己产品的盲目乐观和觉得用户是xx。每次开会的时候，都大吹特吹我们的产品能给某通解决多少多少问题，而现实情况却是，在我离开之前，我们的产品还一分钱都没赚着，还给一个用户造成了直接的经济损失（这些钱又公司赔付，最后按工资比例分摊到每个人头上）。然后就是总觉某通那边的人是xx，觉得我们的东西不好用，的确，某通那边的工作人员文化程度是不高，但是没办法，谁让他们就是我们就是我们的目标用户呢。《黑客与画家》里就提到：永远都不要觉得自己比用户聪明。你给什么样的人做产品，你就得把自己也降到那个水平来审视自己的产品，要不然你就不要做。总不能你是做儿童游戏应用的，却总怪他们连字都看不懂。 ###没人情味这主要体现在两件事上。 一是有一个美工兼项目经理离职，看这个头衔就知道他在我们公司的作用很大，加之他在公司的时间也比较久了，和公司很多人关系都不错，当时他走的时候大家是很想聚一下的，就当欢送吧。但是『xx』一声不吭，最后连吃个饭也没有，那位同事就这样默默地走了。 二是当时测试部的三个同事先后感冒请假了，导致另外一组项目的测试工作没人了，他竟然打电话硬把最早的感冒的同事叫回来，那个同事发着烧在公司顶了一个上午，最后实在不行了下午回家了。回去之后就直接辞职了（当然，又扔下一个烂摊子）。 ##代码管理混乱当然，代码管理的混乱很大一部分原因来自人员流动太大了，因为都是实习生，进进出出很正常。还有过两个试用期结束就走了的准员工，结果留下了一堆没认出来的问题和没人看得懂的代码。 还有一部分原因就是没有实力过硬的主程压阵，四个正式研发人员中，最大的也不过28岁，虽然年纪不代表什么，但是从实际效果来看，他们明显没有把握好大代码量的管理。举例来说，我后期在维护的一个js文件，里面有5500行代码，被七八个页面引用，在里面查一个函数都要半天，改一个地方就容易影响到另一个你想不到的地方。这种不可维护的代码，在我们的工程里还随处可见。代码风格不统一，API调用方式不统一，页面渲染方式不统一，等等等，这些问题甚至出现在每一个js文件里，因为这些文件基本上都被不止一个甚至两个人编写和修改过。 ##公司气氛冷淡虽然这点要求可能过高，但是对于小公司来说，其实是比较好搞公司文化。就那么几个人，活动起来也很灵活，但是现实情况是基本上下了班公司里的人就不会有交集了。其实不需要什么大活动，隔几个星期大家一起吃个饭什么的也能增进感情。我在职期间，活动是搞过几次，但是频率太低，效果也太差。小公司本身硬实力就差，大家感情再淡了，很多东西就事倍功半了。 ##员工激情创业公司相比大公司，最有优势的可能就在于员工激情。因为一般来说，哥们几个聚在一起开公司肯定是想做自己的产品，做属于自己的产品，没有什么比这更能推动开发人员的了。这也是很多小团队可以做出大公司都不一定能做出的优秀产品的原因。一般来说，早期员工是非常珍贵的资源，他们更有激情，后面招聘进来的员工大多只为了工资而来，并没有像早期员工那么强烈的动力和理想，但是如果能使早期员工稳定地留在公司，公司就能长期地用有这种热情，那么后进的员工也会被感染，而形成互相促进的效果。 但是我们公司就奇葩在草创时期的人都走的七七八八了，因为他们本来就是被自己老师（『xx』和另外一个浙大的老师）叫过来的干劳力的，显然不会长待，做完一个阶段之后就走了。那个时期的开发人员到后来只剩下两人，整个公司的热情可想而知。一个小公司里，却都是些只想赚工资的人，真是可悲呀。 ##结束吐槽了这么多，无非是被前同事的离职勾起了很多回忆。最后，希望那些还没离职的前同事们，继续奋斗，或是早日辞职吧。","categories":[],"tags":[{"name":"吐槽","slug":"吐槽","permalink":"http://findingsea.github.io/tags/吐槽/"}]},{"title":"Django Tips - 1","slug":"django-dev-on-weibo-apps-1","date":"2013-10-19T07:49:00.000Z","updated":"2020-02-22T09:30:45.911Z","comments":true,"path":"2013/10/19/django-dev-on-weibo-apps-1/","link":"","permalink":"http://findingsea.github.io/2013/10/19/django-dev-on-weibo-apps-1/","excerpt":"近来想用Django做一个微博的站内应用，虽说一个简单的站内应用用Django开发有点『杀鸡用牛刀』的意思，但是由于之前用Django开发的经验为零，作为第一个练手项目，微博应用还是相当合适的。顺便把遇到的一些问题和解决方案记录下来，以备回看、","text":"近来想用Django做一个微博的站内应用，虽说一个简单的站内应用用Django开发有点『杀鸡用牛刀』的意思，但是由于之前用Django开发的经验为零，作为第一个练手项目，微博应用还是相当合适的。顺便把遇到的一些问题和解决方案记录下来，以备回看、 ###本地调试在实际运行中，用户当然是通过微博应用页面来访问我们的服务器，使用我们的应用，但是在开发调试的时候，如果每次都需要把代码同步到服务器才能看到效果的话那简直要『疯了』，所以设置本地调试必不可少。 所幸设置本地调试并不复杂。 首先，在『应用信息』–&gt;『高级信息』–&gt;『安全设置』中，将『应用的服务IP地址』设置为：127.0.0.1。注意，『基本信息』中的『应用实际地址』必须是线上地址，不要把这个地址改为127.0.0.1。 然后，修改hosts文件。Mac下修改hosts的方法，可以参考果迷网的文章——在 Mac OS X Lion 下修改 Hosts 的四种方法。在hosts中添加这样一行： 1127.0.0.1 www.xxxx.com www.xxxx.com是你的应用服务器地址。这样浏览器在根据hosts解析的时候，会将对www.xxxx.com的访问重定向到本地。这时候在浏览器地址栏中输入www.xxxx.com，你会发现访问的是本地，同理，微博页面向www.xxxx.com发送的请求其实是发到本地，它包含的也是本地的页面。这样我们就可以在本地对我们的应用进行修改，然后通过微博应用页面直接开效果了，等开发和调试工作完成后在部署到服务器上即可。 ###新浪POST请求的CSRF问题微博站内应用其实就是把你应用的页面嵌在它规定的一个iframe里面，当用户访问的你的应用时，新浪微博会在该月面通过一个form发送一个POST请求到你的『应用实际地址』上，这样带来的一个问题就是：Django处于防止CSRF攻击的考虑对于发送POST请求的form要求有csrf_token，否则就会发生403错误，如下： 1[18/Oct/2013 18:13:40] \"POST /friendscare/ HTTP/1.1\" 403 2294 但是这个POST请求是从微博页面发送过来的，不是由我们控制的，那解决方法就是在接收微博请求的view函数上禁止csrf，利用@csrf_exempt修饰符可以做到这一点，可以查看相关文档。 ###X-Frame-Options问题在解决了POST请求的CSRF问题之后，访问应用界面发现还是没有任何现实，打开Chrome开发者工具，发现Console中有错误： 报错的意思直译就是无法在框架中现实http://www.findingsea.com:8000/friendscare/页面，因为该页面把X-Frame-Options的值设为了SAMEORIGIN，之前没有见过这类报错，参考不在水中的鱼的博文HTTP X-Frame-Options得知： X-Frame-Options response header 可用于指示是否应该允许浏览器呈现在一个页面&lt;FRAME&gt;或&lt;IFRAME&gt;中. 以确保网站内容是不是嵌入到其它网站 而X-Frame-Options的值为SAMEORIGIN表示页面只能显示在页面本网站的框架中，所以我的应用页面就不能被包含在微博页面的iframe框架中了。而这个值是Django默认设置的，同样是出于安全性的考虑，如果要对一个特定视图允许被第三方页面包含，只要加上@xframe_options_exempt修饰符即可，可以查看文档。","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://findingsea.github.io/tags/Django/"}]},{"title":"可能引起「We were unable to load Disqus」错误的一种情况分析","slug":"about-we-were-unable-to-load-disqus","date":"2013-09-23T06:06:00.000Z","updated":"2020-02-22T09:30:45.911Z","comments":true,"path":"2013/09/23/about-we-were-unable-to-load-disqus/","link":"","permalink":"http://findingsea.github.io/2013/09/23/about-we-were-unable-to-load-disqus/","excerpt":"今天想往Octopress里加评论，之前看了网上的教程，应该是简单的事情，因为Octopress本来为你准备好了评论插件Disqus的代码，只需要去Disqus注册个帐号，然后在_config.yml里面打开配置就行了，没想到这么简单的事情却被之前埋的的一个坑给坑惨了。","text":"今天想往Octopress里加评论，之前看了网上的教程，应该是简单的事情，因为Octopress本来为你准备好了评论插件Disqus的代码，只需要去Disqus注册个帐号，然后在_config.yml里面打开配置就行了，没想到这么简单的事情却被之前埋的的一个坑给坑惨了。 之前在《利用Octopress在Github上搭建博客及后续问题总汇》这篇文章提到过，我利用Octopress建站主要参考的教程就是破船的《利用Octopress搭建一个Github博客》，其中对于_config.yml的设置提到过： config.yml是博客重要的一个配置文件，在config.yml文件中有三大配置项：Main Configs、Jekyll &amp; Plugins和3rd Party Settings。 一般，该文件中其中url是必须要填写的，这里的url是在github上创建的一个仓库地址，具体请看第四步中创建的地址。另外再修改一下title、subtitle和author，根据需求，在开启一些第三方组件服务。 而其中的坑就在于文章说_config.yml中的url需要配置成GitHub上的仓库地址，当时根据这种说法，我配置的url为： 1url: https://github.com/findingsea/findingsea.github.com.git 当时启动部署一切都正常，我也根本没想到这样配置其实是错误的。要知道为什么这样配置是错误的，就要先讲讲Disqus。一般情况下，Disqus想要引入正常，就要保证/source/_includes/disqus.html文件中的disqus_url和_config.yml文件中的disqus_short_name这两个值的正确。disqus_url是Disqus需要嵌入评论插件的地址，disqus_short_name是Disqus对你的站点的标识。disqus_short_name是自己手动设置的，而且是在要启动Disqus插件的时候才设置的，一般不会出错，而disqus_url的值是Octopress读取你的配置文件自动生成的，这里如果发生错误是很难发现的。而我们看disqus_url的定义： 1var disqus_url = '&#123;&#123; site.url &#125;&#125;&#123;&#123; page.url &#125;&#125;'; 很明显，disqus_url的值由_config.yml配置文件中的url和当前页面的路径决定。我在/source/_includes/disqus.html中将disqus_url的值进行输出，发现在上述配置方法下，disqus_url的值为： 1https://github.com/findingsea/findingsea.github.com.git/blog/2013/09/23/about-we-were-unable-to-load-disqus/ 也就是说现在变成了我们要求Disqus在GitHub仓库子页面下插入评论插件，这不是作死是什么！ 所以正确的设置方法，应该是在_config.yml中将url设置为你站点的地址，对应我就应该是http://findingsea.github.io。Octopress官网的配置说明页面也对url的值进行了描述： 最值得信赖的还是官方的文档，老是看网上的教程就难免踩到坑。","categories":[],"tags":[{"name":"Octopress","slug":"Octopress","permalink":"http://findingsea.github.io/tags/Octopress/"}]},{"title":"利用Octopress在Github上搭建博客及后续问题总汇","slug":"li-yong-octopresszai-githubshang-da-jian-bo-ke-ji-hou-xu-wen-ti-zong-hui","date":"2013-09-20T07:03:00.000Z","updated":"2020-02-22T09:30:45.909Z","comments":true,"path":"2013/09/20/li-yong-octopresszai-githubshang-da-jian-bo-ke-ji-hou-xu-wen-ti-zong-hui/","link":"","permalink":"http://findingsea.github.io/2013/09/20/li-yong-octopresszai-githubshang-da-jian-bo-ke-ji-hou-xu-wen-ti-zong-hui/","excerpt":"用Octopress在GitHub上搭建博客已经不是什么新鲜事了，网上的教程也多了去了，大题的方法什么都差不多，这篇Blog就把这些资源总汇一下，然后再加几点我遇到的问题和解决办法。","text":"用Octopress在GitHub上搭建博客已经不是什么新鲜事了，网上的教程也多了去了，大题的方法什么都差不多，这篇Blog就把这些资源总汇一下，然后再加几点我遇到的问题和解决办法。 搭建和配置搭建的大致过程大概包括：安装Ruby –&gt; 安装Octopress –&gt; 配置Octopress –&gt; 部署到GitHub上 –&gt; 提交博客。我主要参考的是破船的这篇教程——《利用Octopress搭建一个Github博客》。一路按教程走下来大问题应该不会有，但是小问题可能就不断了，这待会会讲到。 其他比较推荐的教程还有，唐巧的这篇《象写程序一样写博客：搭建基于github的博客》(好吧，他还把『像』写错了)。这里面还提到了一些提高访问速度的技巧和介绍了一个支持微博评论的工具，都挺有用的。 另外，还有这篇《Octopress - 像黑客一样写博客》，介绍地非常详细，并介绍了很多个性化配置的技巧，其中对CSS的修改我觉得非常值得学习和借鉴。 //— 2013-09-21 update —// 以及这篇《Octopress博客问题解决方案与技巧》，里面汇总了很多Octopress的设置技巧，在首页输出摘要的设置方法和zsh报错的原因（下面会提到），我都是从这篇文章里面找到。 遇到的问题安装失败问题在运行下面这些语句的时候，终端直接就没反应了，然后过很久报error，据说是访问的地址可能被墙了，但是我在浏览器里访问http://rubygems.org/这个地址是可以的，所以就很纠结，当时就卡在这里下不去，最后无奈就多试了几次，结果就好了。你只能服了天朝的网络了。（从目前情况来看，应该识没有被墙，如果报类似could not download这种错误，只能多试几次，也没别的办法了） 123gem install bundlerrbenv rehash # If you use rbenv, rehash to be able to run the bundle commandbundle install 引号问题根据唐巧的教程，新建文章的指令应该是： 1rake new_post[\"title\"] 然后在相应的markdown文件中头部自动生成的信息中会有： 1title: \"title\" 当时当我按照这个指令去执行的执行的时候，终端报错： 1zsh: no matches found: new_post[title] 我在网上找到的解决办法是将指令改成： 1rake 'new_post[\"title\"]' 这样创建新文章是成功了，但是立马引发了另一个问题。生成好文章之后，执行rake generate指令，终端报错： 12345678910111213141516/Users/findingsea/.rvm/rubies/ruby-1.9.3-p448/lib/ruby/1.9.1/psych.rb:203:in `parse': (&lt;unknown&gt;): did not find expected key while parsing a block mapping at line 2 column 1 (Psych::SyntaxError) from /Users/findingsea/.rvm/rubies/ruby-1.9.3-p448/lib/ruby/1.9.1/psych.rb:203:in `parse_stream' from /Users/findingsea/.rvm/rubies/ruby-1.9.3-p448/lib/ruby/1.9.1/psych.rb:151:in `parse' from /Users/findingsea/.rvm/rubies/ruby-1.9.3-p448/lib/ruby/1.9.1/psych.rb:127:in `load' from /Users/findingsea/.rvm/gems/ruby-1.9.3-p448/gems/jekyll-0.11.2/lib/jekyll/convertible.rb:33:in `read_yaml' from /Users/findingsea/.rvm/gems/ruby-1.9.3-p448/gems/jekyll-0.11.2/lib/jekyll/post.rb:39:in `initialize' from /Users/findingsea/Workspace/Github/octopress/plugins/preview_unpublished.rb:23:in `new' from /Users/findingsea/Workspace/Github/octopress/plugins/preview_unpublished.rb:23:in `block in read_posts' from /Users/findingsea/Workspace/Github/octopress/plugins/preview_unpublished.rb:21:in `each' from /Users/findingsea/Workspace/Github/octopress/plugins/preview_unpublished.rb:21:in `read_posts' from /Users/findingsea/.rvm/gems/ruby-1.9.3-p448/gems/jekyll-0.11.2/lib/jekyll/site.rb:128:in `read_directories' from /Users/findingsea/.rvm/gems/ruby-1.9.3-p448/gems/jekyll-0.11.2/lib/jekyll/site.rb:98:in `read' from /Users/findingsea/.rvm/gems/ruby-1.9.3-p448/gems/jekyll-0.11.2/lib/jekyll/site.rb:38:in `process' from /Users/findingsea/.rvm/gems/ruby-1.9.3-p448/gems/jekyll-0.11.2/bin/jekyll:250:in `&lt;top (required)&gt;' from /Users/findingsea/.rvm/gems/ruby-1.9.3-p448/bin/jekyll:23:in `load' from /Users/findingsea/.rvm/gems/ruby-1.9.3-p448/bin/jekyll:23:in `&lt;main&gt;' 当时差点没吓死，以为怎么了，把关键错误描述上网搜了下，找到了这篇《Linked List Posts: From Movable Type to Octopress》这个老兄（暂且认为是男的吧）和我遇到了一样的错误，他新建的markdown文件里title的内容里，出现双引号嵌套双引号，这违反了markdown的语法规则，所以解析出错了。我立马查看了我新建的问题，果然如此： 1title: \"\"title\"\" 着就相当于中间的title不包含在任何引号中，所以生成的时候会报错。最后我把指令改成如下所示，就一切正常了。 1rake 'new_post[title]' 至于原因现在还不是很清楚，我怀疑很有可能是shell造成的，我用的zsh，而教程上一般用bash的比较多。 //— 2013-09-21 update —// 上面提到的问题已在《Octopress博客问题解决方案与技巧》中找打，的确是shell引起的问题，用zsh的同学可以借鉴下。 字体问题由于对字体方面有洁癖，所以在这上面耗费了很久，看了很多博客采用的字体方案，其中Aiur最让我喜欢，尤其是正文的英文字体，所以我立马留言向博主询问他采用的是哪种字体，最后得知是Google的开源字体Open Sans。 Octopress字体的设置文件是：sass/custom/_fonts.scss，其中$heading-font-family定义的是文章标题的字体，$header-title-font-family定义的是博客标题的字体，$header-subtitle-font-family定义的是博客子标题的字体，$sans和$serif定义的是正文的字体，$mono定义的是代码的字体。这里需要注意的是，/sass/custom/_style.scss里定义的样式会覆盖其他地方定义的样式，但唯独_font.scss里的这几个值不会被覆盖，也就说如果你在_fonts.scss里已经定义了$mono的值，还想在_style.scss中修改&lt;code&gt;&lt;/code&gt;的字体样式是不行的，最后渲染出的结果还是$mono的字体。（一开始我不知道这一点，在_style.scss里折腾了好久）。 特别说明的是我对编程字体尤其在意，我最喜欢的是Adobe的开源字体Source Code Pro，而且是跨平台的，不过这在很多机器上不一定有装，而且貌似GoogleFonts没有收录这个字体，所以我依次补充了Mac上最适宜的编程字体Monaco，Windows上最适宜的编程字体Consolas，和Ubuntu上最适宜的编程字体Ubuntu Mono，这里的设置是依次序寻找到第一个可以使用的字体。（也就说浏览器会先寻找本机是否装有Source Code Pro，如果没有就寻找下一个Monaco，以此类推，直到找到一个可用的字体进行渲染，另外，我所选的三款字体都是三个平台默认安装的，这样可以最大程度地保证代码阅读质量） 下面是我的_fonts.scss文件中的定义： 123456$sans: Open Sans;$serif: Open Sans;$mono: Soure Code Pro, Monaco, Consolas, Ubuntu Mono;$heading-font-family: \"PT Serif\",Georgia,\"STHeiti\",\"SimHei\",\"Helvetica Neue\",Arial,sans-serif;$header-title-font-family: \"Futura\", sans-serif;$header-subtitle-font-family: \"Futura\", sans-serif; 最后说一点，在上文中提到的唐巧的《象写程序一样写博客：搭建基于github的博客》中，他提到了一个优化博客load速度的方法是：删除/source/_includes/custom/head.html文件中的谷歌字体，因为GFW的关系，这部分载入会特别慢。但这会引发一个问题就是你无法使用PT Serif和Open Sans这些优质的谷歌字体了，解决方法是可以讲他们下载到本地，然后在/sass/custom/_style.scss中添加： 1234@font-face &#123; font-family: Open Sans; src: url(fonts/OpenSans-Regular.ttf)&#125; 不过这种方法的弊端在于需要把你用到的每个本地可能没有安装的字体都下载下来，我嫌太麻烦，就没有按这种方法，而且英文字体库不像中文字体库动辄上M，基本都维持在K这个级别，速度慢了这么一点还是可以忍受的。","categories":[],"tags":[{"name":"Octopress","slug":"Octopress","permalink":"http://findingsea.github.io/tags/Octopress/"},{"name":"GitHub","slug":"GitHub","permalink":"http://findingsea.github.io/tags/GitHub/"}]},{"title":"Python生成器","slug":"pythonsheng-cheng-qi","date":"2013-09-20T05:48:00.000Z","updated":"2020-02-22T09:30:45.910Z","comments":true,"path":"2013/09/20/pythonsheng-cheng-qi/","link":"","permalink":"http://findingsea.github.io/2013/09/20/pythonsheng-cheng-qi/","excerpt":"生成器可以说是Python和其他语言较为不同的地方，刚开始看到《Python基础教程》里的Python生成器内容时，还是很不适应，因为以前学过的语言都没有这种特性，所以理解不能，好在经过反复阅读书上的内容和自己编写代码测试之后，终于感觉理解到点上了，这里写篇Blog用来备忘。","text":"生成器可以说是Python和其他语言较为不同的地方，刚开始看到《Python基础教程》里的Python生成器内容时，还是很不适应，因为以前学过的语言都没有这种特性，所以理解不能，好在经过反复阅读书上的内容和自己编写代码测试之后，终于感觉理解到点上了，这里写篇Blog用来备忘。 生成器基本概念从概念上来说，生成器就是用普通方法定义的迭代器，或者更直观点的讲法就是任何包含yield语句的函数都是一个生成器。看一个简单生成器的代码1： 1234def repeater(): for i in range(10): yield 1print list(repeater()) 输出如下： [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]这个生成器生成了一组长度为10，每个元素都为1的数据，我们最后将其转换成列表形式进行输出。 在这个例子中，如果用print来代替yield我们也能得到『相似』的输出。但是yield的一个显著特征就是它不是返回任何值，而是产生值，代码1中，就是每次循环产生一个1。而当函数执行完之后，并不返回值，也不返回None（这一点很重要，如果只是简单地把yield当成print的一种变形就很容易犯这个错误），而是返回一个生成器，如果我们直接输出代码1中的repeater()函数： 1print repeater() 将会得到： &lt;generator object repeater at 0x101a4e410&gt;就像上面所说的，生成器并不直接返回值，而是返回一个根据你的函数定义的生成器，当用类似list(generator)方法调用的时候，就可以根据相应的数据结构生成数据。 再来看一个较为复杂的生成器代码2： 123456789def flatten(nested): try: for sublist in nested: for element in flatten(sublist): yield element except TypeError: yield nestedprint list(flatten([[0,1,2],3,4,[[5,6]],7])) 代码2的输出为： [0, 1, 2, 3, 4, 5, 6, 7]代码2的作用就是将一棵树进行展开，采用了递归的思想，它的工作原理就是，如果当前的对象还是可以展开的，那就继续展开，如果无法展开（Python中int是无法展开的），就会抛出TypeError这个异常，而且这个引发TypeError的值就是我们希望得到的值，所以捕获这个异常后生成值。 代码2同样来自《Python基础教程》，如果要深究起运行过程，则先需要理解生成器是可迭代的，是可以为作为for循环的展开对象的。并且，yield每次产生一个值，都会将函数冻结，下次则再从该冻结的点继续执行。拿第一个元素0举例来说明代码2的运行过程（以下为我根据测试程序结果推断的）： 第一层，运行flatten([[0,1,2],3,4,[[5,6]],7])，展开后sublist为[0,1,2]，进入第二层 第二层，运行flatten([0,1,2])，展开后sublist为0，进入第三层 第三层，运行flatten(0)，代码试图对0进行展开，Python抛出TypeError，由代码捕获到，生成数据0，并返回生成器 返回第二层，对生成器进行迭代（含数据0），生成数据0，函数冻结，并返回生成器 返回第一层，对生成器进行迭代（含数据0），生成数据0，函数回到第二层的冻结点继续执行。 next()方法next()方法的示例代码如下： 12345def repeater(): while True: yield 1r = repeater()print r.next() 以上代码会输出1，而且如果你继续调用r.next()，就会继续输出1。next()其实就是迭代器，读取生成器生成的下一个值，这里可以看出生成器相较于列表更有优势的一点就是：列表总是先将数据生成并储存起来，当需要用的时候就去读取，而生成器都是当需要使用的时候才生成数据，这一点在处理大数据量甚至是无限生成的数据时尤其有用。 next()方法还需要注意的一点是，对于yield n语句，next()返回的是n的值，而yield n本身的返回值为None，这一点在send()方法中还会再一次被提到。 send(value)方法send()方法允许外界向生成器内部传递数据，当调用send()方法时，内部将会挂起生成器，yield作为表达式而非语句使用，yield n将会有一个返回值，该值就是外界通过send()方法传递进来的值。send()方法的示例代码如下： 123456789101112# When you call next(), n is ever None. When you call send(num), yield is hold up,# so (yield value) return numdef repeater(value):while True: n = (yield value) if n is not None: value = nr = repeater(11)print r.next()r.send(10)print r.next() 输出为： 11 10可以看到在生成器初始化完后，调用next()得到的值是我们初始化时传递进去的11，而当调用send()方法向生成器传了一个值10之后，在调用next()方法，得到就是后传进去的值10了。 send()方法需要注意的有两点： 通过send()方法传入生成器的值，由n = (yield value)的形式被生成器内部接收，n即为传进来的参数的值。而如果未调用send()方法，n的值为None。 send()方法不能在生成器刚初始化完成的时候调用，也就说必须要等到yield函数至少执行1次之后，才能调用send()方法，这是因为send()会在内部使生成器挂起，所以必须要求yield已经执行过，如果去掉上述代码中的第一个r.next()，则会得到错误：TypeError: can&#39;t send non-None value to a just-started generator。如果一定要在刚刚启动的生成器使用send()方法，可以采用send(None)来解决。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://findingsea.github.io/tags/Python/"}]}]}